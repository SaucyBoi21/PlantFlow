{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 22:55:07.121111: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-06 22:55:07.248001: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-06 22:55:07.249146: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-06 22:55:08.185960: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dataloader.ipynb\n",
      "Tensorflow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import import_ipynb\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from dataloader import get_LA_X_df, get_y_df, data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filepath = \"../../data/csv/data_matrix2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_LA_X_df(csv_filepath)\n",
    "y = get_y_df(csv_filepath, 'LA_mm2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam(\"num_units\", hp.Discrete([16, 32, 64, 128, 256]))\n",
    "HP_DROPOUT = hp.HParam(\"dropout\", hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam(\"optimizer\", hp.Discrete(['adam', 'sgd']))\n",
    "HP_ACTIVATION = hp.HParam(\"activation\", hp.Discrete(['linear', 'relu', 'sigmoid']))\n",
    "\n",
    "METRIC_ACCURACY = 'loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-06 22:55:10.093373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-06 22:55:10.117387: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "with tf.summary.create_file_writer('../../logs/hyperparam_tuning/repression/LA').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, HP_ACTIVATION],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name=\"Test Accuracy\")]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_prep(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LA_model(hparams):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(hparams[HP_NUM_UNITS], hparams[HP_ACTIVATION], name='layers_input', input_shape = (20,),),\n",
    "            tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(hparams[HP_NUM_UNITS], hparams[HP_ACTIVATION], name='layers_dense2'),\n",
    "            tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(1, name='layers_dense3')\n",
    "        ])\n",
    "\n",
    "        model.compile (\n",
    "            optimizer=hparams[HP_OPTIMIZER],\n",
    "            loss='mae',\n",
    "        )\n",
    "\n",
    "        model.fit (\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=250,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "                hp.KerasCallback(log_dir, hparams)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        accuracy = model.evaluate(X_test, y_test)\n",
    "        return accuracy\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../../logs/hyperparam_tuning/regression/LA/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy = LA_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 16, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 17ms/step - loss: 689.7323 - val_loss: 660.0598\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6802 - val_loss: 660.0251\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.6257 - val_loss: 659.9890\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5682 - val_loss: 659.9525\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.5073 - val_loss: 659.8905\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4429 - val_loss: 659.8296\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3745 - val_loss: 659.7646\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3020 - val_loss: 659.6823\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2253 - val_loss: 659.6042\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1442 - val_loss: 659.5237\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.0587 - val_loss: 659.4402\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.9686 - val_loss: 659.3515\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.8740 - val_loss: 659.2531\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.7747 - val_loss: 659.1500\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6705 - val_loss: 659.0336\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.5616 - val_loss: 658.9329\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4479 - val_loss: 658.8103\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3293 - val_loss: 658.6801\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2057 - val_loss: 658.5651\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.0775 - val_loss: 658.4346\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9439 - val_loss: 658.3055\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8055 - val_loss: 658.1656\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6620 - val_loss: 658.0219\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5136 - val_loss: 657.8649\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.3601 - val_loss: 657.7031\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.2015 - val_loss: 657.5297\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.0378 - val_loss: 657.3616\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.8691 - val_loss: 657.1957\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.6952 - val_loss: 657.0172\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.5163 - val_loss: 656.8372\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.3322 - val_loss: 656.6373\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1429 - val_loss: 656.4163\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9487 - val_loss: 656.2295\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.7491 - val_loss: 656.0367\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.5446 - val_loss: 655.8239\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3350 - val_loss: 655.6264\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.1201 - val_loss: 655.3991\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.9001 - val_loss: 655.1677\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.6750 - val_loss: 654.9380\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.4448 - val_loss: 654.6890\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.2095 - val_loss: 654.4299\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.9691 - val_loss: 654.1882\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.7235 - val_loss: 653.9423\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.4728 - val_loss: 653.6857\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.2171 - val_loss: 653.3987\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.9562 - val_loss: 653.1392\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.6904 - val_loss: 652.8943\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.4193 - val_loss: 652.6299\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.1432 - val_loss: 652.3282\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.8621 - val_loss: 652.0406\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.5759 - val_loss: 651.7451\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.2847 - val_loss: 651.4453\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.9884 - val_loss: 651.1557\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.6870 - val_loss: 650.8688\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.3806 - val_loss: 650.5612\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.0694 - val_loss: 650.2397\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.7530 - val_loss: 649.9189\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.4316 - val_loss: 649.5760\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.1053 - val_loss: 649.2327\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.7740 - val_loss: 648.8698\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.4377 - val_loss: 648.5214\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.0964 - val_loss: 648.1866\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.7502 - val_loss: 647.8328\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.3992 - val_loss: 647.4797\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.0432 - val_loss: 647.1342\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.6821 - val_loss: 646.7725\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.3163 - val_loss: 646.4244\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.9456 - val_loss: 646.0468\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.5701 - val_loss: 645.6766\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.1896 - val_loss: 645.3100\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.8042 - val_loss: 644.9103\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.4141 - val_loss: 644.5044\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.0191 - val_loss: 644.1153\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.6193 - val_loss: 643.7224\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.2146 - val_loss: 643.3029\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.8052 - val_loss: 642.9064\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.3909 - val_loss: 642.4883\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.9720 - val_loss: 642.0577\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.5483 - val_loss: 641.6127\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.1198 - val_loss: 641.1925\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.6866 - val_loss: 640.7643\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.2486 - val_loss: 640.3276\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.8059 - val_loss: 639.8873\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.3586 - val_loss: 639.4347\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.9065 - val_loss: 638.9891\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.4497 - val_loss: 638.5195\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.9883 - val_loss: 638.0473\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.5222 - val_loss: 637.5430\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.0515 - val_loss: 637.0956\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.5762 - val_loss: 636.6188\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.0962 - val_loss: 636.1772\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.6116 - val_loss: 635.6938\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.1224 - val_loss: 635.1887\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.6286 - val_loss: 634.7047\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.1304 - val_loss: 634.1899\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.6274 - val_loss: 633.6425\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.1200 - val_loss: 633.1068\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.6080 - val_loss: 632.5807\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.0915 - val_loss: 632.0493\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.5704 - val_loss: 631.5244\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.0449 - val_loss: 631.0045\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.5150 - val_loss: 630.4620\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.9803 - val_loss: 629.9136\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.4413 - val_loss: 629.3997\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.8979 - val_loss: 628.8615\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.3501 - val_loss: 628.2622\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.7977 - val_loss: 627.7428\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.2410 - val_loss: 627.2005\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.6799 - val_loss: 626.6796\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.1143 - val_loss: 626.1135\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 655.5443 - val_loss: 625.4855\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.9700 - val_loss: 624.8932\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.3913 - val_loss: 624.2531\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 653.8083 - val_loss: 623.6366\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 653.2209 - val_loss: 623.0067\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.6292 - val_loss: 622.3594\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.0332 - val_loss: 621.7525\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 651.4327 - val_loss: 621.1328\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 650.8281 - val_loss: 620.5310\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.2192 - val_loss: 619.8757\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.6059 - val_loss: 619.2100\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.9885 - val_loss: 618.6044\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.3666 - val_loss: 617.9914\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.7406 - val_loss: 617.3478\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.1104 - val_loss: 616.7719\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 646.4759 - val_loss: 616.1123\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.8372 - val_loss: 615.5031\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.1942 - val_loss: 614.8518\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 644.5472 - val_loss: 614.2475\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.8960 - val_loss: 613.5678\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.2405 - val_loss: 612.9525\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 642.5809 - val_loss: 612.3203\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.9172 - val_loss: 611.6992\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.2493 - val_loss: 610.9767\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.5773 - val_loss: 610.3093\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 639.9012 - val_loss: 609.6347\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 639.2209 - val_loss: 608.9412\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.5365 - val_loss: 608.2527\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.8481 - val_loss: 607.5859\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.1555 - val_loss: 606.9271\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.4589 - val_loss: 606.1872\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.7582 - val_loss: 605.4281\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.0535 - val_loss: 604.6982\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.3447 - val_loss: 603.9048\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.6319 - val_loss: 603.1884\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.9152 - val_loss: 602.4657\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.1943 - val_loss: 601.6530\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.4694 - val_loss: 600.9076\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.7407 - val_loss: 600.1849\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.0078 - val_loss: 599.4675\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.2710 - val_loss: 598.7361\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.5303 - val_loss: 597.9820\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.7856 - val_loss: 597.1935\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.0370 - val_loss: 596.4401\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.2843 - val_loss: 595.6893\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.5279 - val_loss: 594.8914\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.7675 - val_loss: 594.0579\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.0031 - val_loss: 593.2938\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.2349 - val_loss: 592.4725\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.4628 - val_loss: 591.6243\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.6868 - val_loss: 590.8133\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.9069 - val_loss: 590.0240\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.1230 - val_loss: 589.2124\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.3355 - val_loss: 588.4525\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.5441 - val_loss: 587.7422\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 617.7487 - val_loss: 587.0001\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.9496 - val_loss: 586.2767\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.1468 - val_loss: 585.5836\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.3401 - val_loss: 584.7427\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.5296 - val_loss: 583.9288\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.7152 - val_loss: 583.1412\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.8971 - val_loss: 582.2786\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.0752 - val_loss: 581.3843\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 611.2495 - val_loss: 580.5150\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 610.4202 - val_loss: 579.6777\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 609.5869 - val_loss: 578.7988\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 608.7501 - val_loss: 577.9368\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.9094 - val_loss: 577.1431\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.0651 - val_loss: 576.2958\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.2170 - val_loss: 575.3843\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 605.3651 - val_loss: 574.5165\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.5097 - val_loss: 573.7546\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.6506 - val_loss: 572.8813\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.7876 - val_loss: 572.0178\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 601.9211 - val_loss: 571.1974\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 601.0509 - val_loss: 570.3339\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.1770 - val_loss: 569.3672\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.2995 - val_loss: 568.4658\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.4183 - val_loss: 567.6011\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.5334 - val_loss: 566.7456\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.6450 - val_loss: 565.8950\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.7542 - val_loss: 565.4921\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.8608 - val_loss: 565.5984\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.9638 - val_loss: 565.1694\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.0618 - val_loss: 564.4100\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.1558 - val_loss: 563.5646\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.2458 - val_loss: 562.6545\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.3322 - val_loss: 561.6451\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.4149 - val_loss: 560.6411\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.4941 - val_loss: 559.6453\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.5698 - val_loss: 558.6262\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 586.6418 - val_loss: 557.6367\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.7103 - val_loss: 556.6436\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.7753 - val_loss: 555.6268\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 583.8367 - val_loss: 554.6662\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.8947 - val_loss: 553.7133\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.9492 - val_loss: 552.7428\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.0001 - val_loss: 551.7668\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.0475 - val_loss: 550.8336\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 579.0915 - val_loss: 549.8674\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 578.1320 - val_loss: 548.8654\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.1689 - val_loss: 547.8931\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.2025 - val_loss: 546.9351\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.2325 - val_loss: 545.9823\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.2592 - val_loss: 544.9915\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 573.2823 - val_loss: 544.0097\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.3693 - val_loss: 543.4553\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.3227 - val_loss: 542.7128\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.3374 - val_loss: 541.7866\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.3475 - val_loss: 540.8112\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.3539 - val_loss: 539.7692\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.3566 - val_loss: 538.7621\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.3558 - val_loss: 537.7568\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.3516 - val_loss: 536.8347\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.3439 - val_loss: 535.7950\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.3329 - val_loss: 534.7756\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.3185 - val_loss: 533.7978\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.3008 - val_loss: 532.7440\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.2797 - val_loss: 531.7762\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.2552 - val_loss: 530.7984\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.2273 - val_loss: 529.7812\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 557.1961 - val_loss: 528.7570\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.1617 - val_loss: 527.7201\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.1238 - val_loss: 526.7238\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.0826 - val_loss: 525.7077\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.0381 - val_loss: 524.7131\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.0029 - val_loss: 523.9301\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.9426 - val_loss: 523.5474\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.9653 - val_loss: 523.6998\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.8390 - val_loss: 523.2664\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.7801 - val_loss: 522.3419\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.7167 - val_loss: 521.2388\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.6494 - val_loss: 520.0460\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.5786 - val_loss: 519.0121\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.5044 - val_loss: 517.9432\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.4269 - val_loss: 516.8925\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.3461 - val_loss: 515.7099\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.2621 - val_loss: 514.6677\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.1749 - val_loss: 513.5967\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.0845 - val_loss: 512.5093\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 602.5551\n",
      "--- Starting trial: run-1\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 16, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6625 - val_loss: 660.0745\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4340 - val_loss: 659.8464\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2004 - val_loss: 659.6068\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9579 - val_loss: 659.3530\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7022 - val_loss: 659.0825\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4288 - val_loss: 658.7959\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1330 - val_loss: 658.4761\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8090 - val_loss: 658.1268\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.4508 - val_loss: 657.7295\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0513 - val_loss: 657.2849\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.6023 - val_loss: 656.7964\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.0945 - val_loss: 656.2429\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.5168 - val_loss: 655.5993\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.8570 - val_loss: 654.8622\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.0999 - val_loss: 654.0281\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.2286 - val_loss: 653.0649\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.2229 - val_loss: 651.9576\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.0593 - val_loss: 650.6720\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.7101 - val_loss: 649.1781\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.1434 - val_loss: 647.4170\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.3212 - val_loss: 645.4081\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.1993 - val_loss: 643.0449\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 671.7258 - val_loss: 640.3044\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.8400 - val_loss: 637.0883\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.4706 - val_loss: 633.3676\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.5339 - val_loss: 628.9758\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.9321 - val_loss: 623.8703\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.5504 - val_loss: 617.8994\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.2540 - val_loss: 610.8885\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.8850 - val_loss: 602.6907\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.2582 - val_loss: 593.1348\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 619.1567 - val_loss: 581.9893\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.3260 - val_loss: 568.9495\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.4674 - val_loss: 553.8859\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.3221 - val_loss: 537.0327\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.7462 - val_loss: 518.5983\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 537.5317 - val_loss: 498.8212\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.9186 - val_loss: 475.1027\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 487.4995 - val_loss: 448.4379\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 459.0469 - val_loss: 422.3755\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 433.2842 - val_loss: 399.0478\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.0834 - val_loss: 379.3931\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 392.3538 - val_loss: 361.7589\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.0519 - val_loss: 336.6555\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 352.0186 - val_loss: 320.5729\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 330.5017 - val_loss: 299.1333\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.7662 - val_loss: 268.7778\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.6971 - val_loss: 249.5965\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.6624 - val_loss: 234.9998\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 223.9937 - val_loss: 191.3861\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.8671 - val_loss: 173.5192\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 175.0962 - val_loss: 237.7320\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 137.8142 - val_loss: 285.2977\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.1647 - val_loss: 272.0216\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.0323 - val_loss: 328.9122\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.9620 - val_loss: 126.5753\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.0433 - val_loss: 253.7106\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.8060 - val_loss: 298.2093\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.5595 - val_loss: 278.3860\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.3668 - val_loss: 260.8446\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.6441 - val_loss: 180.4785\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.7678 - val_loss: 244.9955\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.0570 - val_loss: 223.5703\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.5758 - val_loss: 208.6336\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.4493 - val_loss: 206.8200\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.7068 - val_loss: 278.2694\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.2102 - val_loss: 243.1551\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.3882 - val_loss: 198.9616\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.5555 - val_loss: 176.9402\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.0566 - val_loss: 122.3336\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.1489 - val_loss: 202.2220\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1219 - val_loss: 106.8981\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.1958 - val_loss: 206.2789\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4449 - val_loss: 122.3772\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.5666 - val_loss: 174.2261\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8728 - val_loss: 124.4960\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3166 - val_loss: 95.8802\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.0220 - val_loss: 130.3502\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4969 - val_loss: 125.1052\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.8565 - val_loss: 103.2900\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 74.9399 - val_loss: 133.1932\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.4421 - val_loss: 132.9004\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 135.0976 - val_loss: 99.6075\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.1087 - val_loss: 76.6623\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.8411 - val_loss: 80.9815\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.9977 - val_loss: 71.8987\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.1757 - val_loss: 84.5012\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.9612 - val_loss: 92.3804\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.9667 - val_loss: 123.7020\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6709 - val_loss: 100.9369\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4923 - val_loss: 92.2185\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.8064 - val_loss: 100.5148\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 66.1685 - val_loss: 70.1466\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.3316 - val_loss: 104.0256\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.0808 - val_loss: 73.2959\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.3130 - val_loss: 98.4481\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.1203 - val_loss: 72.7294\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4401 - val_loss: 75.4159\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.9076 - val_loss: 84.1385\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.2158 - val_loss: 69.8278\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.6653 - val_loss: 86.4150\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.2410 - val_loss: 97.7267\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.7360 - val_loss: 69.8654\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.2507 - val_loss: 82.9130\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.5018 - val_loss: 78.5864\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.2764 - val_loss: 78.7376\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.1285 - val_loss: 106.0637\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.6462 - val_loss: 106.0682\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1413 - val_loss: 95.0443\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.8973 - val_loss: 92.3198\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.1068 - val_loss: 81.7946\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.4786 - val_loss: 82.9690\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.6627 - val_loss: 82.7684\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1855 - val_loss: 69.8142\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.9683 - val_loss: 74.3279\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.5168 - val_loss: 67.7345\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.3638 - val_loss: 69.3844\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.4350 - val_loss: 90.6665\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.0609 - val_loss: 90.2043\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.3036 - val_loss: 78.6869\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.2295 - val_loss: 79.2784\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.9922 - val_loss: 69.2974\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.6876 - val_loss: 82.1188\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8741 - val_loss: 79.8962\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.1563 - val_loss: 69.2382\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5269 - val_loss: 105.3075\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6659 - val_loss: 77.4788\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8524 - val_loss: 67.3013\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4938 - val_loss: 71.5321\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0074 - val_loss: 67.5021\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.7836 - val_loss: 73.1898\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.6508 - val_loss: 101.0680\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8107 - val_loss: 72.9991\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.2951 - val_loss: 72.3223\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2118 - val_loss: 80.9747\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.4000 - val_loss: 72.5532\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.0302 - val_loss: 65.6021\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8048 - val_loss: 66.2789\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1428 - val_loss: 64.5964\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7726 - val_loss: 69.6026\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1900 - val_loss: 67.6254\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0327 - val_loss: 70.1056\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.9150 - val_loss: 68.2845\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1485 - val_loss: 69.8110\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.0811 - val_loss: 103.1702\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9529 - val_loss: 76.8366\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.6994 - val_loss: 70.9860\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9146 - val_loss: 79.2006\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.1492 - val_loss: 86.5052\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 120.2836 - val_loss: 85.2903\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.1005 - val_loss: 67.7720\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.1826 - val_loss: 67.3163\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.4017 - val_loss: 65.9731\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0263 - val_loss: 74.2960\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.3055 - val_loss: 71.8745\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.9833 - val_loss: 76.1571\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.7704 - val_loss: 85.7488\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.6676 - val_loss: 75.3197\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.6614 - val_loss: 70.1891\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.0067 - val_loss: 66.4354\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6100 - val_loss: 70.9534\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.9346 - val_loss: 70.7727\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.5605 - val_loss: 65.0535\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.7773 - val_loss: 65.9469\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.9780 - val_loss: 73.6720\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.6736 - val_loss: 68.4960\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.6250 - val_loss: 66.2070\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.1050 - val_loss: 67.7135\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.0228 - val_loss: 70.4703\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.4625 - val_loss: 68.2736\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.8163 - val_loss: 65.8322\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.1424 - val_loss: 61.0529\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.6837 - val_loss: 69.2997\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.3022 - val_loss: 68.5042\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.1219 - val_loss: 64.9486\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.2267 - val_loss: 70.1918\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.7541 - val_loss: 66.3048\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.2212 - val_loss: 63.2336\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8160 - val_loss: 63.2347\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6669 - val_loss: 67.0907\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.3319 - val_loss: 67.3484\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.8904 - val_loss: 70.8453\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8307 - val_loss: 73.9587\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1584 - val_loss: 69.3680\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.5060 - val_loss: 66.9322\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.2273 - val_loss: 85.6199\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.2692 - val_loss: 69.9357\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.8850 - val_loss: 71.8149\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.0872 - val_loss: 79.5124\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.3675 - val_loss: 66.2359\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0359 - val_loss: 62.0457\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.6893 - val_loss: 63.6339\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 131.3037 - val_loss: 77.8249\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.4169 - val_loss: 68.7118\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 102.0450 - val_loss: 65.1376\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5184 - val_loss: 67.1584\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.6325 - val_loss: 78.3598\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3298 - val_loss: 71.2698\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5028 - val_loss: 79.5721\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.8578 - val_loss: 67.3195\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.3898 - val_loss: 70.0644\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9920 - val_loss: 70.3739\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3709 - val_loss: 69.7771\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7131 - val_loss: 76.6503\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6603 - val_loss: 80.5624\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5195 - val_loss: 68.0461\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.5259 - val_loss: 70.1233\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7972 - val_loss: 71.7700\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3860 - val_loss: 76.6304\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4094 - val_loss: 73.1952\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.0385 - val_loss: 75.9836\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0893 - val_loss: 69.6906\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.1712 - val_loss: 71.8598\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.4048 - val_loss: 68.6079\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1825 - val_loss: 66.7194\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8126 - val_loss: 69.0685\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2738 - val_loss: 69.5367\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9691 - val_loss: 72.4312\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.4016 - val_loss: 82.2406\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.5125 - val_loss: 82.9764\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3889 - val_loss: 73.1164\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5773 - val_loss: 68.2579\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.3282 - val_loss: 74.5388\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8159 - val_loss: 67.1457\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.0107 - val_loss: 67.0284\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1812 - val_loss: 67.2421\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4475 - val_loss: 65.5908\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.0438 - val_loss: 71.4941\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.1300 - val_loss: 66.7649\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4514 - val_loss: 66.5021\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3918 - val_loss: 70.7625\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 98.7496 - val_loss: 68.7694\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.0438 - val_loss: 63.9304\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9189 - val_loss: 71.9292\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0356 - val_loss: 69.9531\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8409 - val_loss: 68.9076\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9881 - val_loss: 62.1230\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.2769 - val_loss: 68.3246\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.2199 - val_loss: 64.7803\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2418 - val_loss: 74.2537\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2353 - val_loss: 76.9480\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7528 - val_loss: 64.6296\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.6456 - val_loss: 64.0430\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5558 - val_loss: 65.1303\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4225 - val_loss: 66.5554\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.0131 - val_loss: 67.7980\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.3085 - val_loss: 79.5338\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.6399 - val_loss: 69.8981\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9941 - val_loss: 74.3260\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.3390 - val_loss: 68.6213\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49.7666\n",
      "--- Starting trial: run-2\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 16, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.7314 - val_loss: 660.7661\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6771 - val_loss: 660.6869\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6205 - val_loss: 660.6014\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5608 - val_loss: 660.5138\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4977 - val_loss: 660.4330\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4310 - val_loss: 660.3521\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3604 - val_loss: 660.2650\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2856 - val_loss: 660.1812\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2066 - val_loss: 660.0843\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1232 - val_loss: 659.9780\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.0353 - val_loss: 659.8735\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.9429 - val_loss: 659.7627\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.8458 - val_loss: 659.6563\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.7439 - val_loss: 659.5322\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.6374 - val_loss: 659.4099\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.5261 - val_loss: 659.2919\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.4099 - val_loss: 659.1650\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.2886 - val_loss: 659.0362\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1626 - val_loss: 658.9007\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0316 - val_loss: 658.7625\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8957 - val_loss: 658.6062\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7548 - val_loss: 658.4512\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6087 - val_loss: 658.3011\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.4578 - val_loss: 658.1461\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3017 - val_loss: 657.9700\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.1406 - val_loss: 657.8060\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.9744 - val_loss: 657.6132\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.8030 - val_loss: 657.4392\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.6267 - val_loss: 657.2537\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.4452 - val_loss: 657.0740\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.2587 - val_loss: 656.8815\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.0670 - val_loss: 656.6610\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.8702 - val_loss: 656.4208\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.6683 - val_loss: 656.2108\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.4614 - val_loss: 656.0125\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.2493 - val_loss: 655.7860\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.0320 - val_loss: 655.5548\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.8097 - val_loss: 655.3165\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.5823 - val_loss: 655.0772\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.3497 - val_loss: 654.8467\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.1121 - val_loss: 654.6138\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.8693 - val_loss: 654.3487\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.6215 - val_loss: 654.0897\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.3686 - val_loss: 653.8188\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.1107 - val_loss: 653.5420\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.8475 - val_loss: 653.2429\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.5794 - val_loss: 652.9559\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 682.3063 - val_loss: 652.6856\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.0280 - val_loss: 652.3994\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.7446 - val_loss: 652.1030\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.4564 - val_loss: 651.8087\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.1629 - val_loss: 651.5060\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.8646 - val_loss: 651.2245\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.5612 - val_loss: 650.9323\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.2528 - val_loss: 650.6229\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.9394 - val_loss: 650.2935\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.6209 - val_loss: 649.9704\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.2975 - val_loss: 649.6372\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.9692 - val_loss: 649.2634\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.6359 - val_loss: 648.9213\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.2977 - val_loss: 648.5505\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.9545 - val_loss: 648.2153\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.6063 - val_loss: 647.8865\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.2533 - val_loss: 647.5992\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.8953 - val_loss: 647.2892\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.5326 - val_loss: 646.9337\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.1649 - val_loss: 646.5801\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.7922 - val_loss: 646.2150\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.4147 - val_loss: 645.8463\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.0325 - val_loss: 645.4269\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6454 - val_loss: 645.0500\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.2534 - val_loss: 644.5850\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.8564 - val_loss: 644.1436\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.4550 - val_loss: 643.7236\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.0485 - val_loss: 643.3068\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.6373 - val_loss: 642.9373\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 672.2214 - val_loss: 642.6299\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.8007 - val_loss: 642.2806\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.3752 - val_loss: 641.8720\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.9450 - val_loss: 641.4453\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.5101 - val_loss: 641.0284\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.0704 - val_loss: 640.5853\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.6259 - val_loss: 640.1786\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.1769 - val_loss: 639.8151\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.7231 - val_loss: 639.3727\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.2648 - val_loss: 638.8856\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.8017 - val_loss: 638.3865\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.3340 - val_loss: 637.8635\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.8617 - val_loss: 637.3304\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.3846 - val_loss: 636.9216\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.9031 - val_loss: 636.4670\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.4169 - val_loss: 635.9323\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.9261 - val_loss: 635.3305\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.4308 - val_loss: 634.7270\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.9308 - val_loss: 634.1389\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.4264 - val_loss: 633.5665\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.9174 - val_loss: 632.9932\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.4039 - val_loss: 632.4781\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.8857 - val_loss: 631.8942\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.3632 - val_loss: 631.3824\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.8361 - val_loss: 630.7853\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.3046 - val_loss: 630.2507\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.7685 - val_loss: 629.6898\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.2280 - val_loss: 629.2109\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.6831 - val_loss: 628.6958\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.1337 - val_loss: 628.1749\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.5798 - val_loss: 627.6583\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.0216 - val_loss: 627.0602\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.4590 - val_loss: 626.3497\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 655.8920 - val_loss: 625.7396\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 655.3205 - val_loss: 625.1229\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.7446 - val_loss: 624.5117\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 654.1646 - val_loss: 623.8435\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 653.5801 - val_loss: 623.2907\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.9913 - val_loss: 622.6874\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.3981 - val_loss: 622.0139\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.8005 - val_loss: 621.3808\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.1988 - val_loss: 620.7453\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 650.5926 - val_loss: 620.1987\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.9823 - val_loss: 619.6108\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.3676 - val_loss: 619.0395\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.7487 - val_loss: 618.4304\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.1255 - val_loss: 617.6838\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.4980 - val_loss: 617.0071\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 646.8664 - val_loss: 616.3417\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 646.2305 - val_loss: 615.7135\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.5904 - val_loss: 615.0703\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.9462 - val_loss: 614.3880\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 644.2977 - val_loss: 613.7171\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.6450 - val_loss: 613.1514\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.9882 - val_loss: 612.5729\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.3272 - val_loss: 611.8095\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.6620 - val_loss: 611.2158\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.9929 - val_loss: 610.6031\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.3195 - val_loss: 609.9319\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 639.6420 - val_loss: 609.2349\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.9602 - val_loss: 608.5209\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.2746 - val_loss: 607.7289\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.5847 - val_loss: 606.8744\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.8908 - val_loss: 606.1307\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.1929 - val_loss: 605.3760\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.4908 - val_loss: 604.6511\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.7848 - val_loss: 603.9407\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.0746 - val_loss: 603.3102\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.3605 - val_loss: 602.6136\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.6423 - val_loss: 601.8190\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.9202 - val_loss: 601.0368\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.1940 - val_loss: 600.4128\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.4639 - val_loss: 599.7627\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.7297 - val_loss: 599.0892\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.9916 - val_loss: 598.4883\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.2495 - val_loss: 597.9171\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.5035 - val_loss: 597.3853\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.7535 - val_loss: 596.8570\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.9997 - val_loss: 596.1565\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.2418 - val_loss: 595.3057\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 624.4800 - val_loss: 594.4981\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 623.7144 - val_loss: 593.5419\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.9448 - val_loss: 592.6149\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.1714 - val_loss: 591.7100\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.3941 - val_loss: 590.8634\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 620.6129 - val_loss: 589.9802\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 619.8279 - val_loss: 589.0867\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 619.0390 - val_loss: 588.2775\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 618.2462 - val_loss: 587.3064\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.4496 - val_loss: 586.5506\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.6492 - val_loss: 585.7750\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 615.8450 - val_loss: 584.9387\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 615.0369 - val_loss: 584.0518\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 614.2251 - val_loss: 583.1183\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 613.4095 - val_loss: 582.2302\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.5901 - val_loss: 581.5095\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 611.7669 - val_loss: 580.7629\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.9399 - val_loss: 580.0077\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.1093 - val_loss: 579.2197\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.2748 - val_loss: 578.3148\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.4366 - val_loss: 577.3652\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.5947 - val_loss: 576.5359\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.7490 - val_loss: 575.7133\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.8997 - val_loss: 574.8362\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.0464 - val_loss: 574.0579\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 604.1898 - val_loss: 573.0017\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.3293 - val_loss: 572.1506\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.4651 - val_loss: 571.3578\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 601.5973 - val_loss: 570.5269\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.7258 - val_loss: 569.7064\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.8506 - val_loss: 568.8313\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.9718 - val_loss: 568.0182\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.0895 - val_loss: 567.2979\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.2033 - val_loss: 566.3881\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.3136 - val_loss: 565.2937\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.4203 - val_loss: 564.1790\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.5233 - val_loss: 563.2496\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.6227 - val_loss: 562.2205\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.7186 - val_loss: 561.1129\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.8109 - val_loss: 560.1595\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.8995 - val_loss: 559.2081\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.9846 - val_loss: 558.3893\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 589.0661 - val_loss: 557.5955\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.1441 - val_loss: 556.7780\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.2185 - val_loss: 556.0368\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.2894 - val_loss: 555.3344\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.3567 - val_loss: 554.5369\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.4205 - val_loss: 553.6394\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.4808 - val_loss: 552.6032\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.5375 - val_loss: 551.7859\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.6412 - val_loss: 550.3752\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.6436 - val_loss: 549.4601\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.6924 - val_loss: 548.8510\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.7363 - val_loss: 548.1382\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.7759 - val_loss: 547.3474\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.8118 - val_loss: 546.5038\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.8442 - val_loss: 545.6761\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.8730 - val_loss: 544.7236\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 573.8984 - val_loss: 543.7830\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.9203 - val_loss: 542.8342\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.9387 - val_loss: 541.8864\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.9537 - val_loss: 540.8875\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.9653 - val_loss: 539.9323\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.9734 - val_loss: 538.9604\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.9781 - val_loss: 537.9757\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.9796 - val_loss: 537.0195\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.9775 - val_loss: 536.0356\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.9721 - val_loss: 535.0042\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 564.0076 - val_loss: 534.5634\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 562.9559 - val_loss: 534.7028\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.9418 - val_loss: 534.1796\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.9235 - val_loss: 533.2548\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 559.9014 - val_loss: 532.1584\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.8757 - val_loss: 530.9232\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.8467 - val_loss: 529.7772\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.8142 - val_loss: 528.6647\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.7784 - val_loss: 527.5715\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.7393 - val_loss: 526.4966\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.6968 - val_loss: 525.4771\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.6511 - val_loss: 524.4163\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.7212 - val_loss: 522.5332\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.5537 - val_loss: 520.6328\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.5001 - val_loss: 519.2958\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.5578 - val_loss: 519.8831\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.4041 - val_loss: 519.8221\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.3311 - val_loss: 519.0163\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.2879 - val_loss: 518.0917\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.2086 - val_loss: 515.0568\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.1318 - val_loss: 513.3505\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.0560 - val_loss: 511.9556\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.9751 - val_loss: 510.8706\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 539.8901 - val_loss: 510.1521\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 538.8016 - val_loss: 509.3855\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.7819 - val_loss: 507.7289\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 600.5554\n",
      "--- Starting trial: run-3\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 16, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 44ms/step - loss: 689.6551 - val_loss: 659.7912\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4081 - val_loss: 659.5828\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1553 - val_loss: 659.3640\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8925 - val_loss: 659.1263\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.6147 - val_loss: 658.8617\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 688.3172 - val_loss: 658.5743\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9943 - val_loss: 658.2495\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6398 - val_loss: 657.8920\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2468 - val_loss: 657.4914\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.8071 - val_loss: 657.0359\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.3120 - val_loss: 656.5060\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.7506 - val_loss: 655.9272\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1107 - val_loss: 655.2418\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3781 - val_loss: 654.4507\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.5364 - val_loss: 653.5446\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.5660 - val_loss: 652.4864\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.4443 - val_loss: 651.2552\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.1451 - val_loss: 649.8323\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.6371 - val_loss: 648.1764\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.8842 - val_loss: 646.2588\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 674.8438 - val_loss: 644.0237\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.4663 - val_loss: 641.4211\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.6931 - val_loss: 638.3574\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 666.4560 - val_loss: 634.7975\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 662.6746 - val_loss: 630.6429\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.2550 - val_loss: 625.7770\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.0872 - val_loss: 620.0961\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.0415 - val_loss: 613.4188\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.9667 - val_loss: 605.6650\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.6852 - val_loss: 596.5185\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.9883 - val_loss: 585.8253\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.6321 - val_loss: 573.3349\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.3301 - val_loss: 558.6678\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.7463 - val_loss: 541.6703\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.5674 - val_loss: 525.7239\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.2659 - val_loss: 504.5145\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.6406 - val_loss: 483.6604\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.3266 - val_loss: 461.7985\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.1485 - val_loss: 433.7589\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.6185 - val_loss: 431.5497\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.7391 - val_loss: 424.8722\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 402.9901 - val_loss: 423.6665\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.5377 - val_loss: 440.4154\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368.8393 - val_loss: 434.0931\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.5418 - val_loss: 414.3485\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.5775 - val_loss: 366.7195\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 308.4773 - val_loss: 366.3678\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 285.5809 - val_loss: 331.8281\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.8838 - val_loss: 289.6578\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.0767 - val_loss: 263.5459\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 204.7487 - val_loss: 223.8697\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 165.4137 - val_loss: 155.3670\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 163.1546 - val_loss: 143.8866\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130.4483 - val_loss: 155.0994\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.2950 - val_loss: 150.7349\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.0224 - val_loss: 181.1919\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.9784 - val_loss: 239.4485\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.9915 - val_loss: 267.7809\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.8024 - val_loss: 286.0659\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.7714 - val_loss: 141.4451\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 149.1307 - val_loss: 206.7173\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4049 - val_loss: 214.6448\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1381 - val_loss: 206.0315\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5066 - val_loss: 189.6906\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7785 - val_loss: 179.7195\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9717 - val_loss: 183.2773\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.0919 - val_loss: 143.9992\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.8726 - val_loss: 185.1153\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9190 - val_loss: 139.5212\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2972 - val_loss: 131.8430\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.9064 - val_loss: 115.0096\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.4131 - val_loss: 94.9414\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.3389 - val_loss: 89.9993\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8005 - val_loss: 84.8912\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.9750 - val_loss: 104.1241\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.2844 - val_loss: 91.9494\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8560 - val_loss: 91.4616\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.9262 - val_loss: 85.0944\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 89.4428 - val_loss: 120.0088\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 106.5593 - val_loss: 124.3442\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.6716 - val_loss: 93.9617\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4902 - val_loss: 68.7311\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.5436 - val_loss: 84.0225\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.4140 - val_loss: 98.0876\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.7712 - val_loss: 64.7708\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.3207 - val_loss: 67.7587\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.9598 - val_loss: 90.0824\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3339 - val_loss: 79.3464\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5491 - val_loss: 74.5657\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.4258 - val_loss: 71.8847\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.4743 - val_loss: 70.9804\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.9720 - val_loss: 64.3557\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8408 - val_loss: 66.4776\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.3908 - val_loss: 86.3086\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.3555 - val_loss: 65.9673\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.2515 - val_loss: 79.5794\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.2119 - val_loss: 70.8518\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.1979 - val_loss: 86.2010\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3059 - val_loss: 69.6087\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.8965 - val_loss: 63.7228\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3440 - val_loss: 73.4887\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.4921 - val_loss: 81.2581\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.3129 - val_loss: 63.8562\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.6244 - val_loss: 76.4666\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.9726 - val_loss: 75.2234\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.4793 - val_loss: 70.2337\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 130.4626 - val_loss: 82.8159\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.3773 - val_loss: 85.9306\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.8338 - val_loss: 63.2238\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4251 - val_loss: 68.5108\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4958 - val_loss: 66.2606\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7890 - val_loss: 120.0518\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.5253 - val_loss: 65.7412\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.3086 - val_loss: 66.8780\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.7403 - val_loss: 69.6612\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4505 - val_loss: 77.6390\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9758 - val_loss: 65.3587\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1068 - val_loss: 68.2469\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6427 - val_loss: 71.6320\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.4078 - val_loss: 90.2847\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8577 - val_loss: 73.0582\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.6796 - val_loss: 74.6001\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.3285 - val_loss: 65.5041\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.6001 - val_loss: 75.6782\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.8889 - val_loss: 77.9783\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3521 - val_loss: 102.0868\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.1880 - val_loss: 73.8630\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.9360 - val_loss: 69.2549\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.1293 - val_loss: 70.4098\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.6834 - val_loss: 82.1726\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.2171 - val_loss: 68.8356\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.5440 - val_loss: 66.4048\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.1961 - val_loss: 72.1696\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2228 - val_loss: 72.7335\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9767 - val_loss: 74.2249\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.6026 - val_loss: 64.8260\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.9476 - val_loss: 63.7116\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.7496 - val_loss: 63.6132\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6237 - val_loss: 73.4809\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.8406 - val_loss: 70.3228\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.5336 - val_loss: 70.5647\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0757 - val_loss: 66.5663\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0046 - val_loss: 67.8999\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.1403 - val_loss: 72.9644\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.1368 - val_loss: 68.5195\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.6478 - val_loss: 68.5218\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.1706 - val_loss: 67.2504\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 122.7530 - val_loss: 69.4671\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6199 - val_loss: 65.9162\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 129.7766 - val_loss: 70.5078\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.4578 - val_loss: 76.9982\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4204 - val_loss: 76.0738\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.8956 - val_loss: 83.3179\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7723 - val_loss: 77.0710\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.5412 - val_loss: 73.5454\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7200 - val_loss: 75.0921\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.7854 - val_loss: 83.4158\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.9238 - val_loss: 64.2557\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4405 - val_loss: 66.3447\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.1172 - val_loss: 65.6271\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.8691 - val_loss: 67.9760\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.9482 - val_loss: 79.0358\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.1271 - val_loss: 72.6243\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6571 - val_loss: 64.2028\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4611 - val_loss: 64.4643\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.8095 - val_loss: 66.9350\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.5338 - val_loss: 61.9781\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.3064 - val_loss: 76.1760\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.6522 - val_loss: 75.7921\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1961 - val_loss: 71.7934\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6595 - val_loss: 71.6152\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.4169 - val_loss: 68.4703\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.9825 - val_loss: 91.5755\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0161 - val_loss: 76.4938\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.7918 - val_loss: 68.7774\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.1466 - val_loss: 61.1422\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.4518 - val_loss: 67.7574\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.6178 - val_loss: 85.5232\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.3473 - val_loss: 66.5163\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8605 - val_loss: 60.8911\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7280 - val_loss: 60.8865\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4126 - val_loss: 74.6086\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6121 - val_loss: 68.6161\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3793 - val_loss: 60.3706\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.6459 - val_loss: 69.7517\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.0080 - val_loss: 74.4370\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8443 - val_loss: 68.6837\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.8819 - val_loss: 74.3325\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8699 - val_loss: 65.7288\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5215 - val_loss: 61.0416\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3365 - val_loss: 67.1417\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5009 - val_loss: 82.7657\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0061 - val_loss: 68.3133\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.4531 - val_loss: 62.7209\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2541 - val_loss: 66.5345\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4290 - val_loss: 60.1226\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3040 - val_loss: 62.0792\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0616 - val_loss: 74.9381\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1447 - val_loss: 61.9333\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0729 - val_loss: 64.7040\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3195 - val_loss: 62.1349\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6306 - val_loss: 70.1563\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.2958 - val_loss: 66.4782\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.6007 - val_loss: 65.3436\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.5372 - val_loss: 64.3023\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4798 - val_loss: 65.9224\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9944 - val_loss: 72.2957\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 80.1273 - val_loss: 73.1197\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.5217 - val_loss: 63.2212\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6849 - val_loss: 89.9140\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8256 - val_loss: 69.4723\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3876 - val_loss: 63.0033\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5672 - val_loss: 68.6482\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1353 - val_loss: 66.6376\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1100 - val_loss: 82.6974\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.3455 - val_loss: 76.6778\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1917 - val_loss: 77.9785\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.8386 - val_loss: 78.5047\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.7677 - val_loss: 76.9167\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9835 - val_loss: 67.1323\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4892 - val_loss: 62.9447\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3796 - val_loss: 61.1201\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7595 - val_loss: 69.0865\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.1875 - val_loss: 64.8744\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4842 - val_loss: 74.3245\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6576 - val_loss: 65.5592\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8225 - val_loss: 68.3810\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2617 - val_loss: 67.2998\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0457 - val_loss: 70.0323\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4357 - val_loss: 68.8652\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 75.0073 - val_loss: 68.3851\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.8006 - val_loss: 75.3310\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3797 - val_loss: 78.5143\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.4845 - val_loss: 76.8656\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0436 - val_loss: 61.7267\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8216 - val_loss: 79.9426\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.1894 - val_loss: 83.0436\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8251 - val_loss: 77.2665\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5535 - val_loss: 64.9737\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7409 - val_loss: 64.3481\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1248 - val_loss: 68.6552\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.4030 - val_loss: 74.6462\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6478 - val_loss: 60.5640\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.1139 - val_loss: 69.0388\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.7512 - val_loss: 65.4637\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.5487 - val_loss: 61.3992\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6891 - val_loss: 65.1093\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2352 - val_loss: 98.0816\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.1211 - val_loss: 72.6170\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.3004 - val_loss: 64.7443\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.9191\n",
      "--- Starting trial: run-4\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 16, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7363 - val_loss: 660.6931\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6942 - val_loss: 660.6436\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.6496 - val_loss: 660.5904\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.6020 - val_loss: 660.5349\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.5511 - val_loss: 660.4734\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4964 - val_loss: 660.4120\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4377 - val_loss: 660.3420\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3748 - val_loss: 660.2677\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3076 - val_loss: 660.1906\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2358 - val_loss: 660.1104\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1593 - val_loss: 660.0206\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0782 - val_loss: 659.9323\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9923 - val_loss: 659.8414\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9015 - val_loss: 659.7416\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8058 - val_loss: 659.6377\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7051 - val_loss: 659.5305\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5994 - val_loss: 659.4181\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4886 - val_loss: 659.3016\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3727 - val_loss: 659.1785\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2517 - val_loss: 659.0545\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1256 - val_loss: 658.9218\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9943 - val_loss: 658.7852\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.8579 - val_loss: 658.6437\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.7162 - val_loss: 658.4954\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5694 - val_loss: 658.3365\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.4174 - val_loss: 658.1863\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2601 - val_loss: 658.0248\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0976 - val_loss: 657.8693\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.9298 - val_loss: 657.6986\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7570 - val_loss: 657.5351\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.5787 - val_loss: 657.3483\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.3952 - val_loss: 657.1585\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.2066 - val_loss: 656.9857\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.0127 - val_loss: 656.7968\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.8136 - val_loss: 656.5964\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.6091 - val_loss: 656.3802\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.3996 - val_loss: 656.1599\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1848 - val_loss: 655.9428\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.9647 - val_loss: 655.7197\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.7396 - val_loss: 655.4915\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.5091 - val_loss: 655.2747\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.2735 - val_loss: 655.0533\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.0327 - val_loss: 654.8088\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.7867 - val_loss: 654.5735\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.5355 - val_loss: 654.3182\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.2792 - val_loss: 654.0555\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.0178 - val_loss: 653.8022\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.7511 - val_loss: 653.5695\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.4794 - val_loss: 653.2914\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.2025 - val_loss: 653.0148\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.9204 - val_loss: 652.7448\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.6334 - val_loss: 652.4650\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.3412 - val_loss: 652.1987\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.0439 - val_loss: 651.9308\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.7415 - val_loss: 651.6240\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.4341 - val_loss: 651.3397\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.1216 - val_loss: 651.0641\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.8041 - val_loss: 650.7482\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.4816 - val_loss: 650.3922\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.1541 - val_loss: 650.0802\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.8215 - val_loss: 649.7798\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.4839 - val_loss: 649.4319\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.1414 - val_loss: 649.1120\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 677.7939 - val_loss: 648.7646\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.4415 - val_loss: 648.4470\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.0841 - val_loss: 648.0859\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.7218 - val_loss: 647.7385\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.3545 - val_loss: 647.3875\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.9824 - val_loss: 647.0220\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.6053 - val_loss: 646.6370\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 675.2234 - val_loss: 646.2643\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.8366 - val_loss: 645.9073\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.4450 - val_loss: 645.4797\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.0484 - val_loss: 645.0901\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.6470 - val_loss: 644.6896\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.2408 - val_loss: 644.2679\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.8300 - val_loss: 643.8417\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.4142 - val_loss: 643.4301\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.9936 - val_loss: 642.9916\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.5683 - val_loss: 642.6171\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.1382 - val_loss: 642.2249\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.7034 - val_loss: 641.7657\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.2638 - val_loss: 641.3445\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.8196 - val_loss: 640.8354\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.3706 - val_loss: 640.3794\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.9169 - val_loss: 639.9374\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.4586 - val_loss: 639.4402\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.9955 - val_loss: 638.9761\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.5278 - val_loss: 638.4390\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.0555 - val_loss: 637.9420\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.5786 - val_loss: 637.4464\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.0969 - val_loss: 636.9158\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.6107 - val_loss: 636.4185\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 665.1199 - val_loss: 635.9130\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.6245 - val_loss: 635.4374\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.1246 - val_loss: 634.9939\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.6200 - val_loss: 634.5524\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.1109 - val_loss: 634.0190\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.5974 - val_loss: 633.5428\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.0792 - val_loss: 633.0541\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.5566 - val_loss: 632.5565\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.0294 - val_loss: 632.0798\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.4978 - val_loss: 631.5218\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.9617 - val_loss: 630.9804\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.4211 - val_loss: 630.3964\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.8761 - val_loss: 629.8180\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.3265 - val_loss: 629.2538\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.7726 - val_loss: 628.6730\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.2143 - val_loss: 628.1042\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.6516 - val_loss: 627.4760\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.0844 - val_loss: 626.8937\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 655.5130 - val_loss: 626.2758\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.9371 - val_loss: 625.6964\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.3568 - val_loss: 625.0701\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.7722 - val_loss: 624.4974\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 653.1833 - val_loss: 623.8885\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.5901 - val_loss: 623.2668\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 651.9925 - val_loss: 622.6367\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 651.3906 - val_loss: 621.9342\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.7844 - val_loss: 621.3455\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.1740 - val_loss: 620.7857\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.5592 - val_loss: 620.2206\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.9402 - val_loss: 619.6393\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.3170 - val_loss: 619.0225\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.6895 - val_loss: 618.4523\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.0578 - val_loss: 617.8428\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 646.4219 - val_loss: 617.1989\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.7818 - val_loss: 616.6086\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.1374 - val_loss: 615.9797\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 644.4888 - val_loss: 615.3145\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.8362 - val_loss: 614.6144\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.1794 - val_loss: 613.9130\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 642.5183 - val_loss: 613.2561\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.8532 - val_loss: 612.5682\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.1840 - val_loss: 611.8979\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.5105 - val_loss: 611.2734\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 639.8329 - val_loss: 610.6222\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 639.1514 - val_loss: 609.9812\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.4658 - val_loss: 609.3182\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.7759 - val_loss: 608.6063\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.0820 - val_loss: 607.9163\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.3841 - val_loss: 607.1652\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.6821 - val_loss: 606.5179\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.9761 - val_loss: 605.8716\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.2661 - val_loss: 605.0891\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.5519 - val_loss: 604.3694\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.8339 - val_loss: 603.7233\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.1118 - val_loss: 603.0209\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.3857 - val_loss: 602.2615\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.6557 - val_loss: 601.5456\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.9216 - val_loss: 600.7758\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.1835 - val_loss: 600.0624\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.4417 - val_loss: 599.2886\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.6957 - val_loss: 598.5469\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.9459 - val_loss: 597.8729\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.1922 - val_loss: 597.1216\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.4345 - val_loss: 596.3420\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.6729 - val_loss: 595.5604\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 623.9074 - val_loss: 594.8362\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.1381 - val_loss: 594.0402\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.3648 - val_loss: 593.2362\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.5876 - val_loss: 592.4451\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.8068 - val_loss: 591.6985\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.0219 - val_loss: 590.8790\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.2331 - val_loss: 590.1230\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.4407 - val_loss: 589.2717\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.6443 - val_loss: 588.3956\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.8442 - val_loss: 587.5873\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.0402 - val_loss: 586.7784\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 615.2324 - val_loss: 586.0876\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.4209 - val_loss: 585.2613\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.6056 - val_loss: 584.4890\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.7864 - val_loss: 583.7397\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 611.9636 - val_loss: 583.0256\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 611.1369 - val_loss: 582.1888\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.3065 - val_loss: 581.3912\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 609.4724 - val_loss: 580.5502\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 608.6345 - val_loss: 579.7003\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.7929 - val_loss: 578.7992\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.9476 - val_loss: 577.8867\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.0986 - val_loss: 577.0758\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 605.2459 - val_loss: 576.2057\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.3895 - val_loss: 575.3250\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.5294 - val_loss: 574.5623\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 602.6657 - val_loss: 573.6424\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.7983 - val_loss: 572.6497\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 600.9272 - val_loss: 571.7507\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 600.0525 - val_loss: 570.8835\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.1741 - val_loss: 569.9526\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.2921 - val_loss: 569.0519\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 597.4064 - val_loss: 568.1475\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 596.5172 - val_loss: 567.2227\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.6243 - val_loss: 566.2252\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.7278 - val_loss: 565.3264\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.8278 - val_loss: 564.3539\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.9241 - val_loss: 563.4367\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.0170 - val_loss: 562.5165\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 591.1887 - val_loss: 562.3920\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.1971 - val_loss: 561.9301\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.2805 - val_loss: 561.1331\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.3596 - val_loss: 560.3836\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.4346 - val_loss: 559.3422\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.5062 - val_loss: 558.4235\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.5740 - val_loss: 557.5263\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.6384 - val_loss: 556.6029\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 583.6991 - val_loss: 555.5339\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.7564 - val_loss: 554.6147\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.8102 - val_loss: 553.6752\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.8605 - val_loss: 552.7285\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 579.9072 - val_loss: 551.8531\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.9505 - val_loss: 550.9002\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.9905 - val_loss: 549.9368\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 577.0268 - val_loss: 548.9464\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.0597 - val_loss: 548.0229\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.0892 - val_loss: 546.9881\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.1152 - val_loss: 546.1201\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.1377 - val_loss: 545.1453\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.1569 - val_loss: 544.2177\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.1726 - val_loss: 543.2032\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.3058 - val_loss: 542.5376\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.1982 - val_loss: 541.6990\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.2056 - val_loss: 540.7768\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.2085 - val_loss: 539.8334\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.2075 - val_loss: 538.8470\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.2029 - val_loss: 537.7952\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.1948 - val_loss: 536.8047\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.1833 - val_loss: 535.7932\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.1683 - val_loss: 534.7165\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.1501 - val_loss: 533.6902\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.1286 - val_loss: 532.6193\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.1036 - val_loss: 531.5890\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 558.1202 - val_loss: 530.7874\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 557.0472 - val_loss: 530.2214\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.0145 - val_loss: 529.4251\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.9772 - val_loss: 528.5838\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.9360 - val_loss: 527.6665\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.8912 - val_loss: 526.5742\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.8430 - val_loss: 525.4888\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.7914 - val_loss: 524.3854\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.7454 - val_loss: 523.5610\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.6827 - val_loss: 522.6825\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.6230 - val_loss: 521.6201\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.5590 - val_loss: 520.5458\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.4913 - val_loss: 519.4343\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.4201 - val_loss: 518.4476\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.3456 - val_loss: 517.3740\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.2679 - val_loss: 516.4670\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.1868 - val_loss: 515.3503\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.1024 - val_loss: 514.3162\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.0150 - val_loss: 513.2524\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 604.0461\n",
      "--- Starting trial: run-5\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 16, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6595 - val_loss: 659.9956\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4235 - val_loss: 659.7525\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1824 - val_loss: 659.5009\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9316 - val_loss: 659.2373\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.6671 - val_loss: 658.9562\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.3840 - val_loss: 658.6518\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.0773 - val_loss: 658.3212\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.7411 - val_loss: 657.9527\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3690 - val_loss: 657.5419\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9534 - val_loss: 657.0867\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4860 - val_loss: 656.5679\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.9565 - val_loss: 655.9795\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.3540 - val_loss: 655.3072\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.6650 - val_loss: 654.5356\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.8740 - val_loss: 653.6505\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.9630 - val_loss: 652.6241\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.9107 - val_loss: 651.4501\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.6927 - val_loss: 650.0899\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.2799 - val_loss: 648.5054\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.6385 - val_loss: 646.6844\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.7289 - val_loss: 644.5384\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.5045 - val_loss: 642.0610\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.9108 - val_loss: 639.1875\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.8842 - val_loss: 635.8255\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.3495 - val_loss: 631.9216\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 660.2193 - val_loss: 627.3464\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.3906 - val_loss: 621.9932\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.7426 - val_loss: 615.7194\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.1341 - val_loss: 608.4576\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 635.3992 - val_loss: 599.8999\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.3436 - val_loss: 589.8824\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 615.7391 - val_loss: 578.1747\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.3184 - val_loss: 564.4336\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.7680 - val_loss: 548.3767\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.7208 - val_loss: 530.1511\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.0981 - val_loss: 511.5500\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.7741 - val_loss: 492.9396\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 507.6906 - val_loss: 472.8622\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 483.0259 - val_loss: 450.4715\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 457.9912 - val_loss: 430.0773\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.7813 - val_loss: 408.9570\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 414.4496 - val_loss: 388.8981\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.7581 - val_loss: 366.6937\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 380.1475 - val_loss: 343.9944\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.4576 - val_loss: 320.6069\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 340.6387 - val_loss: 301.0501\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.8416 - val_loss: 277.6670\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 297.6775 - val_loss: 249.8854\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 276.4103 - val_loss: 223.3022\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 252.3468 - val_loss: 195.7386\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.5392 - val_loss: 176.7687\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.8651 - val_loss: 156.3112\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.6094 - val_loss: 141.8390\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 154.6129 - val_loss: 126.5198\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.4973 - val_loss: 119.2356\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.5673 - val_loss: 102.6385\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.1023 - val_loss: 109.8535\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.7704 - val_loss: 109.7312\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.1798 - val_loss: 99.4383\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.2588 - val_loss: 96.9042\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 132.1801 - val_loss: 99.5984\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.6801 - val_loss: 91.4135\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4578 - val_loss: 106.6645\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.4936 - val_loss: 151.9954\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.2421 - val_loss: 102.8991\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5821 - val_loss: 163.6191\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0927 - val_loss: 112.0009\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.3426 - val_loss: 99.3922\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.2131 - val_loss: 150.5344\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.1702 - val_loss: 111.7742\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.6113 - val_loss: 132.9010\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.2081 - val_loss: 101.5010\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.4179 - val_loss: 91.7896\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.6174 - val_loss: 154.6461\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.3617 - val_loss: 72.5495\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.6082 - val_loss: 98.3363\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.0511 - val_loss: 94.9514\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.7782 - val_loss: 75.9200\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7374 - val_loss: 82.1925\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.0462 - val_loss: 77.3430\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9309 - val_loss: 118.8840\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.8623 - val_loss: 83.8364\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.9263 - val_loss: 177.2536\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.7959 - val_loss: 72.4398\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.5458 - val_loss: 84.0446\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7684 - val_loss: 95.7561\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.4188 - val_loss: 71.0567\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.5877 - val_loss: 65.9694\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1812 - val_loss: 118.7050\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 97.3449 - val_loss: 69.7945\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.6004 - val_loss: 82.4486\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.1051 - val_loss: 72.6046\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2165 - val_loss: 67.8846\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7750 - val_loss: 72.2464\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7311 - val_loss: 92.2213\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.1616 - val_loss: 92.7658\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2893 - val_loss: 118.8835\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5780 - val_loss: 109.6012\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.6025 - val_loss: 95.0173\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.0493 - val_loss: 69.4959\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.7066 - val_loss: 88.4927\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.4732 - val_loss: 76.7844\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.7796 - val_loss: 95.4266\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.6693 - val_loss: 70.0872\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.5275 - val_loss: 80.5794\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.9735 - val_loss: 73.4432\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.5418 - val_loss: 90.4681\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0044 - val_loss: 73.4920\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.5558 - val_loss: 78.7367\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.0649 - val_loss: 76.2263\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.0282 - val_loss: 80.2729\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 74.6416 - val_loss: 120.0619\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.3036 - val_loss: 75.0454\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.3055 - val_loss: 112.5641\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.0337 - val_loss: 102.7044\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.9258 - val_loss: 83.5388\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.9226 - val_loss: 74.4680\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5766 - val_loss: 115.3480\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.9475 - val_loss: 86.6988\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.5880 - val_loss: 103.1955\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.8633 - val_loss: 129.9660\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1277 - val_loss: 78.9085\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.0635 - val_loss: 113.4798\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7541 - val_loss: 76.9592\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5873 - val_loss: 65.7705\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.3907 - val_loss: 78.5688\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.4187 - val_loss: 68.3308\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.8328 - val_loss: 74.2561\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.8656 - val_loss: 68.0279\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.2934 - val_loss: 68.9037\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.4313 - val_loss: 71.1010\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5910 - val_loss: 67.2020\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.8238 - val_loss: 79.7008\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.5333 - val_loss: 77.0288\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.5470 - val_loss: 148.2428\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.5983 - val_loss: 65.6155\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.7778 - val_loss: 128.6939\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1861 - val_loss: 79.3638\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 102.5184 - val_loss: 78.8413\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.5840 - val_loss: 100.3107\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.3308 - val_loss: 77.8205\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 103.8693 - val_loss: 88.4809\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119.7217 - val_loss: 67.9440\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.9651 - val_loss: 97.2938\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2647 - val_loss: 109.3746\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4606 - val_loss: 73.9370\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1818 - val_loss: 89.2341\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1120 - val_loss: 94.0868\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7078 - val_loss: 67.9209\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 120.9153 - val_loss: 76.7260\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.8404 - val_loss: 93.9883\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.2785 - val_loss: 100.4988\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.4800 - val_loss: 70.8291\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.0132 - val_loss: 80.3422\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5588 - val_loss: 101.1734\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5386 - val_loss: 98.8422\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.8144 - val_loss: 105.1966\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0662 - val_loss: 83.1556\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.0025 - val_loss: 65.0282\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.9242 - val_loss: 63.7538\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5425 - val_loss: 86.6931\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.3847 - val_loss: 64.3295\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.7798 - val_loss: 79.2101\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 113.8337 - val_loss: 77.6930\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.7619 - val_loss: 115.2746\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.7301 - val_loss: 119.2668\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2180 - val_loss: 72.9340\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9150 - val_loss: 119.4111\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9669 - val_loss: 105.5373\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.1106 - val_loss: 78.9140\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4574 - val_loss: 91.9588\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3921 - val_loss: 69.6481\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8260 - val_loss: 106.6368\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2237 - val_loss: 118.3719\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.6668 - val_loss: 101.1387\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.0479 - val_loss: 70.3931\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9892 - val_loss: 111.3927\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.7436 - val_loss: 99.2055\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8242 - val_loss: 70.0977\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.9578 - val_loss: 70.5602\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.6247 - val_loss: 74.0988\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.8155 - val_loss: 80.9071\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4054 - val_loss: 125.3057\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0216 - val_loss: 71.6302\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6701 - val_loss: 112.6239\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0859 - val_loss: 75.3892\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9639 - val_loss: 92.9708\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7288 - val_loss: 67.1805\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.2177 - val_loss: 79.9010\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8506 - val_loss: 70.3057\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.5539 - val_loss: 67.5734\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.4647 - val_loss: 162.2664\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.6979 - val_loss: 77.8750\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3131 - val_loss: 70.4517\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7752 - val_loss: 80.1703\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.4475 - val_loss: 68.1800\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4869 - val_loss: 74.2577\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.3612 - val_loss: 105.7921\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.5560 - val_loss: 68.1924\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.6211 - val_loss: 89.8088\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.7737 - val_loss: 84.3633\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9871 - val_loss: 75.9242\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5039 - val_loss: 70.5766\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4094 - val_loss: 101.2654\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.7893 - val_loss: 117.9242\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.5954 - val_loss: 73.4566\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4482 - val_loss: 148.2513\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.8572 - val_loss: 66.0756\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.2226 - val_loss: 67.2308\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.0135 - val_loss: 161.8635\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.4735 - val_loss: 87.2721\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.3313 - val_loss: 87.0982\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.2072 - val_loss: 63.4280\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.6547 - val_loss: 75.4665\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 72.4591 - val_loss: 109.2859\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.6316 - val_loss: 102.6973\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5739 - val_loss: 78.2014\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.2174 - val_loss: 85.6387\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1874 - val_loss: 90.8695\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.1580 - val_loss: 85.4203\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5135 - val_loss: 81.4730\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.5028 - val_loss: 65.1681\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.6988 - val_loss: 84.9034\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.0847 - val_loss: 74.6257\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5816 - val_loss: 91.4570\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.1317 - val_loss: 102.4759\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.4624 - val_loss: 99.4697\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.2559 - val_loss: 89.5137\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7232 - val_loss: 68.2029\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8843 - val_loss: 82.0181\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1028 - val_loss: 64.0509\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.3808 - val_loss: 78.0280\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7063 - val_loss: 112.8283\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7631 - val_loss: 108.5822\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.6965 - val_loss: 66.6629\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0720 - val_loss: 87.8808\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1352 - val_loss: 107.3259\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.0787 - val_loss: 102.1488\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.1516 - val_loss: 95.9565\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.1827 - val_loss: 63.8855\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.8729 - val_loss: 89.1954\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6002 - val_loss: 84.8360\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.2744 - val_loss: 83.9834\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.0173 - val_loss: 70.0402\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1928 - val_loss: 92.2851\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.2180 - val_loss: 76.3482\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1671 - val_loss: 98.3376\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1587 - val_loss: 87.5561\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.1851 - val_loss: 82.5171\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.2063 - val_loss: 72.5593\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 77.2114\n",
      "--- Starting trial: run-6\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 16, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7308 - val_loss: 660.2341\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6748 - val_loss: 660.1711\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6165 - val_loss: 660.1144\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5551 - val_loss: 660.0537\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4904 - val_loss: 659.9927\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4219 - val_loss: 659.9099\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3496 - val_loss: 659.8396\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2732 - val_loss: 659.7610\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1925 - val_loss: 659.6875\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1075 - val_loss: 659.6041\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0180 - val_loss: 659.5058\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.9239 - val_loss: 659.3968\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8253 - val_loss: 659.3038\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7218 - val_loss: 659.2000\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.6136 - val_loss: 659.0818\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5008 - val_loss: 658.9682\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.3831 - val_loss: 658.8649\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.2605 - val_loss: 658.7587\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.1329 - val_loss: 658.6312\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.0006 - val_loss: 658.4862\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.8632 - val_loss: 658.3482\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7210 - val_loss: 658.2112\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.5737 - val_loss: 658.0477\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.4214 - val_loss: 657.8883\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2640 - val_loss: 657.7319\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.1018 - val_loss: 657.5633\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.9344 - val_loss: 657.3859\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.7620 - val_loss: 657.2000\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.5844 - val_loss: 657.0298\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4020 - val_loss: 656.8485\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.2143 - val_loss: 656.6375\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.0215 - val_loss: 656.4502\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.8238 - val_loss: 656.2548\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.6209 - val_loss: 656.0460\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.4130 - val_loss: 655.8245\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.1998 - val_loss: 655.6400\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 684.9817 - val_loss: 655.4073\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.7585 - val_loss: 655.1993\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.5302 - val_loss: 654.9476\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.2968 - val_loss: 654.7004\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.0583 - val_loss: 654.4564\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.8148 - val_loss: 654.2355\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.5662 - val_loss: 654.0028\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.3125 - val_loss: 653.7615\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.0537 - val_loss: 653.4720\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.7899 - val_loss: 653.1818\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.5211 - val_loss: 652.8823\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.2472 - val_loss: 652.6129\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.9681 - val_loss: 652.3489\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.6841 - val_loss: 652.0742\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.3951 - val_loss: 651.7923\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.1013 - val_loss: 651.4972\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.8021 - val_loss: 651.1796\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.4981 - val_loss: 650.8997\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.1891 - val_loss: 650.6076\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.8751 - val_loss: 650.2953\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.5560 - val_loss: 649.9495\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.2322 - val_loss: 649.5844\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.9033 - val_loss: 649.2184\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.5693 - val_loss: 648.8650\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.2306 - val_loss: 648.4997\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.8868 - val_loss: 648.1862\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.5382 - val_loss: 647.8209\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.1846 - val_loss: 647.4328\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.8262 - val_loss: 647.1115\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.4628 - val_loss: 646.7187\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.0946 - val_loss: 646.3351\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.7216 - val_loss: 645.9951\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.3436 - val_loss: 645.6096\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.9608 - val_loss: 645.2181\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.5731 - val_loss: 644.8507\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.1808 - val_loss: 644.4391\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.7834 - val_loss: 644.0360\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.3813 - val_loss: 643.6168\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.9745 - val_loss: 643.1923\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.5630 - val_loss: 642.7425\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.1465 - val_loss: 642.3387\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.7253 - val_loss: 641.9131\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.2994 - val_loss: 641.4475\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 670.8688 - val_loss: 640.9485\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.4335 - val_loss: 640.5458\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.9933 - val_loss: 640.1151\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.5486 - val_loss: 639.6205\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.0992 - val_loss: 639.1198\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.6449 - val_loss: 638.6143\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.1862 - val_loss: 638.1991\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.7228 - val_loss: 637.7022\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.2545 - val_loss: 637.1856\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.7818 - val_loss: 636.6993\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.3045 - val_loss: 636.2101\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.8225 - val_loss: 635.7208\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.3359 - val_loss: 635.1915\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.8447 - val_loss: 634.7314\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.3490 - val_loss: 634.2520\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.8488 - val_loss: 633.7667\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.3439 - val_loss: 633.1992\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.8345 - val_loss: 632.7027\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.3206 - val_loss: 632.2161\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.8021 - val_loss: 631.7296\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.2792 - val_loss: 631.2228\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.7518 - val_loss: 630.6750\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.2198 - val_loss: 630.1149\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.6835 - val_loss: 629.5846\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.1425 - val_loss: 628.9523\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.5973 - val_loss: 628.5079\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.0475 - val_loss: 628.0040\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.4934 - val_loss: 627.4286\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.9347 - val_loss: 626.9014\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.3718 - val_loss: 626.3369\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 655.8044 - val_loss: 625.8193\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.2325 - val_loss: 625.2837\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.6564 - val_loss: 624.7225\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.0759 - val_loss: 624.0805\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.4910 - val_loss: 623.5103\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.9019 - val_loss: 622.9703\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.3083 - val_loss: 622.3174\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.7104 - val_loss: 621.7518\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.1084 - val_loss: 621.1886\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 650.5018 - val_loss: 620.5599\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.8912 - val_loss: 619.9484\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.2762 - val_loss: 619.3337\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.6569 - val_loss: 618.6235\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.0333 - val_loss: 617.9045\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.4056 - val_loss: 617.3021\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 646.7736 - val_loss: 616.6310\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.1373 - val_loss: 615.9431\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.4969 - val_loss: 615.3010\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 644.8522 - val_loss: 614.6464\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 644.2034 - val_loss: 614.0548\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.5505 - val_loss: 613.3806\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 642.8932 - val_loss: 612.7299\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 642.2319 - val_loss: 612.1149\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.5663 - val_loss: 611.4771\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.8969 - val_loss: 610.7659\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.2231 - val_loss: 610.0975\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 639.5452 - val_loss: 609.3795\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.8632 - val_loss: 608.7164\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.1771 - val_loss: 608.0363\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.4869 - val_loss: 607.3345\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.7927 - val_loss: 606.6446\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.0944 - val_loss: 605.8971\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.3920 - val_loss: 605.2048\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.6855 - val_loss: 604.5087\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.9752 - val_loss: 603.8226\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.2606 - val_loss: 603.1396\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.5421 - val_loss: 602.4737\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.8196 - val_loss: 601.7274\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.0930 - val_loss: 601.0756\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.3626 - val_loss: 600.3106\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.6281 - val_loss: 599.5366\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.8896 - val_loss: 598.7242\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.1472 - val_loss: 597.9294\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.4007 - val_loss: 597.0975\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.6505 - val_loss: 596.4007\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.8962 - val_loss: 595.5920\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.1379 - val_loss: 594.7979\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.3759 - val_loss: 593.9757\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.6099 - val_loss: 593.1075\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.8400 - val_loss: 592.2779\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.0662 - val_loss: 591.4333\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.2885 - val_loss: 590.6069\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.5070 - val_loss: 589.8404\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 619.7215 - val_loss: 589.0649\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.9323 - val_loss: 588.2778\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.1392 - val_loss: 587.4045\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.3422 - val_loss: 586.5436\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.5414 - val_loss: 585.8610\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 615.7369 - val_loss: 585.0499\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 614.9285 - val_loss: 584.2101\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.1163 - val_loss: 583.4298\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.3003 - val_loss: 582.6226\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.4805 - val_loss: 581.7679\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 611.6569 - val_loss: 581.0320\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 610.8296 - val_loss: 580.1953\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 609.9985 - val_loss: 579.4106\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.1638 - val_loss: 578.5161\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.3251 - val_loss: 577.6771\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.4829 - val_loss: 576.7710\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.6369 - val_loss: 575.9463\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.7871 - val_loss: 575.1376\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.9337 - val_loss: 574.3689\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 604.0765 - val_loss: 573.5913\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.2156 - val_loss: 572.7170\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 602.3511 - val_loss: 571.9323\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 601.4829 - val_loss: 571.1085\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.6110 - val_loss: 570.3397\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.7355 - val_loss: 569.4420\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.8564 - val_loss: 568.4958\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.9735 - val_loss: 567.5336\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.0871 - val_loss: 566.5790\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.1969 - val_loss: 565.7214\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.3032 - val_loss: 564.7072\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.4058 - val_loss: 563.7952\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.5049 - val_loss: 562.8358\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.6003 - val_loss: 562.0011\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.6923 - val_loss: 560.9529\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.7805 - val_loss: 559.9970\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.8652 - val_loss: 559.0147\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.9465 - val_loss: 557.9471\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.0240 - val_loss: 557.1030\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.0980 - val_loss: 556.2081\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.1685 - val_loss: 555.3384\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.2355 - val_loss: 554.5375\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.2989 - val_loss: 553.7788\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 583.3587 - val_loss: 552.8927\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.4150 - val_loss: 551.9620\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.6194 - val_loss: 552.9285\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.5229 - val_loss: 552.8237\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.5704 - val_loss: 552.0292\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.6135 - val_loss: 551.2145\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 577.6526 - val_loss: 550.2319\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.6880 - val_loss: 549.1352\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.7200 - val_loss: 548.0590\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.7484 - val_loss: 547.0703\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 573.7734 - val_loss: 546.0038\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.7948 - val_loss: 545.0101\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.8129 - val_loss: 543.9365\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.8275 - val_loss: 542.8911\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.8387 - val_loss: 541.9012\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.8464 - val_loss: 540.8487\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.8508 - val_loss: 539.8625\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.8517 - val_loss: 538.8937\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.8492 - val_loss: 537.8862\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.8434 - val_loss: 536.8927\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.8341 - val_loss: 535.8216\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.9467 - val_loss: 535.5064\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.8103 - val_loss: 534.8165\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.7926 - val_loss: 533.9449\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.7706 - val_loss: 532.9512\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 558.7447 - val_loss: 531.9266\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.7153 - val_loss: 530.9504\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.7233 - val_loss: 529.5208\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.6512 - val_loss: 528.3171\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.6132 - val_loss: 527.2689\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.5709 - val_loss: 526.1880\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.5250 - val_loss: 525.1016\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.4755 - val_loss: 524.2289\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.4227 - val_loss: 523.1603\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.3665 - val_loss: 522.1309\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.3071 - val_loss: 521.0590\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.2444 - val_loss: 520.0233\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.2380 - val_loss: 519.1570\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.1130 - val_loss: 518.3018\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.0425 - val_loss: 517.2981\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.9674 - val_loss: 516.4022\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.0297 - val_loss: 515.3922\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.8150 - val_loss: 514.5742\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.7335 - val_loss: 513.5953\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.6463 - val_loss: 512.5712\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.5548 - val_loss: 511.5535\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 601.2142\n",
      "--- Starting trial: run-7\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 16, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6689 - val_loss: 660.1279\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4568 - val_loss: 659.9291\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2401 - val_loss: 659.7127\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0156 - val_loss: 659.4834\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7792 - val_loss: 659.2399\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.5272 - val_loss: 658.9839\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2551 - val_loss: 658.7017\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.9581 - val_loss: 658.3970\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6306 - val_loss: 658.0490\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2663 - val_loss: 657.6653\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.8579 - val_loss: 657.2319\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.3973 - val_loss: 656.7373\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.8746 - val_loss: 656.1836\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.2786 - val_loss: 655.5388\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.5962 - val_loss: 654.7857\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.8122 - val_loss: 653.9323\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.9085 - val_loss: 652.9471\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.8644 - val_loss: 651.8128\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.6553 - val_loss: 650.4846\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.2524 - val_loss: 648.9517\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.6224 - val_loss: 647.1897\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.7256 - val_loss: 645.1205\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.5162 - val_loss: 642.7009\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 670.9397 - val_loss: 639.8912\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.9330 - val_loss: 636.6215\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.4217 - val_loss: 632.7725\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.3187 - val_loss: 628.2584\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 655.5213 - val_loss: 622.9755\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.9105 - val_loss: 616.7986\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.3453 - val_loss: 609.5889\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.6611 - val_loss: 601.1849\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.6648 - val_loss: 591.2870\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.1298 - val_loss: 579.7500\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.7906 - val_loss: 566.2172\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.3359 - val_loss: 550.3588\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.4005 - val_loss: 531.8724\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.8879 - val_loss: 512.0826\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.5989 - val_loss: 491.1857\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 505.4009 - val_loss: 466.1023\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 477.6687 - val_loss: 439.1762\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 451.1913 - val_loss: 414.1096\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.9976 - val_loss: 395.8083\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 410.5020 - val_loss: 374.7794\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 395.8009 - val_loss: 353.5602\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.1113 - val_loss: 332.4811\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 363.4567 - val_loss: 320.1081\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.4496 - val_loss: 292.0902\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.2791 - val_loss: 269.8297\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 302.8802 - val_loss: 231.0307\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.2647 - val_loss: 208.9547\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 258.7247 - val_loss: 183.3930\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.8219 - val_loss: 159.5682\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.2010 - val_loss: 149.8703\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.0840 - val_loss: 213.0429\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.1905 - val_loss: 176.3353\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.9718 - val_loss: 291.7011\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.1164 - val_loss: 306.7298\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.3860 - val_loss: 241.1380\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.7353 - val_loss: 322.3931\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.4403 - val_loss: 317.9969\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.1463 - val_loss: 272.4967\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.8423 - val_loss: 262.8913\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.9163 - val_loss: 293.4775\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.4042 - val_loss: 332.9444\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.4021 - val_loss: 278.7567\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.4509 - val_loss: 207.9449\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.0822 - val_loss: 222.7903\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.6178 - val_loss: 230.4237\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.9635 - val_loss: 189.5046\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.2868 - val_loss: 219.7163\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0161 - val_loss: 194.0468\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1779 - val_loss: 151.0203\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118.1472 - val_loss: 179.8176\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.6773 - val_loss: 166.6722\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.6715 - val_loss: 179.9889\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.6419 - val_loss: 165.6562\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8540 - val_loss: 140.9700\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.0828 - val_loss: 155.6020\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.4973 - val_loss: 148.3673\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.7681 - val_loss: 84.8858\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.4648 - val_loss: 134.7054\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 144.6944 - val_loss: 149.3643\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.8734 - val_loss: 141.8496\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.0024 - val_loss: 84.4306\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.4123 - val_loss: 84.2638\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.1365 - val_loss: 113.8783\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.0867 - val_loss: 109.7417\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.1206 - val_loss: 105.1863\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.0271 - val_loss: 100.8723\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.7649 - val_loss: 93.7068\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.7875 - val_loss: 100.5343\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.5900 - val_loss: 118.8989\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.7795 - val_loss: 104.6823\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.5694 - val_loss: 107.7439\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6313 - val_loss: 80.0360\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.0980 - val_loss: 65.2574\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.9546 - val_loss: 75.7524\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.1770 - val_loss: 104.1054\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.5785 - val_loss: 67.3808\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.7648 - val_loss: 74.5256\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.5918 - val_loss: 79.5739\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.0260 - val_loss: 81.8341\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.1390 - val_loss: 81.7268\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.5863 - val_loss: 75.8273\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.3553 - val_loss: 91.9611\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.5135 - val_loss: 90.7628\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.7638 - val_loss: 101.7442\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.0425 - val_loss: 69.4753\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.8992 - val_loss: 78.4925\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.4327 - val_loss: 68.0054\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.8380 - val_loss: 73.6433\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.6278 - val_loss: 84.3578\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.8434 - val_loss: 70.5537\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5094 - val_loss: 79.3924\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.1255 - val_loss: 89.3814\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1341 - val_loss: 83.5124\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8554 - val_loss: 90.0982\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.5511 - val_loss: 84.8847\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8067 - val_loss: 98.2198\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6902 - val_loss: 121.9317\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 112.7459 - val_loss: 81.1972\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.0201 - val_loss: 72.1263\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.3167 - val_loss: 70.7188\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.3443 - val_loss: 95.5158\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.5962 - val_loss: 99.1239\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2352 - val_loss: 97.9115\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.3864 - val_loss: 77.4530\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.4822 - val_loss: 73.0788\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.3844 - val_loss: 64.1443\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.8215 - val_loss: 66.4246\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.2885 - val_loss: 76.8895\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.1038 - val_loss: 76.3131\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.3578 - val_loss: 75.2720\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.8485 - val_loss: 77.3205\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.0517 - val_loss: 84.9922\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.4837 - val_loss: 76.2992\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9000 - val_loss: 77.6569\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0166 - val_loss: 83.4114\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.5287 - val_loss: 73.6987\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.4806 - val_loss: 71.4150\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.0705 - val_loss: 64.3352\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.6035 - val_loss: 69.1194\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.8961 - val_loss: 70.3002\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.4996 - val_loss: 67.1273\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.3218 - val_loss: 67.4722\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.8239 - val_loss: 67.7946\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.5820 - val_loss: 70.6881\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.5538 - val_loss: 71.7410\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9141 - val_loss: 70.0928\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.3207 - val_loss: 91.9436\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.3802 - val_loss: 91.9902\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.3906 - val_loss: 93.2268\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.6942 - val_loss: 86.6209\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.3713 - val_loss: 84.8764\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.0930 - val_loss: 90.6114\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.7062 - val_loss: 72.7285\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8990 - val_loss: 72.1072\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.5836 - val_loss: 66.5741\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.6334 - val_loss: 70.2125\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.5930 - val_loss: 66.6070\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.6781 - val_loss: 65.4332\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.0624 - val_loss: 70.0110\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.0808 - val_loss: 69.7174\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5956 - val_loss: 69.0212\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.3353 - val_loss: 64.4193\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.9136 - val_loss: 91.7220\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.8036 - val_loss: 64.2099\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.2634 - val_loss: 61.3311\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.8118 - val_loss: 62.5868\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.9290 - val_loss: 66.5559\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.4803 - val_loss: 64.9047\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.1222 - val_loss: 64.7376\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.7547 - val_loss: 70.5100\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.7636 - val_loss: 76.1923\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.7014 - val_loss: 68.0407\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.7877 - val_loss: 76.6366\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1922 - val_loss: 75.9285\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 131.8277 - val_loss: 72.4752\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3524 - val_loss: 72.4982\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.0181 - val_loss: 76.1426\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.0965 - val_loss: 68.8417\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.5993 - val_loss: 71.6402\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.3184 - val_loss: 82.9447\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.1610 - val_loss: 73.5054\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.2738 - val_loss: 79.2021\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.3287 - val_loss: 78.8919\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.2246 - val_loss: 70.7049\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.8087 - val_loss: 76.7831\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.7178 - val_loss: 65.6260\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.7154 - val_loss: 73.8482\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4326 - val_loss: 70.8632\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.8782 - val_loss: 71.3255\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.0211 - val_loss: 62.7993\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5363 - val_loss: 62.1378\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.8987 - val_loss: 62.9973\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0030 - val_loss: 64.8424\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.5124 - val_loss: 79.3894\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.0879 - val_loss: 77.0088\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.9657 - val_loss: 68.7161\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.9509 - val_loss: 68.1072\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.6651 - val_loss: 64.2102\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.5479 - val_loss: 63.7730\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.4578 - val_loss: 64.9936\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.3696 - val_loss: 60.6121\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.7903 - val_loss: 63.8634\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.8768 - val_loss: 64.5961\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.3578 - val_loss: 62.1910\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.8899 - val_loss: 74.7361\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.5854 - val_loss: 67.4337\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.2102 - val_loss: 66.5564\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0113 - val_loss: 70.4022\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.3156 - val_loss: 74.1243\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.8092 - val_loss: 72.3822\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9612 - val_loss: 66.6799\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.4828 - val_loss: 70.5032\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.3240 - val_loss: 71.7180\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.1625 - val_loss: 68.7879\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.6291 - val_loss: 64.0032\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.7170 - val_loss: 67.7759\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.8487 - val_loss: 69.8625\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.1636 - val_loss: 66.3203\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.9074 - val_loss: 65.2851\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.2593 - val_loss: 63.4270\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.1407 - val_loss: 65.0771\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.3667 - val_loss: 60.7475\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.3705 - val_loss: 64.4362\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1602 - val_loss: 65.8903\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.2090 - val_loss: 68.9640\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.2205 - val_loss: 68.8960\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.5677 - val_loss: 69.5934\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 127.1768 - val_loss: 63.7862\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.0872 - val_loss: 65.5492\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.0765 - val_loss: 67.4198\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.5616 - val_loss: 63.2209\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.9734 - val_loss: 75.1208\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.1783 - val_loss: 70.7434\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2132 - val_loss: 66.0818\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.0142 - val_loss: 72.0514\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6125 - val_loss: 71.7533\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.1811 - val_loss: 65.7705\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5056 - val_loss: 67.8209\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2934 - val_loss: 81.5981\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.5619 - val_loss: 63.9882\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4652 - val_loss: 67.8298\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8239 - val_loss: 65.8389\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 120.8113 - val_loss: 70.3502\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.5775 - val_loss: 72.6629\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.5940 - val_loss: 63.4851\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.4107 - val_loss: 70.2599\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.6261 - val_loss: 64.8243\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50.0995\n",
      "--- Starting trial: run-8\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 16, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7310 - val_loss: 660.3157\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6754 - val_loss: 660.2446\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6172 - val_loss: 660.1702\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5562 - val_loss: 660.0994\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4918 - val_loss: 660.0235\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4238 - val_loss: 659.9365\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3519 - val_loss: 659.8568\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2759 - val_loss: 659.7662\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1956 - val_loss: 659.6731\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1110 - val_loss: 659.5796\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.0220 - val_loss: 659.4868\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.9285 - val_loss: 659.4007\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.8303 - val_loss: 659.3091\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7275 - val_loss: 659.2072\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.6200 - val_loss: 659.0897\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5078 - val_loss: 658.9899\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3906 - val_loss: 658.8727\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2687 - val_loss: 658.7516\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1418 - val_loss: 658.6187\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0101 - val_loss: 658.4891\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.8734 - val_loss: 658.3583\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.7317 - val_loss: 658.2399\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.5851 - val_loss: 658.0972\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.4334 - val_loss: 657.9515\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2768 - val_loss: 657.7930\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.1151 - val_loss: 657.6589\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.9484 - val_loss: 657.5071\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.7767 - val_loss: 657.3222\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.5999 - val_loss: 657.1711\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.4178 - val_loss: 657.0032\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.2309 - val_loss: 656.8287\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.0388 - val_loss: 656.6393\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.8416 - val_loss: 656.4826\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.6393 - val_loss: 656.3212\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.4321 - val_loss: 656.1094\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.2196 - val_loss: 655.8937\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.0021 - val_loss: 655.6964\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.7795 - val_loss: 655.5056\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.5518 - val_loss: 655.2971\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.3190 - val_loss: 655.0781\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.0811 - val_loss: 654.8063\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.8381 - val_loss: 654.5890\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.5900 - val_loss: 654.3603\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3369 - val_loss: 654.0992\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.0787 - val_loss: 653.8349\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.8154 - val_loss: 653.5416\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.5471 - val_loss: 653.2673\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.2737 - val_loss: 652.9640\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.9954 - val_loss: 652.6909\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.7119 - val_loss: 652.4196\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.4235 - val_loss: 652.0964\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.1300 - val_loss: 651.7876\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.8315 - val_loss: 651.4681\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.5280 - val_loss: 651.1555\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.2194 - val_loss: 650.8499\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.9059 - val_loss: 650.5405\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.5875 - val_loss: 650.2609\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.2640 - val_loss: 650.0179\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.9356 - val_loss: 649.7472\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.6022 - val_loss: 649.4672\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.2640 - val_loss: 649.1561\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.9206 - val_loss: 648.8598\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.5725 - val_loss: 648.5186\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.2194 - val_loss: 648.2449\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.8614 - val_loss: 647.9080\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.4985 - val_loss: 647.5630\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.1307 - val_loss: 647.2257\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.7580 - val_loss: 646.8966\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.3806 - val_loss: 646.5291\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.9982 - val_loss: 646.2045\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6110 - val_loss: 645.8443\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.2190 - val_loss: 645.4298\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.8221 - val_loss: 645.0141\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.4205 - val_loss: 644.5799\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.0140 - val_loss: 644.1915\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.6029 - val_loss: 643.8342\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.1870 - val_loss: 643.3779\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.7662 - val_loss: 642.9531\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.3407 - val_loss: 642.5817\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.9104 - val_loss: 642.1818\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.4755 - val_loss: 641.8146\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.0358 - val_loss: 641.4584\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.5914 - val_loss: 641.0791\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.1423 - val_loss: 640.5972\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.6887 - val_loss: 640.1265\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.2302 - val_loss: 639.6761\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.7670 - val_loss: 639.2602\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.2993 - val_loss: 638.8403\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.8269 - val_loss: 638.3321\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.3500 - val_loss: 637.8171\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 665.8683 - val_loss: 637.2502\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 665.3821 - val_loss: 636.7069\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.8913 - val_loss: 636.2181\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.3959 - val_loss: 635.6995\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.8961 - val_loss: 635.1627\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.3915 - val_loss: 634.5621\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.8825 - val_loss: 633.9993\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.3690 - val_loss: 633.5314\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.8509 - val_loss: 633.0959\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.3282 - val_loss: 632.6304\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.8012 - val_loss: 632.1402\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.2696 - val_loss: 631.5711\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.7336 - val_loss: 630.9570\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.1931 - val_loss: 630.3557\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.6481 - val_loss: 629.7635\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.0986 - val_loss: 629.2086\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.5448 - val_loss: 628.6317\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.9866 - val_loss: 627.9749\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.4240 - val_loss: 627.2573\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.8569 - val_loss: 626.6583\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.2854 - val_loss: 626.1057\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.7096 - val_loss: 625.5231\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.1294 - val_loss: 624.9271\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 653.5449 - val_loss: 624.3376\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.9559 - val_loss: 623.7211\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.3629 - val_loss: 623.1718\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.7652 - val_loss: 622.6229\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.1634 - val_loss: 622.1304\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 650.5574 - val_loss: 621.5462\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.9469 - val_loss: 620.9494\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.3322 - val_loss: 620.3776\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.7133 - val_loss: 619.7208\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.0900 - val_loss: 619.1467\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.4626 - val_loss: 618.5592\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.8309 - val_loss: 617.8431\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 646.1951 - val_loss: 617.2336\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.5549 - val_loss: 616.5877\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.9105 - val_loss: 615.9253\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 644.2620 - val_loss: 615.2134\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.6093 - val_loss: 614.4644\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.9525 - val_loss: 613.6404\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.2914 - val_loss: 612.8216\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.6263 - val_loss: 612.0408\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.9569 - val_loss: 611.3356\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.2834 - val_loss: 610.6463\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 639.6059 - val_loss: 610.1072\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.9243 - val_loss: 609.6148\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.2385 - val_loss: 609.0489\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.5485 - val_loss: 608.3456\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.8546 - val_loss: 607.7259\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.1567 - val_loss: 607.4178\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.4545 - val_loss: 606.8917\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.7484 - val_loss: 606.2266\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.0383 - val_loss: 605.4588\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.3241 - val_loss: 604.8135\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.6058 - val_loss: 604.0540\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.8836 - val_loss: 603.4891\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.1574 - val_loss: 602.8857\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.4271 - val_loss: 602.2091\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.6929 - val_loss: 601.4726\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.9548 - val_loss: 600.8403\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.2126 - val_loss: 600.3015\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.4666 - val_loss: 599.7849\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.7166 - val_loss: 599.0819\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.9625 - val_loss: 598.3704\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.2047 - val_loss: 597.5554\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.4429 - val_loss: 596.7438\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.6771 - val_loss: 596.0046\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.9076 - val_loss: 595.2508\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 622.1340 - val_loss: 594.3203\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 621.3566 - val_loss: 593.3618\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.5753 - val_loss: 592.4836\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.7902 - val_loss: 591.5858\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 619.0013 - val_loss: 590.6985\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.2084 - val_loss: 589.8157\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 617.4118 - val_loss: 588.7430\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.6113 - val_loss: 587.8641\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.8069 - val_loss: 587.0024\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.9988 - val_loss: 586.1985\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.1870 - val_loss: 585.3671\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.3713 - val_loss: 584.6445\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.5518 - val_loss: 583.8676\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 611.7285 - val_loss: 583.1187\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 610.9014 - val_loss: 582.1608\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 610.0706 - val_loss: 581.2213\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 609.2361 - val_loss: 580.2183\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.3978 - val_loss: 579.3624\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.5558 - val_loss: 578.6902\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.7101 - val_loss: 577.9520\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 605.8606 - val_loss: 577.1461\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 605.0075 - val_loss: 576.2598\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.1506 - val_loss: 575.3327\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.2900 - val_loss: 574.3311\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.4258 - val_loss: 573.3380\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.5578 - val_loss: 572.4166\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 600.6863 - val_loss: 571.3654\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.8110 - val_loss: 570.7689\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.9321 - val_loss: 570.1041\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.0496 - val_loss: 569.3468\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.1633 - val_loss: 568.4617\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.2736 - val_loss: 567.3647\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 595.3801 - val_loss: 566.3217\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.5553 - val_loss: 567.8854\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.5868 - val_loss: 567.7993\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.6844 - val_loss: 567.0241\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.7773 - val_loss: 566.1565\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.8663 - val_loss: 565.0711\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.9512 - val_loss: 563.9540\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.0327 - val_loss: 562.9086\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.1105 - val_loss: 561.8959\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.1848 - val_loss: 560.7811\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.2554 - val_loss: 559.7641\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.3225 - val_loss: 558.7297\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.3862 - val_loss: 557.7112\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 583.4462 - val_loss: 556.7180\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.5027 - val_loss: 555.6591\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.5559 - val_loss: 554.6219\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.6054 - val_loss: 553.6495\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 579.6665 - val_loss: 552.0524\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.6975 - val_loss: 550.2736\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.7389 - val_loss: 548.8898\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.7755 - val_loss: 547.7427\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.8079 - val_loss: 546.6683\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.8367 - val_loss: 545.7947\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 573.8620 - val_loss: 544.8362\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.8837 - val_loss: 543.7536\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.9020 - val_loss: 542.9123\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.9542 - val_loss: 541.3391\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.9313 - val_loss: 538.7772\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.9418 - val_loss: 537.2360\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.9477 - val_loss: 535.3165\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.9529 - val_loss: 532.9984\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.9532 - val_loss: 531.7679\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.9486 - val_loss: 531.0210\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.9620 - val_loss: 531.5107\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.9858 - val_loss: 531.7363\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.9213 - val_loss: 531.2906\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.9051 - val_loss: 530.6592\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 559.8837 - val_loss: 529.8450\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 558.8582 - val_loss: 529.0011\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.8289 - val_loss: 528.1183\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.7961 - val_loss: 527.3330\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.8657 - val_loss: 526.2240\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.7241 - val_loss: 524.9844\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.6836 - val_loss: 523.9200\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.6384 - val_loss: 523.1522\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.5894 - val_loss: 522.2316\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.5366 - val_loss: 521.3211\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.4806 - val_loss: 520.5539\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.5937 - val_loss: 519.7526\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.4169 - val_loss: 518.9773\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.3035 - val_loss: 518.0679\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.2598 - val_loss: 516.6866\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.1934 - val_loss: 514.0305\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.1010 - val_loss: 511.6764\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.0280 - val_loss: 510.1424\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.9482 - val_loss: 509.0834\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.8636 - val_loss: 508.2155\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.7749 - val_loss: 507.4947\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.8377 - val_loss: 506.0332\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 598.1512\n",
      "--- Starting trial: run-9\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 16, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 689.6494 - val_loss: 660.5276\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3875 - val_loss: 660.2112\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1194 - val_loss: 659.8974\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8403 - val_loss: 659.5811\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 688.5453 - val_loss: 659.2504\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.2285 - val_loss: 658.8945\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8841 - val_loss: 658.4980\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5054 - val_loss: 658.0672\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0845 - val_loss: 657.5887\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6133 - val_loss: 657.0572\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.0814 - val_loss: 656.4579\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.4774 - val_loss: 655.7694\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.7881 - val_loss: 654.9979\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.9979 - val_loss: 654.1064\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.0887 - val_loss: 653.0895\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.0397 - val_loss: 651.9069\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.8260 - val_loss: 650.5494\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.4188 - val_loss: 648.9533\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.7846 - val_loss: 647.1251\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.8839 - val_loss: 645.0093\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.6702 - val_loss: 642.5262\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.0895 - val_loss: 639.6363\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.0784 - val_loss: 636.2784\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.5622 - val_loss: 632.3632\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.4537 - val_loss: 627.7596\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 655.6506 - val_loss: 622.4113\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.0329 - val_loss: 616.1299\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.4601 - val_loss: 608.8398\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.7670 - val_loss: 600.2969\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.7604 - val_loss: 590.3130\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.2136 - val_loss: 578.6091\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.8607 - val_loss: 564.9104\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.3898 - val_loss: 548.8757\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.4357 - val_loss: 530.5899\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.1554 - val_loss: 511.2719\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.2504 - val_loss: 492.2548\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 507.8415 - val_loss: 472.8324\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 483.8858 - val_loss: 455.4378\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 461.4009 - val_loss: 448.2668\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 440.0674 - val_loss: 442.6830\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 425.1641 - val_loss: 424.2148\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.1239 - val_loss: 408.2841\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 398.3441 - val_loss: 389.3991\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 387.7383 - val_loss: 366.5226\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.3021 - val_loss: 347.5079\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.6792 - val_loss: 315.3860\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 341.7142 - val_loss: 302.7893\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 316.2368 - val_loss: 268.4103\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 298.1438 - val_loss: 236.3628\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.5989 - val_loss: 215.1411\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.8263 - val_loss: 200.0930\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.2500 - val_loss: 164.2110\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.8098 - val_loss: 133.4526\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.9235 - val_loss: 105.3885\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.0059 - val_loss: 78.0357\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 153.2424 - val_loss: 106.9109\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 151.2056 - val_loss: 90.1915\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 129.2010 - val_loss: 91.9858\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 155.6183 - val_loss: 108.5696\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.9155 - val_loss: 113.3176\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.1767 - val_loss: 117.4249\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.3936 - val_loss: 89.3863\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 139.5471 - val_loss: 122.0534\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.8148 - val_loss: 135.6915\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.3578 - val_loss: 145.9724\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.4821 - val_loss: 134.0050\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.0949 - val_loss: 97.0614\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.9346 - val_loss: 115.6814\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 129.2859 - val_loss: 103.3201\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.4806 - val_loss: 120.4083\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 131.2058 - val_loss: 122.3626\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 139.9004 - val_loss: 97.8669\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.4476 - val_loss: 106.1662\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.1208 - val_loss: 105.2038\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.9616 - val_loss: 94.6850\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.9575 - val_loss: 70.4166\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118.7967 - val_loss: 78.0547\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 131.0571 - val_loss: 78.9360\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.5191 - val_loss: 80.8816\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.1116 - val_loss: 93.5101\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.3677 - val_loss: 79.9962\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.1068 - val_loss: 73.9958\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.9555 - val_loss: 81.8404\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.0406 - val_loss: 74.2696\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.9289 - val_loss: 93.8741\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.4954 - val_loss: 86.1462\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6832 - val_loss: 81.9290\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 146.0201 - val_loss: 78.5872\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 149.2047 - val_loss: 93.1971\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.7172 - val_loss: 79.3763\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 129.1131 - val_loss: 103.9951\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.2728 - val_loss: 76.2064\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.6828 - val_loss: 70.7996\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.9788 - val_loss: 70.3231\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.8011 - val_loss: 67.8097\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.6181 - val_loss: 114.2901\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.7102 - val_loss: 107.8253\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 112.7468 - val_loss: 98.6735\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.8696 - val_loss: 85.8525\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.1586 - val_loss: 68.0303\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.6171 - val_loss: 72.6984\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.7106 - val_loss: 77.2499\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.4243 - val_loss: 67.3234\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.0355 - val_loss: 80.1920\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.5663 - val_loss: 72.6247\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.9749 - val_loss: 93.3804\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.7262 - val_loss: 85.0207\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.1795 - val_loss: 90.6089\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.4671 - val_loss: 99.6650\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.7353 - val_loss: 83.5643\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.8764 - val_loss: 71.7957\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.5803 - val_loss: 81.3240\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.4457 - val_loss: 98.6374\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.7152 - val_loss: 90.9655\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.9389 - val_loss: 99.3928\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.7480 - val_loss: 68.7432\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.2749 - val_loss: 75.6166\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.9243 - val_loss: 96.9180\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.8806 - val_loss: 101.6933\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 124.7945 - val_loss: 83.8467\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.6467 - val_loss: 72.7754\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 135.3543 - val_loss: 93.6083\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.3148 - val_loss: 66.4544\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.5039 - val_loss: 67.4177\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.0979 - val_loss: 66.5543\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.8728 - val_loss: 80.4143\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.4570 - val_loss: 102.0116\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.1425 - val_loss: 79.6585\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.8922 - val_loss: 79.4815\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.2265 - val_loss: 78.3799\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2259 - val_loss: 87.9974\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.9595 - val_loss: 90.6732\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.6687 - val_loss: 97.1861\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.9853 - val_loss: 69.7665\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.9732 - val_loss: 66.8605\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.1975 - val_loss: 69.1019\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.4180 - val_loss: 90.3246\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.3522 - val_loss: 71.4278\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.4664 - val_loss: 73.0750\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.3058 - val_loss: 71.7180\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.6597 - val_loss: 75.3828\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.4880 - val_loss: 82.9993\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.0841 - val_loss: 90.4229\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4897 - val_loss: 77.6529\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.9975 - val_loss: 75.2153\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.3995 - val_loss: 67.7755\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.7808 - val_loss: 75.9722\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.7688 - val_loss: 92.9424\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119.6087 - val_loss: 72.3280\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.3005 - val_loss: 96.4194\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.1888 - val_loss: 91.4698\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3682 - val_loss: 86.2171\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.6478 - val_loss: 65.6131\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 138.8760 - val_loss: 73.9506\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.6631 - val_loss: 72.1000\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.6768 - val_loss: 67.3020\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.4970 - val_loss: 61.4578\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.7531 - val_loss: 65.9824\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.0437 - val_loss: 71.6891\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.9946 - val_loss: 81.7663\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.0465 - val_loss: 70.6715\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.7954 - val_loss: 76.2584\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.8522 - val_loss: 68.2657\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.7278 - val_loss: 81.6376\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.0160 - val_loss: 81.7448\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6073 - val_loss: 86.3382\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.0680 - val_loss: 82.1315\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.7267 - val_loss: 71.3097\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.6770 - val_loss: 67.7409\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.5279 - val_loss: 75.9425\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.6894 - val_loss: 73.2422\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 140.2160 - val_loss: 71.8215\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.3406 - val_loss: 108.1471\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.1635 - val_loss: 87.4033\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.3294 - val_loss: 73.5945\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 144.3845 - val_loss: 66.3184\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.3197 - val_loss: 114.8770\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.5025 - val_loss: 88.2639\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116.6171 - val_loss: 75.3702\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.0723 - val_loss: 100.0649\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5370 - val_loss: 89.6403\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3268 - val_loss: 81.3375\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.5676 - val_loss: 72.2812\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.0437 - val_loss: 66.8185\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.8746 - val_loss: 65.6261\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.4303 - val_loss: 71.3489\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 132.3571 - val_loss: 93.9889\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.0573 - val_loss: 71.7416\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8247 - val_loss: 76.1218\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2298 - val_loss: 74.3612\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.0118 - val_loss: 67.7215\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.3030 - val_loss: 63.3980\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.0742 - val_loss: 73.5697\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.8751 - val_loss: 75.3456\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 133.6793 - val_loss: 136.5342\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.5630 - val_loss: 95.1945\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.0384 - val_loss: 69.9564\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.1243 - val_loss: 179.5821\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.8736 - val_loss: 141.2260\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.6899 - val_loss: 103.4686\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 134.9851 - val_loss: 88.3477\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.1270 - val_loss: 80.3077\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.4812 - val_loss: 73.1700\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.0586 - val_loss: 94.7319\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.4684 - val_loss: 96.4582\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.6971 - val_loss: 72.8293\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1135 - val_loss: 64.5292\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.6849 - val_loss: 66.8956\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2122 - val_loss: 64.7548\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.6796 - val_loss: 68.6664\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 120.7588 - val_loss: 75.6141\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 96.8016 - val_loss: 72.5266\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 112.9248 - val_loss: 67.4972\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.9281 - val_loss: 66.8329\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.9214 - val_loss: 67.5114\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5529 - val_loss: 71.4654\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.7791 - val_loss: 64.8695\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.6534 - val_loss: 64.6477\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.4718 - val_loss: 84.8989\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.7301 - val_loss: 69.9669\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.5381 - val_loss: 88.9168\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6091 - val_loss: 81.1027\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5707 - val_loss: 82.5208\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.4813 - val_loss: 67.6129\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4743 - val_loss: 88.3166\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.0359 - val_loss: 79.3009\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.1501 - val_loss: 78.6360\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.2464 - val_loss: 64.7187\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.9648 - val_loss: 67.1524\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.6442 - val_loss: 64.2082\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.2837 - val_loss: 72.6084\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.1967 - val_loss: 73.3719\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.8295 - val_loss: 67.0964\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.6756 - val_loss: 80.0443\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.4538 - val_loss: 71.7844\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.0313 - val_loss: 72.3085\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1409 - val_loss: 68.6504\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7272 - val_loss: 67.1899\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.2013 - val_loss: 67.1791\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1376 - val_loss: 67.5940\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.4808 - val_loss: 66.0350\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116.0309 - val_loss: 64.5643\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 99.4670 - val_loss: 69.4022\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2099 - val_loss: 69.7470\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4394 - val_loss: 75.6215\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3381 - val_loss: 78.1670\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9934 - val_loss: 77.4012\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.3557 - val_loss: 71.6749\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.2158 - val_loss: 76.3416\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.9928 - val_loss: 69.6736\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 41.0056\n",
      "--- Starting trial: run-10\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 16, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7328 - val_loss: 660.6388\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6819 - val_loss: 660.5796\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.6286 - val_loss: 660.5249\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5722 - val_loss: 660.4670\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5126 - val_loss: 660.3992\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4492 - val_loss: 660.3307\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3820 - val_loss: 660.2564\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3105 - val_loss: 660.1841\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2349 - val_loss: 660.1059\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1547 - val_loss: 660.0182\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0701 - val_loss: 659.9167\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.9809 - val_loss: 659.8228\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8870 - val_loss: 659.7286\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.7884 - val_loss: 659.6216\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6849 - val_loss: 659.5104\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.5767 - val_loss: 659.3902\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4635 - val_loss: 659.2704\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3453 - val_loss: 659.1401\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2224 - val_loss: 658.9982\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0944 - val_loss: 658.8688\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9612 - val_loss: 658.7202\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8231 - val_loss: 658.5765\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6799 - val_loss: 658.4175\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5318 - val_loss: 658.2609\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.3784 - val_loss: 658.1104\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.2200 - val_loss: 657.9392\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.0565 - val_loss: 657.7561\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.8879 - val_loss: 657.5717\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.7141 - val_loss: 657.3802\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.5352 - val_loss: 657.1933\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.3510 - val_loss: 656.9852\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.1619 - val_loss: 656.8120\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.9676 - val_loss: 656.6024\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.7682 - val_loss: 656.3791\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.5637 - val_loss: 656.1716\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.3538 - val_loss: 655.9468\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.1389 - val_loss: 655.7282\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.9189 - val_loss: 655.4991\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 684.6937 - val_loss: 655.2520\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.4634 - val_loss: 655.0120\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.2280 - val_loss: 654.7602\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.9874 - val_loss: 654.5250\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.7417 - val_loss: 654.2635\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.4910 - val_loss: 653.9992\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.2351 - val_loss: 653.7406\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.9740 - val_loss: 653.4763\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.7081 - val_loss: 653.2252\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.4368 - val_loss: 652.9658\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.1606 - val_loss: 652.6915\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.8793 - val_loss: 652.4169\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.5930 - val_loss: 652.1360\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.3015 - val_loss: 651.8333\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.0049 - val_loss: 651.5259\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.7036 - val_loss: 651.2237\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.3970 - val_loss: 650.9305\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.0854 - val_loss: 650.6130\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.7689 - val_loss: 650.2976\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.4474 - val_loss: 649.9811\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.1208 - val_loss: 649.6254\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.7892 - val_loss: 649.2733\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.4528 - val_loss: 648.9283\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.1115 - val_loss: 648.5446\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 677.7650 - val_loss: 648.1843\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.4138 - val_loss: 647.8408\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.0576 - val_loss: 647.5118\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.6964 - val_loss: 647.1407\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.3303 - val_loss: 646.7769\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.9595 - val_loss: 646.4211\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.5837 - val_loss: 646.0412\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.2031 - val_loss: 645.6412\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.8176 - val_loss: 645.2420\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.4271 - val_loss: 644.8202\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.0320 - val_loss: 644.4494\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.6320 - val_loss: 644.0460\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.2272 - val_loss: 643.6475\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.8176 - val_loss: 643.2743\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.4033 - val_loss: 642.7994\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.9839 - val_loss: 642.4086\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.5601 - val_loss: 642.0637\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.1315 - val_loss: 641.6420\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.6981 - val_loss: 641.2461\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.2599 - val_loss: 640.7970\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.8171 - val_loss: 640.3734\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.3694 - val_loss: 639.9351\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.9173 - val_loss: 639.4781\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.4604 - val_loss: 639.0065\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.9988 - val_loss: 638.5653\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.5325 - val_loss: 638.1075\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.0616 - val_loss: 637.6558\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.5861 - val_loss: 637.1754\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.1060 - val_loss: 636.6812\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.6213 - val_loss: 636.1550\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.1320 - val_loss: 635.6703\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.6380 - val_loss: 635.1910\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.1396 - val_loss: 634.6182\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.6365 - val_loss: 634.0896\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.1290 - val_loss: 633.5381\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.6168 - val_loss: 633.0288\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.1002 - val_loss: 632.5631\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.5790 - val_loss: 632.0391\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.0533 - val_loss: 631.5024\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 660.5231 - val_loss: 630.9294\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.9885 - val_loss: 630.3538\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.4493 - val_loss: 629.8275\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.9058 - val_loss: 629.2544\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.3578 - val_loss: 628.7467\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.8053 - val_loss: 628.1808\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.2485 - val_loss: 627.5787\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.6873 - val_loss: 626.9772\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.1215 - val_loss: 626.4416\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.5514 - val_loss: 625.9640\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.9770 - val_loss: 625.3826\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.3983 - val_loss: 624.7810\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.8151 - val_loss: 624.1357\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 653.2275 - val_loss: 623.4932\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.6357 - val_loss: 622.8463\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.0396 - val_loss: 622.2971\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.4391 - val_loss: 621.6695\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.8344 - val_loss: 621.0286\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.2252 - val_loss: 620.4279\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.6119 - val_loss: 619.8339\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.9943 - val_loss: 619.2145\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.3726 - val_loss: 618.6620\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.7464 - val_loss: 617.9610\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.1160 - val_loss: 617.3317\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 646.4814 - val_loss: 616.7642\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.8427 - val_loss: 616.0874\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.1997 - val_loss: 615.3970\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.5526 - val_loss: 614.7508\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.9012 - val_loss: 614.0815\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.2456 - val_loss: 613.4413\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.5860 - val_loss: 612.7365\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.9221 - val_loss: 612.0117\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.2542 - val_loss: 611.3252\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.5821 - val_loss: 610.6490\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 639.9058 - val_loss: 609.9952\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.2255 - val_loss: 609.3221\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.5411 - val_loss: 608.6852\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.8525 - val_loss: 608.0106\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.1599 - val_loss: 607.3002\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.4632 - val_loss: 606.5829\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.7626 - val_loss: 605.9587\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.0577 - val_loss: 605.1649\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.3489 - val_loss: 604.4561\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.6361 - val_loss: 603.8365\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.9191 - val_loss: 603.1213\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.1982 - val_loss: 602.4019\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.4733 - val_loss: 601.6732\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.7445 - val_loss: 600.9312\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.0115 - val_loss: 600.1772\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.2748 - val_loss: 599.4478\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.5340 - val_loss: 598.7745\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.7892 - val_loss: 597.9057\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 627.0406 - val_loss: 597.0975\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 626.2879 - val_loss: 596.3674\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 625.5314 - val_loss: 595.5916\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.7709 - val_loss: 594.8682\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.0065 - val_loss: 594.2159\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.2382 - val_loss: 593.3576\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.4661 - val_loss: 592.6764\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.6901 - val_loss: 591.9533\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.9101 - val_loss: 591.1539\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.1264 - val_loss: 590.3137\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 619.3387 - val_loss: 589.4809\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.5473 - val_loss: 588.5373\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.7519 - val_loss: 587.6819\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.9529 - val_loss: 586.8845\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.1498 - val_loss: 586.1145\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.3430 - val_loss: 585.3875\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.5325 - val_loss: 584.5839\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.7181 - val_loss: 583.8478\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.9000 - val_loss: 583.0218\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.0781 - val_loss: 582.2310\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 611.2523 - val_loss: 581.4338\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 610.4230 - val_loss: 580.5566\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 609.5898 - val_loss: 579.7221\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.7529 - val_loss: 578.8490\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.9121 - val_loss: 577.9795\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.0677 - val_loss: 577.2021\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.2197 - val_loss: 576.3257\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.3678 - val_loss: 575.4382\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.5123 - val_loss: 574.6745\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.6531 - val_loss: 573.9803\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 602.7903 - val_loss: 573.0704\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 601.9237 - val_loss: 572.1002\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.0535 - val_loss: 571.3204\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 600.1796 - val_loss: 570.4373\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.3019 - val_loss: 569.6193\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.4209 - val_loss: 568.7255\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.5361 - val_loss: 567.7292\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.6476 - val_loss: 566.8027\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.7555 - val_loss: 565.9532\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.8598 - val_loss: 565.0649\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 593.9604 - val_loss: 564.2477\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 593.0576 - val_loss: 563.3281\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.1511 - val_loss: 562.4041\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.2410 - val_loss: 561.5031\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.3274 - val_loss: 560.5366\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.4102 - val_loss: 559.5442\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.4894 - val_loss: 558.5499\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.5652 - val_loss: 557.6431\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.6373 - val_loss: 556.6589\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.7059 - val_loss: 555.6814\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.7710 - val_loss: 554.6595\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 583.8324 - val_loss: 553.7870\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.8905 - val_loss: 552.8757\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.9450 - val_loss: 551.9725\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.9959 - val_loss: 550.9484\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.0435 - val_loss: 549.9901\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 579.0875 - val_loss: 549.0635\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 578.1281 - val_loss: 547.9944\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.3680 - val_loss: 547.2350\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.2034 - val_loss: 546.3028\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 575.2355 - val_loss: 545.4347\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 574.2630 - val_loss: 544.5268\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.4223 - val_loss: 543.7630\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.3118 - val_loss: 542.8475\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.3295 - val_loss: 541.8525\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 570.3660 - val_loss: 540.8220\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.4504 - val_loss: 539.9447\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.3731 - val_loss: 539.4835\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.3858 - val_loss: 538.8019\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.3892 - val_loss: 537.9686\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.3865 - val_loss: 537.1294\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.4685 - val_loss: 536.5320\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.3740 - val_loss: 535.6871\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.3611 - val_loss: 534.8476\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.3438 - val_loss: 533.9233\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.3822 - val_loss: 533.2405\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.3028 - val_loss: 532.1711\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.2762 - val_loss: 531.2242\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.2479 - val_loss: 530.0571\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.2157 - val_loss: 529.0476\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.1789 - val_loss: 528.0291\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.1379 - val_loss: 527.1292\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.0932 - val_loss: 526.1712\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.0450 - val_loss: 525.1984\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.0103 - val_loss: 524.0356\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.9431 - val_loss: 523.0604\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.0855 - val_loss: 522.0034\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.8304 - val_loss: 521.0696\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.7678 - val_loss: 520.1674\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.7007 - val_loss: 519.1354\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.6296 - val_loss: 518.0435\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.5988 - val_loss: 517.4844\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.5649 - val_loss: 516.5706\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.4271 - val_loss: 515.5770\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.3297 - val_loss: 514.5833\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.2452 - val_loss: 513.6034\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.1556 - val_loss: 512.6442\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 602.9796\n",
      "--- Starting trial: run-11\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 16, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 689.6522 - val_loss: 661.1212\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3977 - val_loss: 660.8277\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1372 - val_loss: 660.5320\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8660 - val_loss: 660.2311\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.5796 - val_loss: 659.9120\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.2722 - val_loss: 659.5739\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9385 - val_loss: 659.2126\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5717 - val_loss: 658.8149\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1647 - val_loss: 658.3783\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7091 - val_loss: 657.8893\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.1954 - val_loss: 657.3359\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.6124 - val_loss: 656.7084\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.9475 - val_loss: 655.9960\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.1859 - val_loss: 655.1682\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.3099 - val_loss: 654.2291\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.2998 - val_loss: 653.1329\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.1315 - val_loss: 651.8480\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.7777 - val_loss: 650.3762\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.2059 - val_loss: 648.6843\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.3782 - val_loss: 646.6952\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.2501 - val_loss: 644.3369\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.7699 - val_loss: 641.6138\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.8763 - val_loss: 638.4306\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.4980 - val_loss: 634.7328\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.5511 - val_loss: 630.4036\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.9376 - val_loss: 625.3560\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.5423 - val_loss: 619.4427\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.2299 - val_loss: 612.5215\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.8423 - val_loss: 604.4221\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.1940 - val_loss: 594.9261\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.0673 - val_loss: 583.7851\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.2068 - val_loss: 570.7739\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.3137 - val_loss: 555.4568\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.0367 - val_loss: 537.6331\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.9646 - val_loss: 517.5861\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.9339 - val_loss: 498.9688\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.5519 - val_loss: 478.2621\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.3176 - val_loss: 457.5076\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.1903 - val_loss: 438.0534\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 446.4029 - val_loss: 419.1746\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 426.2899 - val_loss: 400.5559\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.7560 - val_loss: 381.7311\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 394.5546 - val_loss: 362.7319\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 380.1525 - val_loss: 344.7987\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.8447 - val_loss: 327.0700\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.3548 - val_loss: 309.7387\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.9051 - val_loss: 289.7855\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 315.5981 - val_loss: 271.4001\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.7166 - val_loss: 250.4158\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283.7738 - val_loss: 227.1478\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 250.9109 - val_loss: 204.1626\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 226.0342 - val_loss: 178.1596\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.3891 - val_loss: 158.6640\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.9879 - val_loss: 148.9884\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.8892 - val_loss: 137.6953\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 169.1317 - val_loss: 129.5871\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 146.2615 - val_loss: 124.6247\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 152.6883 - val_loss: 122.1487\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 143.5019 - val_loss: 119.8561\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 147.2866 - val_loss: 115.6237\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.8996 - val_loss: 114.4219\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 137.2536 - val_loss: 102.0106\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.0125 - val_loss: 98.6877\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 148.1778 - val_loss: 96.7215\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.6659 - val_loss: 95.2780\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.1980 - val_loss: 92.3317\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.3464 - val_loss: 86.0623\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.1417 - val_loss: 91.0217\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.5656 - val_loss: 90.1996\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.3157 - val_loss: 102.7179\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.4792 - val_loss: 89.2927\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 139.5665 - val_loss: 85.9638\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 171.8615 - val_loss: 85.0370\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 136.8077 - val_loss: 86.4388\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.7686 - val_loss: 89.3696\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 140.6385 - val_loss: 88.6398\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 120.1480 - val_loss: 85.7968\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.8198 - val_loss: 85.3038\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 146.9243 - val_loss: 87.3943\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.4503 - val_loss: 87.2105\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.2368 - val_loss: 89.6901\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 145.5107 - val_loss: 118.5113\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.5910 - val_loss: 88.5220\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.9130 - val_loss: 91.8646\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.9184 - val_loss: 84.3691\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.1906 - val_loss: 82.9469\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.0398 - val_loss: 82.6872\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.3142 - val_loss: 82.9513\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 120.7941 - val_loss: 94.2369\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.5715 - val_loss: 88.4591\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.2070 - val_loss: 84.2934\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.1548 - val_loss: 83.1135\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.5341 - val_loss: 81.0120\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.7279 - val_loss: 81.6323\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 144.2044 - val_loss: 86.3616\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 121.0840 - val_loss: 98.0561\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.6699 - val_loss: 83.5003\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 156.7263 - val_loss: 80.9491\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.5206 - val_loss: 80.0428\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.4931 - val_loss: 81.3166\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.0182 - val_loss: 83.1043\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 142.3446 - val_loss: 81.6010\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 146.4353 - val_loss: 83.2983\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.2824 - val_loss: 85.7575\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2325 - val_loss: 88.1002\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.8481 - val_loss: 84.4171\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 130.6629 - val_loss: 82.6420\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 146.6538 - val_loss: 87.3153\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.3147 - val_loss: 81.3086\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.5870 - val_loss: 81.7659\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.7989 - val_loss: 89.5181\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.7806 - val_loss: 81.9225\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.3405 - val_loss: 91.5316\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 143.7054 - val_loss: 83.3648\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.3189 - val_loss: 82.4420\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.8074 - val_loss: 81.5693\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 139.1139 - val_loss: 80.4714\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.2045 - val_loss: 87.0195\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 134.4954 - val_loss: 94.2624\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.3703 - val_loss: 97.1767\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.4670 - val_loss: 78.8328\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4309 - val_loss: 91.7495\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.3409 - val_loss: 79.2055\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.9030 - val_loss: 78.6434\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.1979 - val_loss: 83.4846\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2507 - val_loss: 78.2355\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.6929 - val_loss: 82.7753\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.4848 - val_loss: 81.7277\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.9554 - val_loss: 83.6559\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.6017 - val_loss: 83.3100\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.8874 - val_loss: 103.1828\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2178 - val_loss: 85.2798\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2012 - val_loss: 85.8177\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.2929 - val_loss: 106.5593\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7570 - val_loss: 88.6397\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.3854 - val_loss: 87.4340\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.3370 - val_loss: 88.2366\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.2846 - val_loss: 89.9465\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.5430 - val_loss: 85.3341\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5191 - val_loss: 89.0977\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.9726 - val_loss: 82.6870\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.7709 - val_loss: 83.1572\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.2541 - val_loss: 79.8197\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.3905 - val_loss: 81.4019\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.7716 - val_loss: 79.1717\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.2638 - val_loss: 128.8030\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.5793 - val_loss: 78.8132\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 138.8041 - val_loss: 90.4209\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.6701 - val_loss: 85.8443\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.2876 - val_loss: 82.7318\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.7078 - val_loss: 112.8093\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.9813 - val_loss: 82.8761\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.8342 - val_loss: 110.4523\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.9066 - val_loss: 82.3909\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.6301 - val_loss: 99.1206\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.3615 - val_loss: 85.8733\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.3488 - val_loss: 84.8146\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.3008 - val_loss: 80.9466\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.5799 - val_loss: 86.6588\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.8481 - val_loss: 79.9796\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.1796 - val_loss: 88.3263\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.8543 - val_loss: 89.9895\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.5406 - val_loss: 82.7379\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.4656 - val_loss: 87.0255\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.3400 - val_loss: 90.8989\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.5405 - val_loss: 82.7217\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4035 - val_loss: 84.6899\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.5663 - val_loss: 88.6229\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8286 - val_loss: 78.5120\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.8129 - val_loss: 86.9664\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.2334 - val_loss: 87.9984\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.4448 - val_loss: 92.3305\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.2795 - val_loss: 103.7406\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.0135 - val_loss: 86.3990\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.0543 - val_loss: 87.6005\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.7637 - val_loss: 77.3583\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.5964 - val_loss: 77.7649\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.4301 - val_loss: 88.1370\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.2640 - val_loss: 124.0434\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 111.5434 - val_loss: 84.9146\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 128.1031 - val_loss: 80.7208\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 103.2609 - val_loss: 90.7607\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.7300 - val_loss: 78.2445\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 119.7055 - val_loss: 79.6799\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 150.5812 - val_loss: 80.1083\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.0144 - val_loss: 82.5728\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1004 - val_loss: 89.8352\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.8043 - val_loss: 79.9402\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0482 - val_loss: 87.8612\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.8530 - val_loss: 80.2377\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.9045 - val_loss: 81.2918\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.7713 - val_loss: 76.5652\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.2060 - val_loss: 95.3416\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.3469 - val_loss: 79.4905\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.7586 - val_loss: 87.1902\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.4070 - val_loss: 75.8681\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.6185 - val_loss: 87.3135\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5024 - val_loss: 86.3283\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.2131 - val_loss: 95.9810\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.7900 - val_loss: 87.9712\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.9030 - val_loss: 81.8542\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.4761 - val_loss: 79.5943\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.6492 - val_loss: 89.6489\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.7537 - val_loss: 80.2488\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5460 - val_loss: 80.5699\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4586 - val_loss: 115.7057\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.1354 - val_loss: 79.0665\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 134.6155 - val_loss: 77.2410\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.4224 - val_loss: 110.1904\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 122.2740 - val_loss: 99.9435\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 121.7032 - val_loss: 82.4491\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.1933 - val_loss: 85.1349\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.9702 - val_loss: 136.7551\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.5668 - val_loss: 84.4472\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2043 - val_loss: 81.2652\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.9197 - val_loss: 77.3110\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.8868 - val_loss: 77.7165\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4749 - val_loss: 82.0972\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.9373 - val_loss: 94.2994\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.0155 - val_loss: 82.3801\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.6083 - val_loss: 85.0837\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.4903 - val_loss: 108.4717\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.3524 - val_loss: 104.9846\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.5450 - val_loss: 93.9057\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 145.5063 - val_loss: 90.0457\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 152.8598 - val_loss: 87.6089\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.9513 - val_loss: 79.1024\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.9353 - val_loss: 79.9496\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5216 - val_loss: 95.0087\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.3782 - val_loss: 76.9088\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.7552 - val_loss: 77.3843\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.8905 - val_loss: 115.8660\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 110.2897 - val_loss: 106.0778\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.7513 - val_loss: 87.7945\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1125 - val_loss: 80.4464\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0418 - val_loss: 91.2078\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 153.9496 - val_loss: 80.9300\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.5517 - val_loss: 96.4050\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.0612 - val_loss: 92.9836\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.9467 - val_loss: 84.2423\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5920 - val_loss: 82.5011\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.7703 - val_loss: 98.4139\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.9899 - val_loss: 82.3654\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.6538 - val_loss: 87.2061\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.2751 - val_loss: 89.4613\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.5751 - val_loss: 82.1725\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.1749 - val_loss: 78.8554\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.1764 - val_loss: 85.1236\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 120.6685 - val_loss: 77.3668\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.5251 - val_loss: 75.8733\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 71.2454\n",
      "--- Starting trial: run-12\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 32, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7291 - val_loss: 660.6029\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.6677 - val_loss: 660.5469\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.6013 - val_loss: 660.4877\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5288 - val_loss: 660.4247\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4496 - val_loss: 660.3515\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3629 - val_loss: 660.2668\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2679 - val_loss: 660.1826\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1646 - val_loss: 660.0891\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0522 - val_loss: 659.9807\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9307 - val_loss: 659.8796\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7997 - val_loss: 659.7466\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6591 - val_loss: 659.6165\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5087 - val_loss: 659.4796\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.3483 - val_loss: 659.3427\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1782 - val_loss: 659.1870\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9976 - val_loss: 659.0210\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8069 - val_loss: 658.8636\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 687.6058 - val_loss: 658.6669\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.3944 - val_loss: 658.4727\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1726 - val_loss: 658.2675\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9403 - val_loss: 658.0677\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.6975 - val_loss: 657.8534\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.4442 - val_loss: 657.6334\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1804 - val_loss: 657.3766\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9058 - val_loss: 657.0988\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6207 - val_loss: 656.8134\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3251 - val_loss: 656.5261\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0189 - val_loss: 656.2388\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.7019 - val_loss: 655.9492\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3744 - val_loss: 655.6089\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.0362 - val_loss: 655.2908\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.6875 - val_loss: 654.9360\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3280 - val_loss: 654.5820\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.9580 - val_loss: 654.2326\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.5773 - val_loss: 653.8406\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.1861 - val_loss: 653.4561\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.7842 - val_loss: 653.0562\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.3719 - val_loss: 652.6709\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.9489 - val_loss: 652.2545\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.5153 - val_loss: 651.8187\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 680.0713 - val_loss: 651.3787\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.6166 - val_loss: 650.9444\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.1517 - val_loss: 650.5134\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.6761 - val_loss: 650.0583\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.1902 - val_loss: 649.6122\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 677.6939 - val_loss: 649.1281\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 677.1870 - val_loss: 648.6055\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 676.6699 - val_loss: 648.0552\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.1422 - val_loss: 647.5967\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 675.6043 - val_loss: 647.0888\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 675.0560 - val_loss: 646.5420\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.4974 - val_loss: 645.9780\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 673.9286 - val_loss: 645.4675\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 673.3496 - val_loss: 644.9053\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 672.7602 - val_loss: 644.3271\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 672.1608 - val_loss: 643.7221\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 671.5511 - val_loss: 643.1144\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 670.9312 - val_loss: 642.5126\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 670.3012 - val_loss: 641.9213\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 669.6611 - val_loss: 641.2782\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 669.0109 - val_loss: 640.6839\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.3507 - val_loss: 640.0396\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.6805 - val_loss: 639.3564\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 667.0002 - val_loss: 638.6049\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 666.3101 - val_loss: 637.8778\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 665.6099 - val_loss: 637.2070\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 664.8998 - val_loss: 636.4804\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 664.1799 - val_loss: 635.7406\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.4499 - val_loss: 634.9615\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 662.7103 - val_loss: 634.2089\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 661.9608 - val_loss: 633.5093\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 661.2014 - val_loss: 632.7670\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.4324 - val_loss: 632.0746\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659.6535 - val_loss: 631.2442\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.8651 - val_loss: 630.4492\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.0668 - val_loss: 629.6414\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 657.2590 - val_loss: 628.8705\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.4415 - val_loss: 628.0679\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.6143 - val_loss: 627.2233\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 654.7776 - val_loss: 626.3994\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.9314 - val_loss: 625.6047\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.0756 - val_loss: 624.8062\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.2103 - val_loss: 624.0065\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 651.3356 - val_loss: 623.1351\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.4515 - val_loss: 622.2540\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.5578 - val_loss: 621.4076\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 648.6548 - val_loss: 620.4223\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.7423 - val_loss: 619.4792\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.8206 - val_loss: 618.5564\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.8895 - val_loss: 617.5637\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.9491 - val_loss: 616.6133\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 643.9995 - val_loss: 615.6620\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 643.0406 - val_loss: 614.6591\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.0725 - val_loss: 613.7117\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.0953 - val_loss: 612.6953\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.1088 - val_loss: 611.7115\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 639.1132 - val_loss: 610.7616\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.1085 - val_loss: 609.7769\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.0947 - val_loss: 608.7396\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 636.0717 - val_loss: 607.7261\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.0398 - val_loss: 606.7941\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.9988 - val_loss: 605.8112\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.9489 - val_loss: 604.7364\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.8900 - val_loss: 603.7057\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 630.8220 - val_loss: 602.7243\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.7452 - val_loss: 601.6406\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.6595 - val_loss: 600.5016\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 627.5649 - val_loss: 599.3786\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.4615 - val_loss: 598.2904\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.3493 - val_loss: 597.1300\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.2282 - val_loss: 595.9751\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.0984 - val_loss: 594.7939\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.9597 - val_loss: 593.7159\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.8124 - val_loss: 592.6686\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.6564 - val_loss: 591.4637\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.4916 - val_loss: 590.3690\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.3182 - val_loss: 589.1589\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.1362 - val_loss: 587.9647\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.9455 - val_loss: 586.8563\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 613.7463 - val_loss: 585.7350\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 612.5383 - val_loss: 584.4974\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.3220 - val_loss: 583.2045\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 610.0971 - val_loss: 581.9741\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 608.8636 - val_loss: 580.7586\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.6217 - val_loss: 579.5675\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.3713 - val_loss: 578.3671\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.1124 - val_loss: 577.1381\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.8453 - val_loss: 575.9153\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.5696 - val_loss: 574.6287\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.2855 - val_loss: 573.4962\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.9933 - val_loss: 572.2735\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.6924 - val_loss: 571.0128\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.3834 - val_loss: 569.7456\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.0662 - val_loss: 568.4216\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.7405 - val_loss: 567.1048\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.4067 - val_loss: 565.7141\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.0646 - val_loss: 564.3685\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.7144 - val_loss: 563.0124\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.3558 - val_loss: 561.7128\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.9893 - val_loss: 560.4212\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.6144 - val_loss: 559.0579\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 585.2316 - val_loss: 557.5953\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 583.8405 - val_loss: 556.0927\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.4415 - val_loss: 554.8141\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.0342 - val_loss: 553.5312\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.6191 - val_loss: 552.2326\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.1958 - val_loss: 550.7827\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.7645 - val_loss: 549.2929\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.3253 - val_loss: 547.9966\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.8781 - val_loss: 546.6781\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.4230 - val_loss: 545.2512\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 570.9600 - val_loss: 543.8397\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.4889 - val_loss: 542.3276\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.0101 - val_loss: 540.8948\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.5233 - val_loss: 539.3222\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.0287 - val_loss: 537.8148\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.5262 - val_loss: 536.2629\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.0159 - val_loss: 534.7370\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.4979 - val_loss: 533.2734\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.9720 - val_loss: 531.6854\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.4385 - val_loss: 530.1096\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.8972 - val_loss: 528.6252\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.3481 - val_loss: 527.0353\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.8613 - val_loss: 528.9363\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.2346 - val_loss: 527.8333\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.6644 - val_loss: 526.0598\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.0854 - val_loss: 524.1695\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.4983 - val_loss: 522.4084\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.9033 - val_loss: 520.4198\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.3005 - val_loss: 518.6167\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.6902 - val_loss: 516.7885\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.0723 - val_loss: 514.9687\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.4469 - val_loss: 513.2234\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.8139 - val_loss: 511.4856\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.1768 - val_loss: 513.5143\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.5323 - val_loss: 514.7745\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 531.8798 - val_loss: 514.2861\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.2181 - val_loss: 512.5340\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 528.5481 - val_loss: 510.6327\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.8704 - val_loss: 508.6012\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.1851 - val_loss: 506.6112\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 523.4924 - val_loss: 504.6035\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 521.7924 - val_loss: 502.6395\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.0848 - val_loss: 500.7768\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.3700 - val_loss: 498.7313\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.6479 - val_loss: 496.7374\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.9184 - val_loss: 494.8225\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.2363 - val_loss: 494.1488\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 511.4447 - val_loss: 493.2146\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.6963 - val_loss: 491.5648\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.9389 - val_loss: 489.4040\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 506.1736 - val_loss: 487.1780\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504.4006 - val_loss: 485.3662\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.6204 - val_loss: 483.4250\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 500.8329 - val_loss: 481.4774\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.0381 - val_loss: 479.6663\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.2363 - val_loss: 477.5406\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.4272 - val_loss: 475.6371\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.6111 - val_loss: 473.6044\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 491.8615 - val_loss: 472.3089\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 489.9622 - val_loss: 471.8863\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 488.1285 - val_loss: 470.4984\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 486.2856 - val_loss: 468.3649\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 484.4346 - val_loss: 466.5379\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 482.5762 - val_loss: 464.6247\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 480.7106 - val_loss: 462.7697\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 478.8401 - val_loss: 461.1927\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.1302 - val_loss: 460.8485\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.0959 - val_loss: 459.7320\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.2101 - val_loss: 457.9368\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.3126 - val_loss: 456.1962\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.4061 - val_loss: 454.4778\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.7433 - val_loss: 452.4097\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.7984 - val_loss: 453.1980\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.7393 - val_loss: 452.4069\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.8259 - val_loss: 450.4165\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.1075 - val_loss: 448.4144\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.0869 - val_loss: 448.6593\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.1686 - val_loss: 447.5884\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 454.1360 - val_loss: 445.3281\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.2592 - val_loss: 442.9316\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.4052 - val_loss: 440.4445\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.3542 - val_loss: 438.4410\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 446.2985 - val_loss: 435.6531\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 444.2786 - val_loss: 433.4304\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 442.3189 - val_loss: 430.7104\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.3914 - val_loss: 428.8050\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.4185 - val_loss: 426.5656\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.3080 - val_loss: 424.5907\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 434.2814 - val_loss: 422.2940\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.7549 - val_loss: 420.7139\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.5154 - val_loss: 418.7516\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.4070 - val_loss: 416.6684\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 426.4471 - val_loss: 414.6812\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.4884 - val_loss: 412.9614\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 422.4243 - val_loss: 410.1634\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.4093 - val_loss: 408.1453\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.9866 - val_loss: 405.4055\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.4437 - val_loss: 403.4502\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 414.5404 - val_loss: 401.4124\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.3291 - val_loss: 399.5869\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.2930 - val_loss: 397.6308\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 407.9415 - val_loss: 395.4123\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.2453 - val_loss: 393.9439\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.8934 - val_loss: 392.3974\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 401.7803 - val_loss: 389.9142\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.6375 - val_loss: 387.8501\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.6861 - val_loss: 385.8864\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.7095 - val_loss: 383.8317\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.0890 - val_loss: 381.1398\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 435.1080\n",
      "--- Starting trial: run-13\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 32, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6589 - val_loss: 660.2973\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4213 - val_loss: 660.0596\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.1784 - val_loss: 659.8142\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9259 - val_loss: 659.5533\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.6594 - val_loss: 659.2808\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 688.3743 - val_loss: 658.9779\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0652 - val_loss: 658.6541\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7263 - val_loss: 658.3070\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.3511 - val_loss: 657.9210\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9319 - val_loss: 657.4700\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4604 - val_loss: 656.9658\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.9265 - val_loss: 656.3920\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3184 - val_loss: 655.7385\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.6230 - val_loss: 655.0013\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.8246 - val_loss: 654.1412\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.9048 - val_loss: 653.1475\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.8425 - val_loss: 652.0058\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.6126 - val_loss: 650.6896\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.1859 - val_loss: 649.1588\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.5283 - val_loss: 647.3657\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.5994 - val_loss: 645.2870\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.3525 - val_loss: 642.8417\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.7327 - val_loss: 640.0047\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.6752 - val_loss: 636.6803\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.1046 - val_loss: 632.8140\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.9319 - val_loss: 628.2735\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.0536 - val_loss: 622.9523\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 649.3475 - val_loss: 616.7447\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 642.6708 - val_loss: 609.4368\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.8560 - val_loss: 600.9111\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.7064 - val_loss: 590.9358\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.9919 - val_loss: 579.2234\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.4423 - val_loss: 565.5252\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.7408 - val_loss: 549.4699\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 570.5162 - val_loss: 530.5818\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.5089 - val_loss: 509.2796\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.4960 - val_loss: 486.7917\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.1593 - val_loss: 461.6779\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.8839 - val_loss: 435.0935\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.7428 - val_loss: 407.8012\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.5978 - val_loss: 384.2953\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.7867 - val_loss: 352.8694\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.5910 - val_loss: 332.3309\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 338.7802 - val_loss: 317.4610\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 315.2104 - val_loss: 286.8559\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.6453 - val_loss: 266.5988\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.9024 - val_loss: 237.9939\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 245.8858 - val_loss: 210.8477\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.7907 - val_loss: 209.0677\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 172.1313 - val_loss: 274.0345\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 147.2345 - val_loss: 262.2627\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.9977 - val_loss: 248.9113\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.5802 - val_loss: 366.1183\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.7898 - val_loss: 369.1698\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.2015 - val_loss: 248.7403\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.0121 - val_loss: 392.2798\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.1370 - val_loss: 360.5413\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8203 - val_loss: 335.2435\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0957 - val_loss: 293.5121\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2708 - val_loss: 174.2046\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8250 - val_loss: 203.3774\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4747 - val_loss: 157.2867\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.0721 - val_loss: 348.5399\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 69.9890 - val_loss: 223.5724\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6051 - val_loss: 240.5098\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.7514 - val_loss: 224.2581\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.0295 - val_loss: 191.2943\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.2836 - val_loss: 172.9089\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.0141 - val_loss: 128.5293\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2953 - val_loss: 139.1430\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.1119 - val_loss: 197.5736\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.0833 - val_loss: 151.1359\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.2377 - val_loss: 98.1180\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.0801 - val_loss: 80.6425\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.8246 - val_loss: 149.1320\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.4794 - val_loss: 111.4318\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 92.1106 - val_loss: 131.9576\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1259 - val_loss: 158.4767\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.9692 - val_loss: 134.6397\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.5792 - val_loss: 120.0096\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 134.3709 - val_loss: 128.3557\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.7675 - val_loss: 82.3886\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.1213 - val_loss: 80.9001\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.2929 - val_loss: 72.9684\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.3673 - val_loss: 72.7774\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6744 - val_loss: 98.0847\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.4916 - val_loss: 112.3608\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.8818 - val_loss: 100.1818\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 74.7854 - val_loss: 71.7921\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.2186 - val_loss: 97.8601\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.9128 - val_loss: 81.8444\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.8669 - val_loss: 93.6087\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.3056 - val_loss: 75.8267\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.9464 - val_loss: 92.8924\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.4471 - val_loss: 89.0832\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.8276 - val_loss: 70.4003\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 70.0333 - val_loss: 98.8292\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.7500 - val_loss: 84.6342\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.1160 - val_loss: 85.8166\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.9570 - val_loss: 98.1969\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7234 - val_loss: 72.0629\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.5392 - val_loss: 79.2452\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.1519 - val_loss: 93.2368\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.1665 - val_loss: 76.7999\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.6009 - val_loss: 66.7794\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5523 - val_loss: 83.8842\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0229 - val_loss: 78.4931\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9987 - val_loss: 90.6212\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1013 - val_loss: 79.0279\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5614 - val_loss: 90.6794\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8374 - val_loss: 85.8988\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.3976 - val_loss: 73.6811\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.5486 - val_loss: 69.0287\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8918 - val_loss: 77.9682\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4327 - val_loss: 69.0370\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6130 - val_loss: 76.6430\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9722 - val_loss: 69.3691\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9861 - val_loss: 67.0951\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.4732 - val_loss: 89.9093\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.0907 - val_loss: 76.1042\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6947 - val_loss: 80.1572\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.8852 - val_loss: 75.6640\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.8256 - val_loss: 83.7238\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6776 - val_loss: 73.5732\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7595 - val_loss: 72.2643\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.6903 - val_loss: 70.7783\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1507 - val_loss: 67.8721\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.3607 - val_loss: 72.9251\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5629 - val_loss: 81.5895\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.9410 - val_loss: 74.8036\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8328 - val_loss: 78.2284\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6497 - val_loss: 64.5601\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9933 - val_loss: 75.9067\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4038 - val_loss: 72.8057\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.5593 - val_loss: 79.0201\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.0178 - val_loss: 74.5121\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.6138 - val_loss: 68.3380\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.3108 - val_loss: 70.8620\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1311 - val_loss: 72.3791\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2475 - val_loss: 78.5066\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8256 - val_loss: 68.8218\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.3283 - val_loss: 63.8543\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4511 - val_loss: 68.7343\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9881 - val_loss: 64.1823\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9187 - val_loss: 71.5031\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.2112 - val_loss: 73.2916\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.5886 - val_loss: 70.2942\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.9292 - val_loss: 67.2311\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1228 - val_loss: 76.3895\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.9151 - val_loss: 66.8701\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.5918 - val_loss: 70.3955\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 86.8097 - val_loss: 76.0382\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9405 - val_loss: 66.3255\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0767 - val_loss: 66.4132\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9615 - val_loss: 67.2711\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9202 - val_loss: 64.1774\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0258 - val_loss: 68.1644\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1435 - val_loss: 65.3043\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5385 - val_loss: 71.9186\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4260 - val_loss: 70.5861\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8644 - val_loss: 78.2475\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1800 - val_loss: 69.7982\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4838 - val_loss: 69.1617\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.7635 - val_loss: 62.3368\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0269 - val_loss: 65.7335\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8109 - val_loss: 73.9782\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0993 - val_loss: 81.8265\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3029 - val_loss: 79.1693\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.0331 - val_loss: 75.3373\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8110 - val_loss: 69.9977\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.9698 - val_loss: 76.1220\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5652 - val_loss: 74.7541\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1567 - val_loss: 66.9729\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2652 - val_loss: 64.2557\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8138 - val_loss: 69.7888\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1148 - val_loss: 73.3584\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0604 - val_loss: 64.5407\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9289 - val_loss: 75.3945\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.2354 - val_loss: 67.3313\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6027 - val_loss: 70.1562\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 64.3843 - val_loss: 71.4363\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.1470 - val_loss: 74.1280\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.6775 - val_loss: 69.8725\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 132.7907 - val_loss: 66.4616\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8367 - val_loss: 67.7878\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 62.1041 - val_loss: 63.8330\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5587 - val_loss: 64.3353\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.1612 - val_loss: 67.4031\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 61.9595 - val_loss: 65.5593\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6756 - val_loss: 63.9956\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.9183 - val_loss: 66.4878\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.5826 - val_loss: 64.2533\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 70.2105 - val_loss: 65.6754\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 149.9950 - val_loss: 62.4904\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.0196 - val_loss: 62.7569\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.9231 - val_loss: 71.0276\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.1295 - val_loss: 72.8956\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.6822 - val_loss: 71.5407\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 129.3142 - val_loss: 66.6525\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.9781 - val_loss: 66.5073\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.2653 - val_loss: 63.3208\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0462 - val_loss: 69.7753\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.2284 - val_loss: 69.8444\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.5278 - val_loss: 72.2447\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.3263 - val_loss: 67.1440\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.5637 - val_loss: 70.3487\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.1227 - val_loss: 70.6028\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6741 - val_loss: 64.2975\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.5380 - val_loss: 71.5165\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.8274 - val_loss: 70.7358\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7346 - val_loss: 69.7653\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9388 - val_loss: 84.5138\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.4227 - val_loss: 77.1172\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.1187 - val_loss: 80.6888\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9678 - val_loss: 71.6660\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 90.2868 - val_loss: 79.8267\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.6994 - val_loss: 69.5523\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.8176 - val_loss: 76.1005\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7029 - val_loss: 71.1791\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6245 - val_loss: 68.4746\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1302 - val_loss: 70.4122\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 88.2794 - val_loss: 67.4341\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.8510 - val_loss: 61.3072\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 103.9912 - val_loss: 67.9436\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.3564 - val_loss: 73.0469\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.1160 - val_loss: 79.6872\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 75.6196 - val_loss: 68.7689\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 80.0587 - val_loss: 69.3358\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 95.4512 - val_loss: 68.1880\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.9904 - val_loss: 65.4189\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0918 - val_loss: 76.7470\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 103.6274 - val_loss: 68.3134\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 101.7759 - val_loss: 65.9926\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.4747 - val_loss: 63.1442\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.5724 - val_loss: 66.9976\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.7151 - val_loss: 64.4781\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 102.3623 - val_loss: 67.9533\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.8875 - val_loss: 68.3513\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4380 - val_loss: 67.0315\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6288 - val_loss: 64.1629\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.7063 - val_loss: 65.5465\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.0862 - val_loss: 74.3913\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.5270 - val_loss: 68.6104\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.1255 - val_loss: 79.4504\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1632 - val_loss: 67.2877\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.3188 - val_loss: 64.2478\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.3927 - val_loss: 64.2118\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7392 - val_loss: 61.1381\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1044 - val_loss: 63.0929\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7833 - val_loss: 61.6685\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 42.8319\n",
      "--- Starting trial: run-14\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 32, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.7266 - val_loss: 660.1701\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6589 - val_loss: 660.0972\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5862 - val_loss: 660.0182\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.5075 - val_loss: 659.9326\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4221 - val_loss: 659.8376\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3292 - val_loss: 659.7308\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2284 - val_loss: 659.6229\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.1191 - val_loss: 659.4999\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.0011 - val_loss: 659.3712\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.8739 - val_loss: 659.2415\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.7375 - val_loss: 659.0919\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 688.5916 - val_loss: 658.9352\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 688.4360 - val_loss: 658.7731\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.2707 - val_loss: 658.6010\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.0955 - val_loss: 658.4280\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.9103 - val_loss: 658.2362\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.7149 - val_loss: 658.0438\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.5093 - val_loss: 657.8239\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2935 - val_loss: 657.5840\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0674 - val_loss: 657.3532\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.8309 - val_loss: 657.1026\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.5841 - val_loss: 656.8448\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.3268 - val_loss: 656.5955\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.0590 - val_loss: 656.3169\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.7809 - val_loss: 656.0438\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.4921 - val_loss: 655.7567\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1927 - val_loss: 655.4449\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.8829 - val_loss: 655.1326\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.5626 - val_loss: 654.8204\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.2316 - val_loss: 654.5110\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.8902 - val_loss: 654.1763\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 683.5382 - val_loss: 653.8220\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 683.1755 - val_loss: 653.4581\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.8024 - val_loss: 653.1002\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.4188 - val_loss: 652.6917\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.0245 - val_loss: 652.3047\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.6198 - val_loss: 651.8907\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.2045 - val_loss: 651.4651\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.7788 - val_loss: 651.0319\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.3425 - val_loss: 650.5898\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.8958 - val_loss: 650.1540\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.4385 - val_loss: 649.7057\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.9709 - val_loss: 649.2302\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.4928 - val_loss: 648.7467\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.0043 - val_loss: 648.2465\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.5054 - val_loss: 647.7271\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.9962 - val_loss: 647.2164\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.4765 - val_loss: 646.7084\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.9466 - val_loss: 646.1938\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.4063 - val_loss: 645.6519\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.8558 - val_loss: 645.1361\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.2949 - val_loss: 644.5967\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 673.7239 - val_loss: 644.0851\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.1426 - val_loss: 643.5529\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.5511 - val_loss: 642.9760\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.9495 - val_loss: 642.3901\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.3376 - val_loss: 641.7773\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.7156 - val_loss: 641.1340\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.0836 - val_loss: 640.5054\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.4415 - val_loss: 639.9143\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.7893 - val_loss: 639.3211\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.1271 - val_loss: 638.7273\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.4548 - val_loss: 638.0803\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.7727 - val_loss: 637.4963\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.0805 - val_loss: 636.9011\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.3784 - val_loss: 636.2439\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.6664 - val_loss: 635.4743\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.9446 - val_loss: 634.7297\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.2129 - val_loss: 633.8827\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.4713 - val_loss: 633.0307\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.7200 - val_loss: 632.3178\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.9587 - val_loss: 631.5033\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.1880 - val_loss: 630.6526\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.4073 - val_loss: 629.8171\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.6171 - val_loss: 629.1304\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.8170 - val_loss: 628.3673\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.0075 - val_loss: 627.5290\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.1882 - val_loss: 626.6918\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.3594 - val_loss: 625.8981\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.5211 - val_loss: 625.0784\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.6730 - val_loss: 624.2795\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.8155 - val_loss: 623.5297\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.9486 - val_loss: 622.7277\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 651.0722 - val_loss: 621.8162\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.1863 - val_loss: 621.0549\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.2911 - val_loss: 620.1984\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.3864 - val_loss: 619.2986\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.4723 - val_loss: 618.4294\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 646.5490 - val_loss: 617.5192\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 645.6163 - val_loss: 616.5762\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.6743 - val_loss: 615.5764\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.7230 - val_loss: 614.5377\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.7626 - val_loss: 613.4395\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.7929 - val_loss: 612.2605\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.8140 - val_loss: 611.2610\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.8259 - val_loss: 610.2459\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.8288 - val_loss: 608.9742\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.8224 - val_loss: 607.7157\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.8070 - val_loss: 606.6332\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.7826 - val_loss: 605.5291\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 634.7491 - val_loss: 604.4490\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.7066 - val_loss: 603.4084\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 632.6550 - val_loss: 602.3420\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.5946 - val_loss: 601.2939\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 630.5251 - val_loss: 600.2352\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.4468 - val_loss: 599.1086\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 628.3596 - val_loss: 598.1017\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 627.2635 - val_loss: 597.0855\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 626.1585 - val_loss: 596.1575\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.0447 - val_loss: 595.3380\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.9221 - val_loss: 594.2977\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.7907 - val_loss: 593.1572\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 621.6506 - val_loss: 592.0945\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.5017 - val_loss: 591.1802\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.3442 - val_loss: 590.0607\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.1780 - val_loss: 588.8495\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 617.0030 - val_loss: 587.7319\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 615.8195 - val_loss: 586.7148\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.6273 - val_loss: 585.5686\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 613.4265 - val_loss: 584.2982\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.2172 - val_loss: 583.1937\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.9992 - val_loss: 582.0405\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 609.7728 - val_loss: 580.6465\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.5378 - val_loss: 579.0233\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.2945 - val_loss: 577.5798\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.0425 - val_loss: 576.2791\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.7822 - val_loss: 574.9290\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.5135 - val_loss: 573.5221\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.2363 - val_loss: 572.0409\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.9509 - val_loss: 570.7013\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.6569 - val_loss: 569.4232\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.3547 - val_loss: 568.0967\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.0441 - val_loss: 566.8322\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.7253 - val_loss: 565.5436\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.3983 - val_loss: 564.1632\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.0629 - val_loss: 562.8272\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.7194 - val_loss: 561.6265\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 590.3675 - val_loss: 560.3146\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 589.0076 - val_loss: 558.8390\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.6395 - val_loss: 557.4143\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.3305 - val_loss: 555.6031\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.8862 - val_loss: 553.5850\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.4959 - val_loss: 551.9985\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.0961 - val_loss: 550.6851\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.6877 - val_loss: 549.3008\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.2711 - val_loss: 548.0593\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.8463 - val_loss: 546.7248\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.5853 - val_loss: 544.3123\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.9803 - val_loss: 542.5439\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.5338 - val_loss: 541.1864\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.0779 - val_loss: 539.8833\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 570.6134 - val_loss: 538.5554\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.1408 - val_loss: 537.2348\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.6603 - val_loss: 535.8873\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.1718 - val_loss: 534.6434\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.6754 - val_loss: 533.4523\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.1712 - val_loss: 532.1531\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.6591 - val_loss: 530.8016\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.1393 - val_loss: 529.4818\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.6116 - val_loss: 528.1839\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.1100 - val_loss: 526.8242\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.5477 - val_loss: 524.1358\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.0148 - val_loss: 522.3212\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.4643 - val_loss: 520.8282\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.9011 - val_loss: 519.5096\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.4017 - val_loss: 516.7711\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.7540 - val_loss: 514.7108\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 546.1675 - val_loss: 513.2275\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.5717 - val_loss: 511.8886\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.9672 - val_loss: 510.6702\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.4661 - val_loss: 509.4831\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.7403 - val_loss: 508.4452\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.1161 - val_loss: 507.2101\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.4824 - val_loss: 505.7652\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.8403 - val_loss: 504.5325\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.1901 - val_loss: 503.1554\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.5325 - val_loss: 501.5446\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 529.8672 - val_loss: 500.1602\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 528.1945 - val_loss: 498.8309\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.5801 - val_loss: 498.0342\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 524.9401 - val_loss: 497.6138\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.1575 - val_loss: 496.1916\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 521.4685 - val_loss: 494.6899\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.7595 - val_loss: 492.9400\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 518.0464 - val_loss: 491.4295\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 516.3234 - val_loss: 489.8772\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.5921 - val_loss: 488.0688\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.8560 - val_loss: 487.6100\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 511.1136 - val_loss: 487.2168\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.3629 - val_loss: 486.0648\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.7843 - val_loss: 484.5812\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.8488 - val_loss: 482.5108\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504.2979 - val_loss: 481.4134\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.3046 - val_loss: 480.5095\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 500.5347 - val_loss: 479.4297\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 498.7284 - val_loss: 478.3583\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 496.9274 - val_loss: 476.9703\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.1170 - val_loss: 475.0180\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 493.5079 - val_loss: 472.4555\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 491.5247 - val_loss: 468.9103\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.7073 - val_loss: 467.6958\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 487.8257 - val_loss: 467.9586\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 485.9838 - val_loss: 467.1954\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.1314 - val_loss: 465.5807\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 482.2704 - val_loss: 463.8203\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.4340 - val_loss: 461.8631\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 478.5660 - val_loss: 459.8002\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 476.8959 - val_loss: 457.9765\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 474.8074 - val_loss: 456.1825\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.5391 - val_loss: 456.6040\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.0322 - val_loss: 456.5075\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 469.6561 - val_loss: 454.9648\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.2502 - val_loss: 452.8626\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.6102 - val_loss: 450.9997\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.4419 - val_loss: 450.1782\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.5550 - val_loss: 448.6714\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 459.9443 - val_loss: 446.9202\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.7353 - val_loss: 445.3552\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 455.7293 - val_loss: 443.9444\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 454.1307 - val_loss: 441.5672\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 452.1839 - val_loss: 440.4486\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.0121 - val_loss: 439.1931\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.0879 - val_loss: 437.8433\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.9435 - val_loss: 435.2626\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 444.1107 - val_loss: 433.9269\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.3141 - val_loss: 430.5151\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.9844 - val_loss: 427.9323\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.2302 - val_loss: 427.4440\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.3490 - val_loss: 430.7750\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.5415 - val_loss: 431.3310\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.2344 - val_loss: 430.3665\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.5743 - val_loss: 428.8103\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.7994 - val_loss: 425.3391\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 427.0213 - val_loss: 422.3954\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.5787 - val_loss: 420.5499\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 422.3858 - val_loss: 417.1839\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.2888 - val_loss: 413.8816\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.8344 - val_loss: 410.9586\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.6019 - val_loss: 408.0220\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 414.5825 - val_loss: 404.4380\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.8395 - val_loss: 402.1949\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.0276 - val_loss: 396.6914\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 409.7870 - val_loss: 393.4283\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.6564 - val_loss: 391.1970\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 404.4714 - val_loss: 389.1862\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 402.2103 - val_loss: 387.4047\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 400.9668 - val_loss: 386.0005\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.6584 - val_loss: 384.6145\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.5174 - val_loss: 383.8289\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.8739 - val_loss: 385.6364\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 435.3519\n",
      "--- Starting trial: run-15\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 32, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6667 - val_loss: 659.5801\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4490 - val_loss: 659.3931\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2267 - val_loss: 659.1967\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.9960 - val_loss: 658.9807\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7531 - val_loss: 658.7509\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4939 - val_loss: 658.4971\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2137 - val_loss: 658.2123\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9077 - val_loss: 657.8979\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5698 - val_loss: 657.5453\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1934 - val_loss: 657.1541\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.7714 - val_loss: 656.7109\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.2949 - val_loss: 656.2097\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.7536 - val_loss: 655.6263\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1359 - val_loss: 654.9603\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.4283 - val_loss: 654.1931\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.6147 - val_loss: 653.3010\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.6766 - val_loss: 652.2838\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.5919 - val_loss: 651.0959\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.3354 - val_loss: 649.7137\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.8771 - val_loss: 648.0987\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.1820 - val_loss: 646.2370\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.2092 - val_loss: 644.0552\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.9103 - val_loss: 641.5411\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.2292 - val_loss: 638.5994\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 667.0997 - val_loss: 635.1463\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.4445 - val_loss: 631.0864\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.1726 - val_loss: 626.3541\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.1776 - val_loss: 620.8690\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.3347 - val_loss: 614.3670\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.4976 - val_loss: 606.8150\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.4945 - val_loss: 598.0037\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.1241 - val_loss: 587.6591\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 613.1507 - val_loss: 575.4825\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.2974 - val_loss: 561.3193\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.4392 - val_loss: 546.0447\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.3649 - val_loss: 528.3707\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.1742 - val_loss: 509.2281\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.3566 - val_loss: 485.8528\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.7466 - val_loss: 460.3704\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 476.7542 - val_loss: 434.0466\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 448.2756 - val_loss: 399.6445\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.8181 - val_loss: 363.3009\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.4274 - val_loss: 333.8251\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.6758 - val_loss: 316.1536\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.7923 - val_loss: 294.1766\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 332.3384 - val_loss: 264.9784\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 314.9587 - val_loss: 242.7510\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 288.6559 - val_loss: 229.0546\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.8402 - val_loss: 184.7401\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.4898 - val_loss: 189.8411\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.7169 - val_loss: 180.9706\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 171.4234 - val_loss: 156.3170\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 150.9174 - val_loss: 178.0622\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.9529 - val_loss: 259.1525\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.3493 - val_loss: 275.9644\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6162 - val_loss: 226.1248\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2860 - val_loss: 262.4301\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1652 - val_loss: 257.6036\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.0552 - val_loss: 201.4926\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1632 - val_loss: 176.1669\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.2521 - val_loss: 173.7395\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.2774 - val_loss: 190.1600\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2016 - val_loss: 173.6344\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2449 - val_loss: 190.8118\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9255 - val_loss: 191.7480\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.4304 - val_loss: 147.6265\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.2898 - val_loss: 125.5637\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.7611 - val_loss: 139.5895\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.1093 - val_loss: 130.7382\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5872 - val_loss: 133.2631\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4948 - val_loss: 122.2307\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.4791 - val_loss: 99.8277\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2830 - val_loss: 102.5011\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8969 - val_loss: 95.4336\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2582 - val_loss: 126.8869\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.2774 - val_loss: 104.3988\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.5938 - val_loss: 82.7017\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8791 - val_loss: 84.0910\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.1954 - val_loss: 78.7557\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4017 - val_loss: 79.0840\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0663 - val_loss: 73.9718\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0571 - val_loss: 80.1702\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1460 - val_loss: 91.1771\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3139 - val_loss: 83.4913\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.6753 - val_loss: 90.7744\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.6133 - val_loss: 99.8216\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7639 - val_loss: 94.7444\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.4752 - val_loss: 90.1289\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.6830 - val_loss: 73.4110\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.9792 - val_loss: 84.3631\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.5743 - val_loss: 71.4786\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.6816 - val_loss: 72.5803\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.4644 - val_loss: 94.0414\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.8302 - val_loss: 77.5939\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.2989 - val_loss: 73.0147\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0758 - val_loss: 69.5880\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5636 - val_loss: 71.8363\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.4409 - val_loss: 80.1919\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.7942 - val_loss: 72.9766\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4048 - val_loss: 79.6481\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4506 - val_loss: 64.6615\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.2833 - val_loss: 70.4897\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.9331 - val_loss: 64.0084\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.3938 - val_loss: 65.2076\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4224 - val_loss: 71.1312\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.5556 - val_loss: 66.4018\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.6119 - val_loss: 77.9834\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1184 - val_loss: 91.9803\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1391 - val_loss: 97.1629\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3835 - val_loss: 87.5057\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.7390 - val_loss: 71.3857\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.0279 - val_loss: 65.9261\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.9099 - val_loss: 64.5037\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8693 - val_loss: 79.3853\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.1110 - val_loss: 66.3410\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8420 - val_loss: 64.3571\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7476 - val_loss: 67.7424\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0525 - val_loss: 64.3361\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1605 - val_loss: 64.3509\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.2375 - val_loss: 69.1767\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5370 - val_loss: 74.2228\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1553 - val_loss: 68.7117\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6720 - val_loss: 72.2514\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0065 - val_loss: 73.2931\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.5715 - val_loss: 63.6246\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.9712 - val_loss: 62.8145\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.8092 - val_loss: 67.7220\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4673 - val_loss: 72.3428\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.5636 - val_loss: 64.1807\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6916 - val_loss: 68.1478\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4336 - val_loss: 72.2665\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.3235 - val_loss: 66.4297\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.5150 - val_loss: 64.3073\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 69.4520 - val_loss: 61.5018\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.2833 - val_loss: 64.3584\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0003 - val_loss: 69.5823\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4895 - val_loss: 70.6846\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.8634 - val_loss: 63.0247\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.2916 - val_loss: 65.4239\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2882 - val_loss: 68.3406\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9766 - val_loss: 63.8089\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9986 - val_loss: 74.7724\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.3057 - val_loss: 72.2859\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.9986 - val_loss: 64.8895\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.7439 - val_loss: 68.0397\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 66.5426 - val_loss: 64.9248\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.8942 - val_loss: 61.1667\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1755 - val_loss: 58.6013\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.3876 - val_loss: 67.3896\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.0010 - val_loss: 75.0106\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.7704 - val_loss: 62.2663\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 130.6736 - val_loss: 64.3800\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.0535 - val_loss: 66.7260\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2589 - val_loss: 68.4083\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.0014 - val_loss: 63.5430\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.8004 - val_loss: 64.0142\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.3249 - val_loss: 64.6339\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 64.9686 - val_loss: 66.8752\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.0669 - val_loss: 61.8291\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.6324 - val_loss: 63.2231\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.8833 - val_loss: 61.6617\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.3925 - val_loss: 63.2584\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7529 - val_loss: 63.4688\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.7380 - val_loss: 61.8943\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.0107 - val_loss: 64.3848\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4619 - val_loss: 64.1319\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 70.3222 - val_loss: 61.3883\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.8691 - val_loss: 68.1138\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6864 - val_loss: 65.7320\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7013 - val_loss: 74.6937\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4145 - val_loss: 66.2666\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3778 - val_loss: 70.6381\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.0474 - val_loss: 69.8683\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.4060 - val_loss: 68.0186\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.7334 - val_loss: 64.6996\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.4798 - val_loss: 72.5652\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.7828 - val_loss: 85.1638\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.9315 - val_loss: 68.8285\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.6059 - val_loss: 62.4614\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.0736 - val_loss: 62.5540\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7477 - val_loss: 61.2939\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5457 - val_loss: 67.9633\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8177 - val_loss: 76.3332\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2158 - val_loss: 65.4145\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 67.1950 - val_loss: 59.4469\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.1396 - val_loss: 75.5344\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6516 - val_loss: 89.8468\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8061 - val_loss: 62.7726\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7813 - val_loss: 62.2835\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0343 - val_loss: 73.7311\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.0159 - val_loss: 60.9032\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.8071 - val_loss: 60.3817\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4689 - val_loss: 63.2596\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.3695 - val_loss: 67.7791\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.7078 - val_loss: 64.1817\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.6778 - val_loss: 66.9337\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.8463 - val_loss: 66.3159\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.8492 - val_loss: 63.9814\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.8796 - val_loss: 61.5192\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.6564 - val_loss: 66.1808\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.0099 - val_loss: 63.0802\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 72.4061 - val_loss: 60.6820\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.1311 - val_loss: 62.3655\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9796 - val_loss: 64.9398\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.1875 - val_loss: 61.3654\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5807 - val_loss: 63.6883\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.1773 - val_loss: 61.4737\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 68.2316 - val_loss: 64.5191\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.7880 - val_loss: 60.3343\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1696 - val_loss: 59.8229\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6966 - val_loss: 61.5303\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.6332 - val_loss: 59.8266\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6871 - val_loss: 64.1359\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7032 - val_loss: 64.2879\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6835 - val_loss: 69.5170\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.0881 - val_loss: 66.5113\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.5582 - val_loss: 70.4304\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9203 - val_loss: 62.7022\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2637 - val_loss: 69.2760\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.6392 - val_loss: 67.4469\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.2370 - val_loss: 60.6057\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.4571 - val_loss: 71.9345\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.0850 - val_loss: 64.3857\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.2845 - val_loss: 62.8000\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1310 - val_loss: 59.7954\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.1715 - val_loss: 60.4859\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.1096 - val_loss: 61.2520\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8629 - val_loss: 61.7615\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2467 - val_loss: 61.2110\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.5969 - val_loss: 63.4687\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5335 - val_loss: 60.6921\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.1136 - val_loss: 64.8934\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8220 - val_loss: 64.3106\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2025 - val_loss: 71.3607\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6942 - val_loss: 61.5451\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.6824 - val_loss: 72.2763\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.3655 - val_loss: 60.6241\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.7578 - val_loss: 61.2642\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.7207 - val_loss: 62.5515\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.8415 - val_loss: 61.5948\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5975 - val_loss: 66.5236\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.1800 - val_loss: 68.9907\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.9271 - val_loss: 67.0629\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.9647 - val_loss: 63.7280\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.9700 - val_loss: 61.7688\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3248 - val_loss: 70.0468\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4395 - val_loss: 65.4830\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 80.6373 - val_loss: 69.9840\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 85.7100 - val_loss: 61.8335\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8639 - val_loss: 67.2549\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 37.1225\n",
      "--- Starting trial: run-16\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 32, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7267 - val_loss: 660.4175\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6594 - val_loss: 660.3320\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5870 - val_loss: 660.2405\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5087 - val_loss: 660.1416\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4237 - val_loss: 660.0330\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3310 - val_loss: 659.9200\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2304 - val_loss: 659.7946\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1213 - val_loss: 659.6630\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.0034 - val_loss: 659.5267\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.8764 - val_loss: 659.3787\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7400 - val_loss: 659.2181\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5941 - val_loss: 659.0425\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4385 - val_loss: 658.8658\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.2731 - val_loss: 658.6788\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0978 - val_loss: 658.4881\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9124 - val_loss: 658.2859\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7169 - val_loss: 658.0726\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5112 - val_loss: 657.8384\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2952 - val_loss: 657.6053\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0688 - val_loss: 657.3697\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.8323 - val_loss: 657.1160\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.5852 - val_loss: 656.8438\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 686.3276 - val_loss: 656.5696\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.0597 - val_loss: 656.2878\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.7812 - val_loss: 655.9911\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.4923 - val_loss: 655.6815\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.1927 - val_loss: 655.3664\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.8827 - val_loss: 655.0613\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.5621 - val_loss: 654.7260\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.2310 - val_loss: 654.3998\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.8893 - val_loss: 654.0526\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.5370 - val_loss: 653.6940\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.1742 - val_loss: 653.3108\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.8008 - val_loss: 652.9115\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.4169 - val_loss: 652.5247\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.0226 - val_loss: 652.0950\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.6176 - val_loss: 651.6730\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.2020 - val_loss: 651.2662\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.7761 - val_loss: 650.8236\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.3397 - val_loss: 650.3892\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.8928 - val_loss: 649.9280\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.4354 - val_loss: 649.5122\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.9675 - val_loss: 649.0214\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.4893 - val_loss: 648.5552\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.0006 - val_loss: 648.0685\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.5015 - val_loss: 647.5720\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.9921 - val_loss: 647.0417\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.4723 - val_loss: 646.5415\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.9422 - val_loss: 646.0067\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.4018 - val_loss: 645.4413\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 674.8510 - val_loss: 644.8735\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.2900 - val_loss: 644.2875\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.7189 - val_loss: 643.6780\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.1374 - val_loss: 643.0677\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.5457 - val_loss: 642.4451\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.9440 - val_loss: 641.8587\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.3320 - val_loss: 641.2505\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.7100 - val_loss: 640.5953\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.0778 - val_loss: 639.9619\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.4355 - val_loss: 639.3559\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.7831 - val_loss: 638.7158\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.1207 - val_loss: 638.0131\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.4484 - val_loss: 637.3234\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.7662 - val_loss: 636.6083\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.0739 - val_loss: 635.9229\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.3716 - val_loss: 635.2506\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.6596 - val_loss: 634.5057\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.9376 - val_loss: 633.7764\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.2058 - val_loss: 633.0736\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.4641 - val_loss: 632.3059\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.7126 - val_loss: 631.5630\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.9514 - val_loss: 630.7814\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.1804 - val_loss: 629.9942\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.3997 - val_loss: 629.1838\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.6093 - val_loss: 628.3799\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.8092 - val_loss: 627.6392\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.9995 - val_loss: 626.8345\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.1802 - val_loss: 625.9837\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 655.3513 - val_loss: 625.1360\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.5128 - val_loss: 624.2946\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.6647 - val_loss: 623.4080\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.8073 - val_loss: 622.5612\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.9401 - val_loss: 621.7040\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.0637 - val_loss: 620.8120\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 650.1777 - val_loss: 619.9544\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.2823 - val_loss: 619.0779\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.3776 - val_loss: 618.1627\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.4635 - val_loss: 617.2893\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.5400 - val_loss: 616.3358\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.6072 - val_loss: 615.4105\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 644.6652 - val_loss: 614.4825\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 643.7139 - val_loss: 613.4236\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 642.7533 - val_loss: 612.5198\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.7836 - val_loss: 611.5198\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.8046 - val_loss: 610.5626\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 639.8163 - val_loss: 609.6095\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.8192 - val_loss: 608.5713\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.8128 - val_loss: 607.5976\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.7973 - val_loss: 606.5968\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.7728 - val_loss: 605.5380\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.7393 - val_loss: 604.6131\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.6967 - val_loss: 603.6238\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.6451 - val_loss: 602.5912\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.5845 - val_loss: 601.3992\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.5151 - val_loss: 600.2158\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.4367 - val_loss: 599.1541\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.3494 - val_loss: 598.0068\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.2531 - val_loss: 596.9370\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.1482 - val_loss: 595.9245\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.0343 - val_loss: 594.9370\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.9117 - val_loss: 593.8813\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.7802 - val_loss: 592.7026\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.6401 - val_loss: 591.6235\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.4911 - val_loss: 590.5341\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.3336 - val_loss: 589.2956\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.1672 - val_loss: 588.1219\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.9922 - val_loss: 586.9818\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 615.8087 - val_loss: 585.7694\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 614.6164 - val_loss: 584.5383\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 613.4155 - val_loss: 583.3640\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.2061 - val_loss: 582.1311\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.9882 - val_loss: 580.9730\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.7618 - val_loss: 579.7656\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.5268 - val_loss: 578.5773\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.2833 - val_loss: 577.3642\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.0313 - val_loss: 576.0848\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.7710 - val_loss: 574.8607\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.5022 - val_loss: 573.5928\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.2250 - val_loss: 572.4099\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.9393 - val_loss: 571.2378\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.6454 - val_loss: 569.8862\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.3431 - val_loss: 568.6484\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.0326 - val_loss: 567.3962\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.7138 - val_loss: 566.1389\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.3865 - val_loss: 564.7758\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.0512 - val_loss: 563.4115\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.7076 - val_loss: 561.9981\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.3558 - val_loss: 560.6052\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.9958 - val_loss: 559.1911\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.6276 - val_loss: 557.8428\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.3621 - val_loss: 557.7184\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 584.8744 - val_loss: 557.1321\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 583.4841 - val_loss: 555.9977\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.0844 - val_loss: 554.7007\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.6759 - val_loss: 553.3035\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.2592 - val_loss: 551.9548\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.8344 - val_loss: 550.3829\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.4014 - val_loss: 549.0084\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.9605 - val_loss: 547.6729\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.5116 - val_loss: 546.1852\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.0548 - val_loss: 544.7018\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 570.5900 - val_loss: 543.1526\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.1174 - val_loss: 541.6141\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.6368 - val_loss: 540.1632\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.1484 - val_loss: 538.7058\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.6521 - val_loss: 537.1517\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.1479 - val_loss: 535.6186\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.6360 - val_loss: 534.1687\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.1163 - val_loss: 532.5510\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.5887 - val_loss: 531.1108\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.0535 - val_loss: 529.5931\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.5105 - val_loss: 527.9537\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.9597 - val_loss: 526.3999\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.4013 - val_loss: 524.6547\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.8351 - val_loss: 522.8719\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 549.2869 - val_loss: 522.7381\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.7037 - val_loss: 521.9188\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.1365 - val_loss: 522.3881\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.5393 - val_loss: 521.2958\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.9434 - val_loss: 519.8662\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.3347 - val_loss: 518.2834\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.7162 - val_loss: 516.4153\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.0892 - val_loss: 514.5016\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.4544 - val_loss: 512.7278\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.8119 - val_loss: 511.1294\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.1618 - val_loss: 509.3496\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.5042 - val_loss: 507.5936\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 529.8391 - val_loss: 505.8201\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 528.1666 - val_loss: 504.1107\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.4866 - val_loss: 502.3832\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 524.7993 - val_loss: 500.7659\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.1046 - val_loss: 499.2136\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 521.5088 - val_loss: 497.7757\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.6994 - val_loss: 496.3225\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 518.0126 - val_loss: 495.2305\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 516.2920 - val_loss: 493.8267\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.6781 - val_loss: 492.1360\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 512.8818 - val_loss: 490.4731\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 511.0923 - val_loss: 489.3113\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.3550 - val_loss: 487.6445\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 507.6653 - val_loss: 485.7949\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 505.8430 - val_loss: 484.1222\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 504.0703 - val_loss: 482.3325\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.2886 - val_loss: 480.7310\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 500.5111 - val_loss: 479.2769\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 498.7076 - val_loss: 477.3966\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.0243 - val_loss: 475.5410\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.1108 - val_loss: 474.2485\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.3079 - val_loss: 472.7073\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 491.5107 - val_loss: 470.6578\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.6624 - val_loss: 468.3554\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 487.8268 - val_loss: 466.4328\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 485.9810 - val_loss: 464.5401\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 484.2419 - val_loss: 463.3909\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 482.3912 - val_loss: 461.6915\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.4131 - val_loss: 459.7076\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 478.5418 - val_loss: 458.1186\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 476.6607 - val_loss: 456.1219\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 474.7714 - val_loss: 454.6907\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.8746 - val_loss: 453.0633\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 471.0250 - val_loss: 451.0771\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 469.3085 - val_loss: 448.8096\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 467.3968 - val_loss: 446.5987\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 465.3806 - val_loss: 444.5097\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 463.8188 - val_loss: 443.2319\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.6245 - val_loss: 441.4667\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 459.5704 - val_loss: 439.3906\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.6118 - val_loss: 437.0891\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.6862 - val_loss: 434.9217\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 453.8758 - val_loss: 432.8083\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 452.1344 - val_loss: 430.8507\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 450.2539 - val_loss: 428.6381\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 448.3163 - val_loss: 427.1090\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 446.1162 - val_loss: 425.4655\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 444.3603 - val_loss: 424.2063\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 442.4344 - val_loss: 423.1040\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.3440 - val_loss: 422.0023\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 438.8622 - val_loss: 420.9574\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.3504 - val_loss: 419.4329\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.6227 - val_loss: 417.5058\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 432.4478 - val_loss: 415.3545\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.6770 - val_loss: 412.9486\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 428.8592 - val_loss: 410.9842\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 426.6240 - val_loss: 409.2822\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.5820 - val_loss: 408.2484\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 422.5726 - val_loss: 407.4145\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.6303 - val_loss: 405.3325\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.9126 - val_loss: 402.7675\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.9512 - val_loss: 400.6067\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.3662 - val_loss: 399.2297\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.6429 - val_loss: 397.0284\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.0579 - val_loss: 394.9477\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.4486 - val_loss: 392.8853\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 406.3441 - val_loss: 390.7574\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 404.6453 - val_loss: 389.5993\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.7673 - val_loss: 387.8052\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 402.2272 - val_loss: 386.7034\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.5945 - val_loss: 386.3066\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 396.5295 - val_loss: 384.5086\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.8390 - val_loss: 383.2718\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 438.2107\n",
      "--- Starting trial: run-17\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 32, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6653 - val_loss: 660.4502\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4438 - val_loss: 660.2114\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2176 - val_loss: 659.9656\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9828 - val_loss: 659.7115\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7355 - val_loss: 659.4458\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4714 - val_loss: 659.1594\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1858 - val_loss: 658.8503\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8735 - val_loss: 658.5112\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5285 - val_loss: 658.1346\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1442 - val_loss: 657.7183\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.7128 - val_loss: 657.2448\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.2253 - val_loss: 656.7150\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6714 - val_loss: 656.1119\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0392 - val_loss: 655.4122\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 684.3145 - val_loss: 654.6155\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.4808 - val_loss: 653.6937\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.5192 - val_loss: 652.6393\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.4073 - val_loss: 651.4225\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.1188 - val_loss: 649.9985\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.6229 - val_loss: 648.3472\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.8836 - val_loss: 646.4337\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.8591 - val_loss: 644.2050\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.4997 - val_loss: 641.6215\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.7476 - val_loss: 638.5773\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.5349 - val_loss: 635.0481\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.7822 - val_loss: 630.9097\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.3959 - val_loss: 626.0811\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.2668 - val_loss: 620.4365\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.2668 - val_loss: 613.8461\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.2452 - val_loss: 606.0966\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.0260 - val_loss: 597.0729\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 622.4022 - val_loss: 586.4798\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.1315 - val_loss: 574.0580\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.9298 - val_loss: 559.5066\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.4636 - val_loss: 542.6572\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.5790 - val_loss: 523.8371\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.3644 - val_loss: 505.0783\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 521.5314 - val_loss: 484.6129\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 496.1118 - val_loss: 461.8028\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.2131 - val_loss: 436.8533\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.5352 - val_loss: 412.4125\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.8735 - val_loss: 387.8954\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 393.2088 - val_loss: 362.2782\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 372.3144 - val_loss: 338.5262\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.8108 - val_loss: 316.1064\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 328.4210 - val_loss: 292.8616\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.0141 - val_loss: 267.7223\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.7208 - val_loss: 238.6375\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.3529 - val_loss: 208.8319\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 218.3100 - val_loss: 182.6529\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 196.2849 - val_loss: 158.7567\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.6988 - val_loss: 140.7704\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 162.4328 - val_loss: 131.3707\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 139.8533 - val_loss: 121.1533\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.4723 - val_loss: 115.4705\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.9029 - val_loss: 98.8047\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.9271 - val_loss: 103.0844\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 131.1602 - val_loss: 105.3867\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.8215 - val_loss: 106.4231\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2923 - val_loss: 104.8155\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.0971 - val_loss: 90.4863\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8026 - val_loss: 96.4513\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.5899 - val_loss: 108.0559\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.7938 - val_loss: 109.6267\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4486 - val_loss: 111.0851\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3231 - val_loss: 88.6357\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8350 - val_loss: 78.4302\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3048 - val_loss: 105.5167\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 120.6745 - val_loss: 94.6044\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.8793 - val_loss: 83.9847\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3098 - val_loss: 83.0454\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2286 - val_loss: 110.2871\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0047 - val_loss: 88.9664\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.9211 - val_loss: 89.9195\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.2413 - val_loss: 77.8370\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.4863 - val_loss: 73.4865\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.3017 - val_loss: 96.9147\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.1369 - val_loss: 75.5469\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9691 - val_loss: 70.5696\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4051 - val_loss: 75.6342\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4170 - val_loss: 67.8822\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8023 - val_loss: 76.8370\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.6698 - val_loss: 84.6913\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 83.5371 - val_loss: 76.9010\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7698 - val_loss: 70.6929\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0706 - val_loss: 77.2995\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5461 - val_loss: 91.6090\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7103 - val_loss: 70.8919\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.2954 - val_loss: 74.4295\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1008 - val_loss: 70.4289\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7845 - val_loss: 75.9901\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2128 - val_loss: 81.9538\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2474 - val_loss: 78.9711\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0798 - val_loss: 90.8251\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.3988 - val_loss: 80.1434\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7729 - val_loss: 69.9618\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7769 - val_loss: 69.5363\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.7386 - val_loss: 76.9684\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6701 - val_loss: 77.3273\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.2042 - val_loss: 97.9718\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.9024 - val_loss: 106.3210\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.3621 - val_loss: 85.5142\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.9122 - val_loss: 66.8398\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.8166 - val_loss: 69.6885\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.1147 - val_loss: 66.4949\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.5846 - val_loss: 88.3599\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0107 - val_loss: 97.6828\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5643 - val_loss: 72.9700\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.5722 - val_loss: 70.4866\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 111.3265 - val_loss: 104.9698\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.3458 - val_loss: 129.6048\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4133 - val_loss: 83.9326\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.2160 - val_loss: 81.0679\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 70.1452 - val_loss: 92.6852\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.7876 - val_loss: 68.9294\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0843 - val_loss: 80.9169\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4427 - val_loss: 86.4431\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.0119 - val_loss: 86.4045\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3391 - val_loss: 78.2085\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.9252 - val_loss: 73.4139\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1612 - val_loss: 72.2081\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.0558 - val_loss: 84.2603\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8751 - val_loss: 79.9803\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4721 - val_loss: 76.4222\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0871 - val_loss: 86.4432\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0123 - val_loss: 73.3696\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.6009 - val_loss: 80.9986\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.7587 - val_loss: 80.5811\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 72.5499 - val_loss: 86.8496\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.5508 - val_loss: 90.3513\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9165 - val_loss: 82.8535\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.4733 - val_loss: 69.1664\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.4053 - val_loss: 99.2058\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.6904 - val_loss: 77.5988\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 86.2052 - val_loss: 77.3967\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0011 - val_loss: 68.9385\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3270 - val_loss: 85.2521\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5448 - val_loss: 63.6138\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7432 - val_loss: 73.7273\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 60.6667 - val_loss: 82.0027\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9605 - val_loss: 82.0019\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5190 - val_loss: 82.7594\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.2057 - val_loss: 94.4062\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.3112 - val_loss: 65.6384\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.8491 - val_loss: 67.6664\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2079 - val_loss: 140.7187\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.8714 - val_loss: 103.6907\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.0804 - val_loss: 68.0755\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.2294 - val_loss: 78.8084\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2922 - val_loss: 72.9273\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4435 - val_loss: 88.5179\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0901 - val_loss: 65.0314\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0750 - val_loss: 75.2181\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7091 - val_loss: 67.6315\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0125 - val_loss: 84.4444\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5606 - val_loss: 64.1879\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.1406 - val_loss: 67.3090\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.6170 - val_loss: 80.9253\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 100.0648 - val_loss: 78.5700\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7261 - val_loss: 69.8222\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.6302 - val_loss: 65.1285\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 125.5602 - val_loss: 67.5145\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.8483 - val_loss: 73.5123\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 133.0567 - val_loss: 67.9918\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1950 - val_loss: 69.3590\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.5474 - val_loss: 66.1528\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.8077 - val_loss: 75.9922\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 113.9682 - val_loss: 99.8011\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8832 - val_loss: 67.5065\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.7808 - val_loss: 85.2272\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.2837 - val_loss: 66.6784\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.3281 - val_loss: 101.3231\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5035 - val_loss: 126.8295\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8631 - val_loss: 72.9182\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5961 - val_loss: 109.9179\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7744 - val_loss: 71.2995\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1300 - val_loss: 144.2560\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.8320 - val_loss: 68.2190\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2217 - val_loss: 92.8657\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.5202 - val_loss: 89.8404\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4565 - val_loss: 87.6977\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8945 - val_loss: 64.0755\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2291 - val_loss: 84.8900\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 123.1600 - val_loss: 76.4193\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.4868 - val_loss: 75.7093\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3222 - val_loss: 91.3903\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3373 - val_loss: 111.6515\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1776 - val_loss: 94.4152\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7893 - val_loss: 70.8637\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.5467 - val_loss: 69.9507\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1188 - val_loss: 65.1151\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.3651 - val_loss: 70.8307\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.6482 - val_loss: 110.2420\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2719 - val_loss: 74.6727\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3546 - val_loss: 63.7551\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.8839 - val_loss: 69.8927\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.0583 - val_loss: 101.3822\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.2686 - val_loss: 66.4144\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3108 - val_loss: 114.3664\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.0229 - val_loss: 86.7803\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8948 - val_loss: 71.4880\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8457 - val_loss: 112.6079\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.8490 - val_loss: 68.7555\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3455 - val_loss: 64.9397\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7087 - val_loss: 70.9282\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.9379 - val_loss: 86.4771\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.1056 - val_loss: 83.2130\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4574 - val_loss: 81.4030\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.8141 - val_loss: 71.6488\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 96.0857 - val_loss: 94.3582\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4958 - val_loss: 125.5369\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1985 - val_loss: 62.9160\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2097 - val_loss: 100.9943\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3770 - val_loss: 66.8410\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.4898 - val_loss: 79.2541\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6872 - val_loss: 73.6866\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.0695 - val_loss: 71.7864\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5167 - val_loss: 67.5311\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.8155 - val_loss: 77.4969\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.8980 - val_loss: 65.7250\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6165 - val_loss: 65.2139\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.2569 - val_loss: 111.5975\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.0777 - val_loss: 96.2019\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.5573 - val_loss: 71.3382\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.6034 - val_loss: 65.1976\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4011 - val_loss: 122.8811\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.8582 - val_loss: 96.2695\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0700 - val_loss: 65.8522\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1439 - val_loss: 82.4602\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2948 - val_loss: 79.6940\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.3063 - val_loss: 67.0801\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4692 - val_loss: 76.0393\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1101 - val_loss: 85.9796\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.7395 - val_loss: 77.9952\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.8778 - val_loss: 73.0053\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2488 - val_loss: 75.6695\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.8858 - val_loss: 77.6119\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8808 - val_loss: 70.7217\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.4521 - val_loss: 63.5681\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1505 - val_loss: 66.1838\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.4489 - val_loss: 85.9277\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6507 - val_loss: 78.8818\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.2150 - val_loss: 71.8121\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.6005 - val_loss: 65.3531\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2666 - val_loss: 71.4401\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1767 - val_loss: 75.8114\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.4169 - val_loss: 74.1885\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4355 - val_loss: 93.2140\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1910 - val_loss: 75.1692\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5343 - val_loss: 64.2352\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 58.6127\n",
      "--- Starting trial: run-18\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 32, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7307 - val_loss: 660.6337\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6728 - val_loss: 660.5708\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6102 - val_loss: 660.5179\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5415 - val_loss: 660.4592\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4661 - val_loss: 660.3755\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3832 - val_loss: 660.3060\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2922 - val_loss: 660.2206\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1927 - val_loss: 660.1329\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.0844 - val_loss: 660.0280\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9667 - val_loss: 659.9245\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8398 - val_loss: 659.8112\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.7032 - val_loss: 659.6846\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.5568 - val_loss: 659.5381\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.4005 - val_loss: 659.3875\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.2341 - val_loss: 659.2448\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.0576 - val_loss: 659.0636\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8707 - val_loss: 658.8829\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.6735 - val_loss: 658.7026\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.4659 - val_loss: 658.5045\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2479 - val_loss: 658.2825\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0194 - val_loss: 658.0872\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7803 - val_loss: 657.8630\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.5306 - val_loss: 657.6489\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.2702 - val_loss: 657.4065\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9993 - val_loss: 657.1432\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.7178 - val_loss: 656.8729\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.4256 - val_loss: 656.6021\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1226 - val_loss: 656.3389\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.8090 - val_loss: 656.0217\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.4848 - val_loss: 655.6939\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.1498 - val_loss: 655.3475\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 683.8041 - val_loss: 655.0328\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.4479 - val_loss: 654.6973\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.0808 - val_loss: 654.3492\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.7032 - val_loss: 653.9608\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.3149 - val_loss: 653.6149\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.9160 - val_loss: 653.2047\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.5065 - val_loss: 652.8084\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.0864 - val_loss: 652.3903\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.6556 - val_loss: 651.9477\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.2144 - val_loss: 651.4899\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.7624 - val_loss: 651.0427\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.3001 - val_loss: 650.5991\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.8272 - val_loss: 650.1381\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.3438 - val_loss: 649.6516\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.8499 - val_loss: 649.1849\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.3456 - val_loss: 648.7195\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.8309 - val_loss: 648.1907\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.3058 - val_loss: 647.7111\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 675.7702 - val_loss: 647.1646\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 675.2243 - val_loss: 646.6596\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6681 - val_loss: 646.0547\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.1015 - val_loss: 645.5297\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.5248 - val_loss: 644.9056\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.9377 - val_loss: 644.3265\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.3403 - val_loss: 643.7570\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.7329 - val_loss: 643.1830\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.1152 - val_loss: 642.5922\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.4873 - val_loss: 641.9391\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.8493 - val_loss: 641.2895\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.2012 - val_loss: 640.6570\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.5432 - val_loss: 640.0526\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.8749 - val_loss: 639.4205\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.1967 - val_loss: 638.7565\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.5084 - val_loss: 638.0626\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.8102 - val_loss: 637.3683\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.1022 - val_loss: 636.6685\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.3841 - val_loss: 635.9737\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.6561 - val_loss: 635.2388\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.9183 - val_loss: 634.5261\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.1707 - val_loss: 633.7780\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.4132 - val_loss: 633.0148\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.6460 - val_loss: 632.2208\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.8689 - val_loss: 631.5092\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.0823 - val_loss: 630.7341\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 658.2858 - val_loss: 629.8765\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.4798 - val_loss: 629.0807\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.6641 - val_loss: 628.2915\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.8386 - val_loss: 627.4725\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.0037 - val_loss: 626.6874\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.1592 - val_loss: 625.8085\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 653.3052 - val_loss: 624.9346\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.4416 - val_loss: 624.0747\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.5684 - val_loss: 623.1998\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 650.6860 - val_loss: 622.3608\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 649.7940 - val_loss: 621.5368\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.8926 - val_loss: 620.6641\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.9819 - val_loss: 619.8092\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 647.0618 - val_loss: 618.9935\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.1324 - val_loss: 618.0755\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 645.1936 - val_loss: 617.1804\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.2456 - val_loss: 616.2485\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.2883 - val_loss: 615.2664\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.3217 - val_loss: 614.2869\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.3460 - val_loss: 613.3383\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 640.3611 - val_loss: 612.3653\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 639.3671 - val_loss: 611.3006\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.3640 - val_loss: 610.3005\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.3517 - val_loss: 609.3791\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 636.3303 - val_loss: 608.3780\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 635.2998 - val_loss: 607.3613\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.2605 - val_loss: 606.3612\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.2120 - val_loss: 605.2787\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.1546 - val_loss: 604.2770\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.0882 - val_loss: 603.2224\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.0129 - val_loss: 602.1239\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.9287 - val_loss: 601.0539\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.8357 - val_loss: 599.9354\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.7337 - val_loss: 598.8791\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.6229 - val_loss: 597.7575\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.5034 - val_loss: 596.5968\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.3749 - val_loss: 595.4633\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.2379 - val_loss: 594.3861\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.0919 - val_loss: 593.1788\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 619.9374 - val_loss: 591.9178\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.7741 - val_loss: 590.7561\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 617.6022 - val_loss: 589.5560\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.4216 - val_loss: 588.3060\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.2324 - val_loss: 587.0663\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.0345 - val_loss: 586.0330\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.8281 - val_loss: 584.8405\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.6131 - val_loss: 583.7532\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 610.3896 - val_loss: 582.5600\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 609.1576 - val_loss: 581.2986\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 607.9171 - val_loss: 580.0915\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.6682 - val_loss: 578.8438\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 605.4108 - val_loss: 577.5473\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 604.1449 - val_loss: 576.2794\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 602.8707 - val_loss: 574.9572\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 601.5881 - val_loss: 573.7358\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 600.2971 - val_loss: 572.4249\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.9979 - val_loss: 571.1951\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.6902 - val_loss: 569.8628\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.3743 - val_loss: 568.5422\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.0501 - val_loss: 567.3007\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.7177 - val_loss: 565.8834\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.3770 - val_loss: 564.6678\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.0281 - val_loss: 563.3810\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.6710 - val_loss: 562.0148\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.3058 - val_loss: 560.5709\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.9325 - val_loss: 559.2201\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.5510 - val_loss: 557.8438\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.1613 - val_loss: 556.4734\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.7635 - val_loss: 555.0509\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.3578 - val_loss: 553.7316\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 579.9440 - val_loss: 552.2014\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.5222 - val_loss: 550.7234\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 577.0923 - val_loss: 549.2715\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.6544 - val_loss: 547.7895\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.2484 - val_loss: 547.4303\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.7595 - val_loss: 548.4903\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.3016 - val_loss: 547.8860\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.8336 - val_loss: 546.5818\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.3565 - val_loss: 544.8203\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.8713 - val_loss: 543.2678\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.3781 - val_loss: 541.4823\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.8770 - val_loss: 539.9127\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.3680 - val_loss: 538.1505\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.8511 - val_loss: 536.5389\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.3266 - val_loss: 535.1115\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 557.7943 - val_loss: 533.3764\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 556.2542 - val_loss: 531.6295\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.7064 - val_loss: 529.9252\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.1509 - val_loss: 528.2997\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.5877 - val_loss: 526.8779\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.0168 - val_loss: 525.3503\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.4384 - val_loss: 523.7829\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.8522 - val_loss: 522.1096\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.2584 - val_loss: 520.4789\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.6570 - val_loss: 518.9327\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.0481 - val_loss: 517.3702\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 540.4316 - val_loss: 515.7148\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.8075 - val_loss: 514.1946\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 537.1760 - val_loss: 512.5354\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.5368 - val_loss: 510.9249\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 533.8902 - val_loss: 509.4353\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 532.2362 - val_loss: 507.8150\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.5747 - val_loss: 506.2209\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 528.9056 - val_loss: 504.5773\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.2292 - val_loss: 502.9247\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.5454 - val_loss: 501.2599\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 523.8542 - val_loss: 499.7047\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 522.1556 - val_loss: 498.1244\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.5038 - val_loss: 498.0306\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.7433 - val_loss: 497.7085\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 517.0250 - val_loss: 496.3211\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.2981 - val_loss: 494.6902\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.5632 - val_loss: 492.7241\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 511.8207 - val_loss: 490.9523\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 510.0709 - val_loss: 488.9946\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.3137 - val_loss: 487.1536\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 506.5493 - val_loss: 485.4066\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 504.8203 - val_loss: 484.8082\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 503.0052 - val_loss: 484.3426\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 501.2224 - val_loss: 483.1021\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.4305 - val_loss: 481.3532\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.6307 - val_loss: 479.7486\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.8944 - val_loss: 479.0543\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.0152 - val_loss: 478.1353\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.1960 - val_loss: 476.6129\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.3683 - val_loss: 474.8018\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.5326 - val_loss: 472.8247\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.6896 - val_loss: 470.6997\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.8394 - val_loss: 468.5681\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 482.9821 - val_loss: 466.5867\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.2023 - val_loss: 464.1833\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 479.2609 - val_loss: 461.3632\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.3984 - val_loss: 459.3153\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.5196 - val_loss: 457.4893\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 473.6299 - val_loss: 455.3609\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.7315 - val_loss: 453.6286\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.9552 - val_loss: 452.0594\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.1284 - val_loss: 450.4329\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 466.2517 - val_loss: 449.1151\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 464.1337 - val_loss: 447.3598\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 462.2110 - val_loss: 446.1768\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.2744 - val_loss: 444.3931\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 458.5549 - val_loss: 442.4016\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.4394 - val_loss: 440.6102\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 454.4586 - val_loss: 439.8077\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 452.5891 - val_loss: 437.8816\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.6094 - val_loss: 435.9192\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 448.7600 - val_loss: 433.7804\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 447.0032 - val_loss: 431.6516\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 444.8272 - val_loss: 429.9889\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.8026 - val_loss: 427.9453\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 440.9136 - val_loss: 425.8548\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 438.7611 - val_loss: 423.6982\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.0482 - val_loss: 421.8612\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 435.0721 - val_loss: 420.3693\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 433.8359 - val_loss: 417.8341\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.8136 - val_loss: 417.2514\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.1424 - val_loss: 415.7929\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.0178 - val_loss: 413.7078\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 425.0895 - val_loss: 411.2458\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 423.3222 - val_loss: 409.4656\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 421.2488 - val_loss: 408.2107\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.8750 - val_loss: 406.3316\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 416.9832 - val_loss: 404.5047\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.1574 - val_loss: 402.8927\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.4610 - val_loss: 400.4170\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.7796 - val_loss: 397.8686\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 409.1980 - val_loss: 395.4703\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.6064 - val_loss: 393.2989\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 404.8294 - val_loss: 391.2730\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 403.0892 - val_loss: 389.4047\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 401.2327 - val_loss: 387.4370\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 399.3104 - val_loss: 384.3038\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 397.2075 - val_loss: 382.0156\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 394.6152 - val_loss: 379.5007\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 430.7474\n",
      "--- Starting trial: run-19\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 32, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 689.6796 - val_loss: 660.1609\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4946 - val_loss: 659.9780\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3062 - val_loss: 659.7861\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1113 - val_loss: 659.5817\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.9071 - val_loss: 659.3712\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6906 - val_loss: 659.1561\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4580 - val_loss: 658.9057\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2057 - val_loss: 658.6364\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9290 - val_loss: 658.3382\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 687.6233 - val_loss: 658.0006\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.2825 - val_loss: 657.6359\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9001 - val_loss: 657.2346\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.4686 - val_loss: 656.7700\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9789 - val_loss: 656.2299\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.4205 - val_loss: 655.6194\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.7813 - val_loss: 654.9280\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.0472 - val_loss: 654.1329\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.2015 - val_loss: 653.2183\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.2249 - val_loss: 652.1529\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.0942 - val_loss: 650.9109\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.7833 - val_loss: 649.4910\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.2604 - val_loss: 647.8206\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.4891 - val_loss: 645.8671\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.4266 - val_loss: 643.6268\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 672.0222 - val_loss: 641.0009\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 669.2171 - val_loss: 637.9217\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.9420 - val_loss: 634.3102\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.1158 - val_loss: 630.0883\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.6432 - val_loss: 625.1779\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.4129 - val_loss: 619.4210\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.2938 - val_loss: 612.7078\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.1326 - val_loss: 604.8243\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.7495 - val_loss: 595.5789\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.9335 - val_loss: 584.8074\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.4375 - val_loss: 572.1467\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.9714 - val_loss: 557.3463\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.1951 - val_loss: 540.1782\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.0552 - val_loss: 521.4236\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.8270 - val_loss: 500.2923\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.9395 - val_loss: 477.4039\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 490.9285 - val_loss: 449.8882\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 461.3076 - val_loss: 420.9712\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.0484 - val_loss: 393.5952\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.5134 - val_loss: 369.5597\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 385.5508 - val_loss: 347.9615\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.5852 - val_loss: 335.5105\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 348.0387 - val_loss: 315.7929\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 325.6254 - val_loss: 284.4588\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 303.5211 - val_loss: 259.9546\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 280.9001 - val_loss: 223.4654\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.4961 - val_loss: 201.6739\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 229.7641 - val_loss: 175.2909\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.7895 - val_loss: 167.4935\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.3655 - val_loss: 191.2466\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.4906 - val_loss: 239.7740\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.0172 - val_loss: 296.9252\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.8769 - val_loss: 345.0799\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.3546 - val_loss: 362.5354\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1892 - val_loss: 362.2774\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7527 - val_loss: 262.8117\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8863 - val_loss: 357.7195\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.4807 - val_loss: 313.1938\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8056 - val_loss: 309.2498\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.9492 - val_loss: 163.9672\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.2282 - val_loss: 220.2953\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.5070 - val_loss: 243.3545\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.4313 - val_loss: 195.8626\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1360 - val_loss: 155.0698\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6913 - val_loss: 160.2567\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4205 - val_loss: 83.0553\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.7701 - val_loss: 141.3834\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9195 - val_loss: 191.9439\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8808 - val_loss: 167.9206\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.1028 - val_loss: 128.4217\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.5666 - val_loss: 87.4287\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.1274 - val_loss: 110.6922\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.0972 - val_loss: 159.4770\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0863 - val_loss: 175.7068\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2618 - val_loss: 87.0738\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9184 - val_loss: 134.3078\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1028 - val_loss: 83.4047\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8047 - val_loss: 127.0256\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.9497 - val_loss: 113.0982\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.8774 - val_loss: 157.6051\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.4897 - val_loss: 79.2150\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.9953 - val_loss: 102.4775\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.8635 - val_loss: 99.4147\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.5186 - val_loss: 112.3833\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.6526 - val_loss: 71.8919\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.1514 - val_loss: 126.5912\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4178 - val_loss: 84.1667\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.8561 - val_loss: 82.5883\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5624 - val_loss: 86.1610\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9089 - val_loss: 80.9658\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.4532 - val_loss: 101.2690\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.6979 - val_loss: 80.0230\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.3166 - val_loss: 83.2111\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2930 - val_loss: 71.7677\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.7196 - val_loss: 93.1442\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.7307 - val_loss: 111.5286\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.4780 - val_loss: 91.0311\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8092 - val_loss: 105.3017\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.6638 - val_loss: 118.9442\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0491 - val_loss: 87.7170\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7805 - val_loss: 82.6190\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4543 - val_loss: 71.3411\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.2209 - val_loss: 72.4443\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0344 - val_loss: 64.7366\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0580 - val_loss: 63.7593\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3974 - val_loss: 69.0155\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2339 - val_loss: 74.4578\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3426 - val_loss: 70.4772\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.4198 - val_loss: 74.1166\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.8103 - val_loss: 69.1970\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.2144 - val_loss: 63.7887\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.1421 - val_loss: 74.3101\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.1391 - val_loss: 70.9677\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2662 - val_loss: 69.6645\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8327 - val_loss: 76.3319\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.0700 - val_loss: 71.1958\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.1518 - val_loss: 69.8772\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.3851 - val_loss: 83.2638\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1140 - val_loss: 79.8501\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.1718 - val_loss: 73.7471\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.1891 - val_loss: 86.4706\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.1580 - val_loss: 80.0183\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.7360 - val_loss: 69.5598\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.8822 - val_loss: 79.0665\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.3090 - val_loss: 80.8910\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.5558 - val_loss: 69.4951\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.9558 - val_loss: 84.0542\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.3202 - val_loss: 83.3291\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.7130 - val_loss: 76.1413\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.8388 - val_loss: 67.9371\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.5272 - val_loss: 68.4672\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.1265 - val_loss: 65.8591\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.8126 - val_loss: 65.7904\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.1501 - val_loss: 68.5674\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.3167 - val_loss: 67.7648\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.3578 - val_loss: 68.1871\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.9146 - val_loss: 73.2747\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.0847 - val_loss: 82.4112\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.1376 - val_loss: 68.2821\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.9414 - val_loss: 70.4790\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 131.5882 - val_loss: 68.2019\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.9864 - val_loss: 77.5462\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.1072 - val_loss: 73.9354\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5908 - val_loss: 67.0699\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6777 - val_loss: 71.4890\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.3638 - val_loss: 68.9431\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.3117 - val_loss: 71.4274\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.1702 - val_loss: 84.1749\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0171 - val_loss: 70.4857\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6597 - val_loss: 71.7555\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.8147 - val_loss: 64.3768\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2296 - val_loss: 67.4123\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5213 - val_loss: 75.0666\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8068 - val_loss: 78.3281\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5121 - val_loss: 69.8915\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.4008 - val_loss: 68.9161\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.8306 - val_loss: 73.7072\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1867 - val_loss: 73.5699\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.3726 - val_loss: 67.8765\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.5642 - val_loss: 79.6473\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.8855 - val_loss: 77.4738\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.2119 - val_loss: 80.1314\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2940 - val_loss: 79.3405\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6783 - val_loss: 83.7562\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.0260 - val_loss: 65.1613\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.3245 - val_loss: 76.3650\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.0244 - val_loss: 70.4810\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.0760 - val_loss: 76.1801\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.5013 - val_loss: 63.3803\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.0565 - val_loss: 61.8909\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.2362 - val_loss: 63.4404\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6953 - val_loss: 64.9060\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1807 - val_loss: 66.5956\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.3588 - val_loss: 65.9764\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6460 - val_loss: 65.7094\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3980 - val_loss: 79.2722\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.0070 - val_loss: 67.4721\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.1695 - val_loss: 70.2552\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1910 - val_loss: 75.9617\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.9246 - val_loss: 77.5467\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.7631 - val_loss: 71.1164\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.9863 - val_loss: 67.1939\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.9687 - val_loss: 66.9012\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.9009 - val_loss: 70.0845\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.3438 - val_loss: 66.8687\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.0590 - val_loss: 63.5926\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9872 - val_loss: 66.2642\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1134 - val_loss: 62.3732\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.9217 - val_loss: 67.8175\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4356 - val_loss: 63.2109\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.9441 - val_loss: 67.9119\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9212 - val_loss: 65.1873\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8845 - val_loss: 66.3414\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.4479 - val_loss: 70.8317\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.7749 - val_loss: 61.9762\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6355 - val_loss: 63.5797\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4906 - val_loss: 64.9932\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5432 - val_loss: 68.2340\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.5684 - val_loss: 65.2201\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.6387 - val_loss: 64.6503\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.6605 - val_loss: 66.3433\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.1799 - val_loss: 66.1596\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.8450 - val_loss: 69.2419\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.4209 - val_loss: 65.8725\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.6045 - val_loss: 65.6883\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.2429 - val_loss: 72.9509\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.3803 - val_loss: 64.1086\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8085 - val_loss: 72.8511\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.1812 - val_loss: 77.5098\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 80.2214 - val_loss: 63.7124\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.6043 - val_loss: 64.8762\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.7601 - val_loss: 61.8046\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.6650 - val_loss: 61.4641\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.1231 - val_loss: 65.8551\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115.5825 - val_loss: 83.2107\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9500 - val_loss: 89.6252\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8279 - val_loss: 69.8859\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5188 - val_loss: 68.4619\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.0389 - val_loss: 69.8792\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1167 - val_loss: 64.7207\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4448 - val_loss: 63.3653\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.7094 - val_loss: 71.3827\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8226 - val_loss: 68.4287\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2545 - val_loss: 67.9869\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.7058 - val_loss: 63.7282\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2353 - val_loss: 78.2684\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1262 - val_loss: 77.9523\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.3023 - val_loss: 70.1209\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7339 - val_loss: 66.5594\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.7990 - val_loss: 65.6157\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.2479 - val_loss: 69.4087\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.0410 - val_loss: 64.5720\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.8326 - val_loss: 66.7391\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7214 - val_loss: 69.7397\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.1325 - val_loss: 66.7777\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3627 - val_loss: 66.3775\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.9038 - val_loss: 66.8944\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.1446 - val_loss: 65.0762\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1930 - val_loss: 67.8569\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.4015 - val_loss: 66.7505\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3317 - val_loss: 64.5558\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8813 - val_loss: 65.5893\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3089 - val_loss: 67.3924\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9744 - val_loss: 65.2123\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6177 - val_loss: 65.6974\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2934 - val_loss: 67.1168\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 59.5477\n",
      "--- Starting trial: run-20\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 32, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7278 - val_loss: 660.1677\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6630 - val_loss: 660.0914\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5932 - val_loss: 660.0114\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.5175 - val_loss: 659.9282\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.4351 - val_loss: 659.8386\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3451 - val_loss: 659.7368\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2471 - val_loss: 659.6382\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1407 - val_loss: 659.5201\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0255 - val_loss: 659.3889\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9012 - val_loss: 659.2404\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7675 - val_loss: 659.0859\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6243 - val_loss: 658.9326\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.4716 - val_loss: 658.7700\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3088 - val_loss: 658.6031\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.1363 - val_loss: 658.4122\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9536 - val_loss: 658.2208\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7607 - val_loss: 658.0267\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5576 - val_loss: 657.8257\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.3442 - val_loss: 657.5967\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 687.1204 - val_loss: 657.3804\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.8863 - val_loss: 657.1605\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6417 - val_loss: 656.9109\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.3866 - val_loss: 656.6702\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.1212 - val_loss: 656.3913\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.8450 - val_loss: 656.1029\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.5583 - val_loss: 655.8108\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.2611 - val_loss: 655.5118\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.9532 - val_loss: 655.2089\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.6348 - val_loss: 654.8784\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3058 - val_loss: 654.5602\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.9662 - val_loss: 654.2182\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.6160 - val_loss: 653.8570\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.2552 - val_loss: 653.5299\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.8839 - val_loss: 653.1680\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.5020 - val_loss: 652.7977\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.1094 - val_loss: 652.3862\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.7064 - val_loss: 651.9495\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.2927 - val_loss: 651.5007\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.8685 - val_loss: 651.0617\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.4338 - val_loss: 650.6411\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.9886 - val_loss: 650.1592\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.5329 - val_loss: 649.6981\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.0668 - val_loss: 649.2334\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.5901 - val_loss: 648.7404\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.1030 - val_loss: 648.2271\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.6057 - val_loss: 647.7098\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.0978 - val_loss: 647.1810\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.5795 - val_loss: 646.6696\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.0509 - val_loss: 646.1428\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.5120 - val_loss: 645.6131\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.9628 - val_loss: 645.1036\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.4032 - val_loss: 644.5529\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.8333 - val_loss: 643.9696\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.2534 - val_loss: 643.3631\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.6631 - val_loss: 642.7281\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 672.0626 - val_loss: 642.1013\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 671.4520 - val_loss: 641.5022\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.8312 - val_loss: 640.8735\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.2004 - val_loss: 640.2806\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.5593 - val_loss: 639.6487\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.9084 - val_loss: 638.9686\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 668.2472 - val_loss: 638.2366\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 667.5761 - val_loss: 637.5767\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.8951 - val_loss: 636.9143\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.2040 - val_loss: 636.2376\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.5029 - val_loss: 635.6544\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.7921 - val_loss: 635.0789\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.0712 - val_loss: 634.5173\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.3405 - val_loss: 633.8383\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.6000 - val_loss: 633.2067\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.8497 - val_loss: 632.5342\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.0895 - val_loss: 631.7695\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.3196 - val_loss: 631.0358\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.5402 - val_loss: 630.2939\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.7508 - val_loss: 629.5073\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.9518 - val_loss: 628.7855\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.1432 - val_loss: 627.9892\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.3248 - val_loss: 627.1266\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.4970 - val_loss: 626.2705\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.6595 - val_loss: 625.4758\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.8126 - val_loss: 624.5826\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.9560 - val_loss: 623.7490\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.0900 - val_loss: 622.7989\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.2144 - val_loss: 621.9061\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 650.3295 - val_loss: 620.9503\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.4351 - val_loss: 620.0161\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.5314 - val_loss: 619.2581\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.6183 - val_loss: 618.4056\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.6958 - val_loss: 617.3692\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 645.7640 - val_loss: 616.3094\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.8229 - val_loss: 615.2195\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.8724 - val_loss: 614.1585\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.9128 - val_loss: 613.1722\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.9441 - val_loss: 612.3135\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.9660 - val_loss: 611.4943\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.9789 - val_loss: 610.6014\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.9825 - val_loss: 609.5627\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.9771 - val_loss: 608.4089\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.9625 - val_loss: 607.1901\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.9390 - val_loss: 605.9608\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.9063 - val_loss: 604.7919\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.8646 - val_loss: 603.9069\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.8140 - val_loss: 602.8628\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.7543 - val_loss: 601.9559\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.6858 - val_loss: 601.0953\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.6082 - val_loss: 599.9102\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 628.5218 - val_loss: 598.8724\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 627.4265 - val_loss: 597.7419\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.3224 - val_loss: 596.6461\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.2094 - val_loss: 595.4507\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.0876 - val_loss: 594.2968\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.9571 - val_loss: 593.0381\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.8179 - val_loss: 591.9234\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.6697 - val_loss: 590.8822\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.5129 - val_loss: 589.7677\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.3475 - val_loss: 588.7859\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.1734 - val_loss: 587.7962\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.9907 - val_loss: 586.7672\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.7993 - val_loss: 585.6216\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.5994 - val_loss: 584.8041\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.3908 - val_loss: 583.5917\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.1738 - val_loss: 582.3749\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.9481 - val_loss: 581.1342\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.7139 - val_loss: 579.9177\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.4713 - val_loss: 578.5414\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.2202 - val_loss: 577.1779\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.9607 - val_loss: 575.8998\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 603.6927 - val_loss: 574.8847\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 602.4164 - val_loss: 573.6068\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.1317 - val_loss: 572.4132\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.8386 - val_loss: 571.0430\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.5372 - val_loss: 569.5307\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.2274 - val_loss: 568.0618\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.9095 - val_loss: 566.4783\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.5832 - val_loss: 565.2069\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.2487 - val_loss: 563.7601\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.9058 - val_loss: 562.2032\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.5549 - val_loss: 560.7332\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.1957 - val_loss: 559.4219\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.8284 - val_loss: 558.0165\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.4529 - val_loss: 556.5717\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.0693 - val_loss: 555.3173\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.6776 - val_loss: 553.9126\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.2778 - val_loss: 552.2869\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.8700 - val_loss: 550.4885\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 579.4540 - val_loss: 549.0272\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 578.0300 - val_loss: 547.4838\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.5981 - val_loss: 546.3882\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 575.1582 - val_loss: 545.1738\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 573.7103 - val_loss: 543.5097\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.2544 - val_loss: 542.1313\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 570.7906 - val_loss: 540.7358\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.3189 - val_loss: 539.2885\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.8393 - val_loss: 537.9374\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.3970 - val_loss: 539.4081\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.8624 - val_loss: 541.0251\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 563.3622 - val_loss: 540.6120\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 561.8525 - val_loss: 539.0641\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 560.4260 - val_loss: 534.3268\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.8155 - val_loss: 530.0072\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.2839 - val_loss: 527.4930\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.7427 - val_loss: 525.7018\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.1931 - val_loss: 524.0937\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.6356 - val_loss: 522.6323\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.0704 - val_loss: 521.1766\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.5034 - val_loss: 518.6911\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.9241 - val_loss: 516.8242\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.3377 - val_loss: 515.1870\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.7424 - val_loss: 513.6851\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.1390 - val_loss: 512.2454\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.5279 - val_loss: 510.8256\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.9091 - val_loss: 509.4269\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.2833 - val_loss: 508.1896\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.6544 - val_loss: 507.1450\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.0165 - val_loss: 505.8884\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.3690 - val_loss: 504.2566\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.7132 - val_loss: 502.8168\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 530.0495 - val_loss: 501.3442\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 528.6039 - val_loss: 503.2537\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.7148 - val_loss: 503.4197\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.0550 - val_loss: 502.2502\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.4072 - val_loss: 500.3153\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 521.6564 - val_loss: 497.5737\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.1598 - val_loss: 495.8199\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.2529 - val_loss: 494.3471\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.6569 - val_loss: 494.9922\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.8197 - val_loss: 494.1534\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.2982 - val_loss: 493.1516\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 511.3730 - val_loss: 494.7683\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.6752 - val_loss: 493.1861\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.9402 - val_loss: 490.5789\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 506.1553 - val_loss: 487.5873\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504.3870 - val_loss: 485.3354\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 502.8683 - val_loss: 483.3247\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 500.8291 - val_loss: 480.5681\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.0402 - val_loss: 478.2027\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.2391 - val_loss: 475.9138\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.5670 - val_loss: 474.0180\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.6508 - val_loss: 472.6281\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 491.8076 - val_loss: 472.0156\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.9910 - val_loss: 470.2281\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.1575 - val_loss: 468.4217\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.3990 - val_loss: 466.8839\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.5928 - val_loss: 466.1848\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 482.6331 - val_loss: 464.9143\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.7734 - val_loss: 462.8414\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 479.1333 - val_loss: 459.7608\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.2671 - val_loss: 457.5792\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.5330 - val_loss: 455.3994\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.6429 - val_loss: 454.3510\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.6255 - val_loss: 453.6684\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.7477 - val_loss: 452.2019\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.0148 - val_loss: 450.1552\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 466.0226 - val_loss: 447.4798\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 464.0282 - val_loss: 444.2935\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.0540 - val_loss: 441.1545\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.0580 - val_loss: 440.3684\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.1696 - val_loss: 438.5637\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.2269 - val_loss: 434.6445\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 454.3174 - val_loss: 432.1089\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 453.1472 - val_loss: 431.0331\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 451.4431 - val_loss: 431.6015\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.7455 - val_loss: 430.6584\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 447.0704 - val_loss: 430.1978\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.0957 - val_loss: 428.6094\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.7504 - val_loss: 427.0554\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.9717 - val_loss: 425.6645\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.0711 - val_loss: 423.2624\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 436.9409 - val_loss: 421.8556\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 435.3105 - val_loss: 421.7611\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.8986 - val_loss: 420.8679\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.4572 - val_loss: 419.0997\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.2853 - val_loss: 416.6144\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 428.4182 - val_loss: 411.0002\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.8198 - val_loss: 406.5983\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 423.5447 - val_loss: 407.4928\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.6088 - val_loss: 409.0682\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 420.6893 - val_loss: 409.4579\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.0218 - val_loss: 408.2087\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.9824 - val_loss: 405.5710\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.7653 - val_loss: 403.5912\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.8274 - val_loss: 401.9499\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 409.7427 - val_loss: 402.5181\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.0853 - val_loss: 399.5807\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 405.3945 - val_loss: 397.9466\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 404.2834 - val_loss: 395.2259\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 402.6859 - val_loss: 391.7968\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 401.5256 - val_loss: 389.3716\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 397.5804 - val_loss: 384.4286\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 396.8194 - val_loss: 382.0959\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 430.3418\n",
      "--- Starting trial: run-21\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 32, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 689.6641 - val_loss: 660.4182\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4398 - val_loss: 660.1863\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2103 - val_loss: 659.9566\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9724 - val_loss: 659.7087\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7215 - val_loss: 659.4526\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4536 - val_loss: 659.1728\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1636 - val_loss: 658.8788\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8465 - val_loss: 658.5462\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.4959 - val_loss: 658.1804\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1052 - val_loss: 657.7648\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.6665 - val_loss: 657.2997\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.1705 - val_loss: 656.7845\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.6068 - val_loss: 656.1804\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.9629 - val_loss: 655.5029\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.2246 - val_loss: 654.7255\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3752 - val_loss: 653.8191\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.3951 - val_loss: 652.7679\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.2615 - val_loss: 651.5392\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.9476 - val_loss: 650.1204\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.4220 - val_loss: 648.4733\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.6481 - val_loss: 646.5659\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.5828 - val_loss: 644.3530\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.1756 - val_loss: 641.7322\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.3675 - val_loss: 638.7186\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 666.0892 - val_loss: 635.1436\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.2595 - val_loss: 631.0007\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 657.7829 - val_loss: 626.1265\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.5480 - val_loss: 620.4496\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 646.4238 - val_loss: 613.8048\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.2567 - val_loss: 605.9915\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.8669 - val_loss: 596.8167\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.0431 - val_loss: 586.1287\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.5378 - val_loss: 573.5493\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.0610 - val_loss: 558.8580\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.2723 - val_loss: 541.8010\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.0790 - val_loss: 523.1354\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.9558 - val_loss: 503.1953\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 517.4839 - val_loss: 478.0268\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.4438 - val_loss: 459.4335\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.1464 - val_loss: 434.8940\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.1758 - val_loss: 409.2544\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.7531 - val_loss: 392.1934\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 392.8336 - val_loss: 373.8163\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.2755 - val_loss: 347.4040\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 363.7410 - val_loss: 320.1257\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.8499 - val_loss: 304.4942\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 327.4024 - val_loss: 268.8288\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 306.6016 - val_loss: 264.8573\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 286.4102 - val_loss: 223.6773\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.8755 - val_loss: 199.5624\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 231.7772 - val_loss: 180.8518\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.3769 - val_loss: 137.6226\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.2259 - val_loss: 116.7477\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.8914 - val_loss: 116.6364\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 166.5450 - val_loss: 102.3323\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.9807 - val_loss: 136.9628\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.9505 - val_loss: 143.8668\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9259 - val_loss: 162.5827\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.5907 - val_loss: 162.8353\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4978 - val_loss: 178.1989\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4876 - val_loss: 170.2540\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.6401 - val_loss: 157.5711\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.3615 - val_loss: 172.0172\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.1843 - val_loss: 174.5446\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 134.0117 - val_loss: 158.1333\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.8252 - val_loss: 185.8093\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.2312 - val_loss: 160.0562\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.0977 - val_loss: 159.3710\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.7251 - val_loss: 120.2398\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 141.3329 - val_loss: 128.0446\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.1857 - val_loss: 139.6898\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.4129 - val_loss: 119.9633\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.0698 - val_loss: 106.4822\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.1476 - val_loss: 124.9592\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3657 - val_loss: 100.1581\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.2511 - val_loss: 152.3020\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.1683 - val_loss: 136.7437\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.9990 - val_loss: 111.0200\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8708 - val_loss: 111.5832\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.1890 - val_loss: 126.4704\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.2296 - val_loss: 111.3735\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.7066 - val_loss: 103.8082\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6834 - val_loss: 93.4253\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3616 - val_loss: 107.5174\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.8663 - val_loss: 99.5026\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.2891 - val_loss: 80.1283\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.1740 - val_loss: 90.9058\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.1680 - val_loss: 78.5420\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.8793 - val_loss: 89.4461\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1389 - val_loss: 85.4585\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8894 - val_loss: 76.9491\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.3318 - val_loss: 74.2792\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7573 - val_loss: 66.3536\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4827 - val_loss: 80.3397\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.6538 - val_loss: 88.8310\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8936 - val_loss: 70.0115\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1222 - val_loss: 70.3394\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.9997 - val_loss: 73.2866\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2604 - val_loss: 87.8075\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8133 - val_loss: 85.9260\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0104 - val_loss: 74.8054\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.0959 - val_loss: 97.7238\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.4692 - val_loss: 89.3510\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6034 - val_loss: 67.6974\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.8878 - val_loss: 72.7011\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.3282 - val_loss: 64.0306\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.6859 - val_loss: 80.3538\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 103.0777 - val_loss: 67.9922\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.6317 - val_loss: 58.5331\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.9927 - val_loss: 68.8572\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8673 - val_loss: 58.9271\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.3020 - val_loss: 70.6462\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.4179 - val_loss: 61.3087\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1315 - val_loss: 67.2289\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.6665 - val_loss: 68.5879\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.6201 - val_loss: 71.2881\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.9830 - val_loss: 70.7741\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.3059 - val_loss: 60.8456\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6828 - val_loss: 66.0044\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0399 - val_loss: 61.2751\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.3929 - val_loss: 67.7059\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3857 - val_loss: 60.9016\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8377 - val_loss: 73.3323\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.4839 - val_loss: 66.2342\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6663 - val_loss: 68.1109\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3329 - val_loss: 62.9739\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7214 - val_loss: 64.1809\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0719 - val_loss: 71.7719\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.4811 - val_loss: 68.4440\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.6837 - val_loss: 73.8240\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1453 - val_loss: 64.5281\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.2522 - val_loss: 63.0251\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1918 - val_loss: 64.2116\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0917 - val_loss: 66.6888\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4990 - val_loss: 66.6310\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.4065 - val_loss: 61.6817\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.0644 - val_loss: 68.9640\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.8195 - val_loss: 70.8179\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.8957 - val_loss: 65.1875\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7649 - val_loss: 66.5520\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3986 - val_loss: 64.5636\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.0682 - val_loss: 67.5689\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5061 - val_loss: 65.5217\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9068 - val_loss: 70.8091\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.6503 - val_loss: 67.4292\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.6373 - val_loss: 79.1830\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.0089 - val_loss: 68.8474\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1505 - val_loss: 79.5879\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116.3101 - val_loss: 66.4121\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 108.3209 - val_loss: 66.2889\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3165 - val_loss: 71.2352\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3512 - val_loss: 73.5603\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0415 - val_loss: 71.5880\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.0174 - val_loss: 64.4027\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.4500 - val_loss: 67.3556\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.4243 - val_loss: 64.4761\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0515 - val_loss: 64.7514\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.7301 - val_loss: 62.5909\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.2193 - val_loss: 66.7320\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0039 - val_loss: 72.4574\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.4124 - val_loss: 64.2424\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9517 - val_loss: 66.2693\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9410 - val_loss: 61.5616\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.9300 - val_loss: 67.7708\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 129.5006 - val_loss: 72.1112\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 94.7047 - val_loss: 68.5790\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1586 - val_loss: 68.3892\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.7054 - val_loss: 66.8780\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.2534 - val_loss: 66.3457\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.9827 - val_loss: 81.2454\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7922 - val_loss: 73.7684\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.8227 - val_loss: 64.5355\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1516 - val_loss: 62.1490\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.3720 - val_loss: 62.3424\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8490 - val_loss: 66.3158\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1805 - val_loss: 62.8792\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1613 - val_loss: 66.9156\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5257 - val_loss: 65.8866\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6320 - val_loss: 71.8641\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9456 - val_loss: 70.6506\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4637 - val_loss: 65.5845\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2701 - val_loss: 71.6801\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.0022 - val_loss: 63.9380\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 73.8027 - val_loss: 66.2835\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.8570 - val_loss: 77.1137\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.7299 - val_loss: 66.3603\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 105.2967 - val_loss: 68.6083\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0444 - val_loss: 61.8456\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.5021 - val_loss: 62.7389\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.3119 - val_loss: 60.6523\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.8143 - val_loss: 67.4186\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.2002 - val_loss: 75.0524\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.6446 - val_loss: 66.6202\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.7797 - val_loss: 62.7934\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9989 - val_loss: 63.0207\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1335 - val_loss: 63.8469\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2190 - val_loss: 60.9539\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8746 - val_loss: 66.0391\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4152 - val_loss: 79.5515\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8335 - val_loss: 65.4660\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1993 - val_loss: 67.9517\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2478 - val_loss: 78.6561\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1234 - val_loss: 65.5839\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4667 - val_loss: 64.3187\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4414 - val_loss: 59.3776\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7502 - val_loss: 61.9105\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.5205 - val_loss: 60.9997\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.0645 - val_loss: 60.9341\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4325 - val_loss: 59.0236\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8334 - val_loss: 61.0494\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.5285 - val_loss: 60.1259\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.9410 - val_loss: 63.0669\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.5112 - val_loss: 73.6972\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9277 - val_loss: 60.3390\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 120.5769 - val_loss: 59.5998\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8251 - val_loss: 71.5456\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1035 - val_loss: 67.4674\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7305 - val_loss: 66.1678\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.0652 - val_loss: 69.4544\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2711 - val_loss: 71.0828\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.0894 - val_loss: 58.1863\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.3528 - val_loss: 69.5257\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.3066 - val_loss: 82.7784\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.8433 - val_loss: 72.4851\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5416 - val_loss: 64.2777\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3940 - val_loss: 60.9275\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6231 - val_loss: 58.6397\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.8926 - val_loss: 62.6305\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8364 - val_loss: 60.7144\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.7054 - val_loss: 63.8840\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4174 - val_loss: 69.5079\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.3578 - val_loss: 73.7004\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 100.7274 - val_loss: 72.4115\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8577 - val_loss: 69.4208\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.7297 - val_loss: 66.7151\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7050 - val_loss: 63.0320\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.5464 - val_loss: 59.8135\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6256 - val_loss: 64.1588\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.5459 - val_loss: 59.5871\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.5264 - val_loss: 68.2890\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6178 - val_loss: 80.4102\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4941 - val_loss: 91.3968\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2365 - val_loss: 70.5650\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.1253 - val_loss: 62.8258\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.0890 - val_loss: 68.4822\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.9695 - val_loss: 64.4041\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.3601 - val_loss: 65.4529\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.8994 - val_loss: 67.1824\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.1861 - val_loss: 69.1974\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.2981 - val_loss: 72.4070\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 39.2834\n",
      "--- Starting trial: run-22\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 32, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.7293 - val_loss: 660.4186\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.6683 - val_loss: 660.3355\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.6024 - val_loss: 660.2418\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5305 - val_loss: 660.1462\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4517 - val_loss: 660.0406\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3654 - val_loss: 659.9255\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2709 - val_loss: 659.8108\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1678 - val_loss: 659.6870\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0558 - val_loss: 659.5506\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9345 - val_loss: 659.4099\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8039 - val_loss: 659.2592\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.6634 - val_loss: 659.0931\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5132 - val_loss: 658.9218\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3529 - val_loss: 658.7462\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.1827 - val_loss: 658.5659\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.0021 - val_loss: 658.3652\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.8113 - val_loss: 658.1514\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6102 - val_loss: 657.9331\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3987 - val_loss: 657.7109\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1767 - val_loss: 657.4747\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9442 - val_loss: 657.2299\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7012 - val_loss: 656.9869\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4476 - val_loss: 656.7249\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1835 - val_loss: 656.4454\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9086 - val_loss: 656.1764\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6232 - val_loss: 655.8922\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3273 - val_loss: 655.5710\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0206 - val_loss: 655.2498\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 684.7032 - val_loss: 654.9474\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 684.3752 - val_loss: 654.6190\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.0367 - val_loss: 654.2820\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.6874 - val_loss: 653.9152\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3276 - val_loss: 653.5499\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.9572 - val_loss: 653.1747\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.5760 - val_loss: 652.7864\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.1842 - val_loss: 652.3803\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.7819 - val_loss: 651.9987\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 681.3691 - val_loss: 651.5884\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.9456 - val_loss: 651.1411\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.5116 - val_loss: 650.7098\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.0670 - val_loss: 650.2609\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.6120 - val_loss: 649.7358\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.1464 - val_loss: 649.2803\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.6704 - val_loss: 648.7891\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.1840 - val_loss: 648.2709\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.6870 - val_loss: 647.8126\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.1797 - val_loss: 647.2841\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.6619 - val_loss: 646.7560\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.1339 - val_loss: 646.1876\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 675.5953 - val_loss: 645.6474\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 675.0466 - val_loss: 645.1059\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.4877 - val_loss: 644.5208\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 673.9182 - val_loss: 643.9995\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.3387 - val_loss: 643.4202\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.7488 - val_loss: 642.8618\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.1489 - val_loss: 642.2378\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.5386 - val_loss: 641.6282\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.9183 - val_loss: 641.0209\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.2878 - val_loss: 640.4289\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.6472 - val_loss: 639.7595\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.9965 - val_loss: 639.1400\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.3359 - val_loss: 638.5341\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.6652 - val_loss: 637.8953\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.9844 - val_loss: 637.2567\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.2938 - val_loss: 636.4906\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.5930 - val_loss: 635.8160\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.8825 - val_loss: 635.1042\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.1620 - val_loss: 634.3415\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.4316 - val_loss: 633.6523\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 662.6915 - val_loss: 632.9312\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 661.9415 - val_loss: 632.2104\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.1818 - val_loss: 631.4360\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.4122 - val_loss: 630.6612\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.6329 - val_loss: 629.8962\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.8439 - val_loss: 629.1093\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.0453 - val_loss: 628.2833\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.2371 - val_loss: 627.4803\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.4191 - val_loss: 626.6796\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.5916 - val_loss: 625.8784\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.7545 - val_loss: 625.0578\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.9077 - val_loss: 624.1567\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.0516 - val_loss: 623.3275\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.1859 - val_loss: 622.4289\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.3106 - val_loss: 621.5095\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.4260 - val_loss: 620.5988\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.5319 - val_loss: 619.8005\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.6285 - val_loss: 618.8116\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.7157 - val_loss: 617.8547\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.7936 - val_loss: 616.9525\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.8621 - val_loss: 616.0624\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 644.9213 - val_loss: 615.1669\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 643.9714 - val_loss: 614.2775\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.0121 - val_loss: 613.2889\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.0435 - val_loss: 612.3517\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.0659 - val_loss: 611.4338\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.0790 - val_loss: 610.5125\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.0830 - val_loss: 609.4870\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.0779 - val_loss: 608.4276\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.0637 - val_loss: 607.3954\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.0404 - val_loss: 606.3915\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.0081 - val_loss: 605.3228\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.9667 - val_loss: 604.2795\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.9164 - val_loss: 603.1785\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.8571 - val_loss: 602.0844\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.7889 - val_loss: 600.9103\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.7117 - val_loss: 599.7554\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.6256 - val_loss: 598.7315\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 627.5306 - val_loss: 597.7311\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.4269 - val_loss: 596.7018\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.3142 - val_loss: 595.5659\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 624.1929 - val_loss: 594.3344\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 623.0627 - val_loss: 593.1602\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.9238 - val_loss: 591.9940\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.7761 - val_loss: 590.7728\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.6196 - val_loss: 589.6915\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.4545 - val_loss: 588.4612\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.2808 - val_loss: 587.2192\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.0983 - val_loss: 586.0312\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.9074 - val_loss: 584.9101\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 613.7078 - val_loss: 583.7040\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.4997 - val_loss: 582.5242\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.2829 - val_loss: 581.3180\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.0576 - val_loss: 580.1274\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.8239 - val_loss: 578.8886\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.5817 - val_loss: 577.6025\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.3310 - val_loss: 576.2966\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.0718 - val_loss: 575.0280\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.8042 - val_loss: 573.8345\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.5283 - val_loss: 572.5236\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 601.2439 - val_loss: 571.2993\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 599.9512 - val_loss: 570.0712\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.6503 - val_loss: 568.7719\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.3409 - val_loss: 567.4954\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.0232 - val_loss: 566.1422\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.6974 - val_loss: 564.7565\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.3632 - val_loss: 563.3689\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.0209 - val_loss: 562.0683\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.6702 - val_loss: 560.6374\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.3115 - val_loss: 559.1744\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.9445 - val_loss: 557.8210\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.5695 - val_loss: 556.3945\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.1863 - val_loss: 555.0989\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.7949 - val_loss: 553.6292\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.3956 - val_loss: 552.1857\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.9881 - val_loss: 550.7467\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.5726 - val_loss: 549.3663\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.1598 - val_loss: 549.0314\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.7239 - val_loss: 548.4772\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.2870 - val_loss: 547.3817\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.8405 - val_loss: 546.1224\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 572.3855 - val_loss: 544.7845\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 570.9759 - val_loss: 544.3894\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.4568 - val_loss: 543.7567\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.9806 - val_loss: 542.5834\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.4946 - val_loss: 541.0214\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.0001 - val_loss: 539.4708\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.4974 - val_loss: 537.8305\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.9866 - val_loss: 536.1307\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.4681 - val_loss: 534.5750\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.9418 - val_loss: 533.0103\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 557.5248 - val_loss: 532.2413\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.8951 - val_loss: 530.9041\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.3347 - val_loss: 529.2195\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.7802 - val_loss: 527.8190\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.2162 - val_loss: 526.3905\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.6603 - val_loss: 524.7544\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.0711 - val_loss: 523.1651\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.4849 - val_loss: 521.4430\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.8899 - val_loss: 519.7662\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 543.3110 - val_loss: 518.4450\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 541.6834 - val_loss: 516.9131\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.0668 - val_loss: 515.4748\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.4413 - val_loss: 513.7750\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 536.8079 - val_loss: 512.1433\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.1667 - val_loss: 510.4212\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.5179 - val_loss: 508.9079\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.8616 - val_loss: 507.3756\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.1979 - val_loss: 505.6205\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 528.5267 - val_loss: 504.1668\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 526.9318 - val_loss: 502.3125\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.1864 - val_loss: 500.3556\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.4835 - val_loss: 498.2600\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 521.9980 - val_loss: 497.1578\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.0882 - val_loss: 495.7942\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.3761 - val_loss: 494.2884\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.6544 - val_loss: 492.5628\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 514.9457 - val_loss: 491.1065\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 513.1917 - val_loss: 489.5509\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 511.4919 - val_loss: 487.4628\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 509.7553 - val_loss: 485.6537\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.9633 - val_loss: 484.8269\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 506.2123 - val_loss: 483.1510\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504.4447 - val_loss: 481.3801\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.8441 - val_loss: 479.8716\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.0207 - val_loss: 479.5385\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.1492 - val_loss: 478.0351\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.6081 - val_loss: 476.4755\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 495.6592 - val_loss: 474.4268\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.7593 - val_loss: 472.7308\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.1264 - val_loss: 471.3529\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 490.1346 - val_loss: 469.7433\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 488.3097 - val_loss: 467.9635\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.4683 - val_loss: 466.0942\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 484.6951 - val_loss: 463.8720\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 482.8132 - val_loss: 461.4957\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.3452 - val_loss: 459.1790\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 479.5375 - val_loss: 457.2317\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 477.3583 - val_loss: 455.0576\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 475.3559 - val_loss: 453.1147\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.5718 - val_loss: 451.0658\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.6326 - val_loss: 449.0771\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.9215 - val_loss: 447.2144\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.9870 - val_loss: 446.2738\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.1946 - val_loss: 444.5945\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 464.1149 - val_loss: 442.2600\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 462.7180 - val_loss: 440.3034\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.8717 - val_loss: 438.3889\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.8662 - val_loss: 436.3453\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.5831 - val_loss: 434.7769\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 454.9224 - val_loss: 432.2964\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 453.1357 - val_loss: 430.8673\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 451.2912 - val_loss: 431.3370\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.7402 - val_loss: 429.9914\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 447.1882 - val_loss: 429.3130\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.4877 - val_loss: 427.7358\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.4188 - val_loss: 425.7659\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 442.0624 - val_loss: 423.8933\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.7947 - val_loss: 421.5726\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.7322 - val_loss: 419.7313\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.1228 - val_loss: 417.3448\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.2522 - val_loss: 415.5758\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.5784 - val_loss: 413.5021\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.4925 - val_loss: 410.8481\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.5971 - val_loss: 408.6367\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.9844 - val_loss: 406.8465\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.8822 - val_loss: 404.6405\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.9081 - val_loss: 402.6943\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.2229 - val_loss: 401.2231\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.3794 - val_loss: 399.1887\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.2034 - val_loss: 397.4610\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.6809 - val_loss: 395.8824\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.6345 - val_loss: 394.8366\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.3793 - val_loss: 394.5533\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.1772 - val_loss: 393.2863\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.8179 - val_loss: 391.4591\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 407.7476 - val_loss: 390.4026\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.0703 - val_loss: 389.7613\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 401.6304 - val_loss: 387.3383\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 399.9245 - val_loss: 385.4491\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.3803 - val_loss: 384.0579\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 444.0020\n",
      "--- Starting trial: run-23\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 32, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6657 - val_loss: 658.6960\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4456 - val_loss: 658.5185\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2206 - val_loss: 658.3228\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9872 - val_loss: 658.1122\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7414 - val_loss: 657.8750\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4789 - val_loss: 657.6094\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1952 - val_loss: 657.3115\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8849 - val_loss: 656.9790\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5424 - val_loss: 656.6016\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1606 - val_loss: 656.1808\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7324 - val_loss: 655.6993\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.2485 - val_loss: 655.1647\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.6990 - val_loss: 654.5457\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.0716 - val_loss: 653.8304\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 684.3525 - val_loss: 653.0168\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.5256 - val_loss: 652.0839\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.5719 - val_loss: 651.0046\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.4692 - val_loss: 649.7706\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.1912 - val_loss: 648.3299\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.7080 - val_loss: 646.6733\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.9836 - val_loss: 644.7603\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.9761 - val_loss: 642.5181\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.6371 - val_loss: 639.9036\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.9088 - val_loss: 636.8561\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.7239 - val_loss: 633.3271\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.0038 - val_loss: 629.1674\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.6558 - val_loss: 624.3349\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 653.5717 - val_loss: 618.7039\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 647.6242 - val_loss: 612.1301\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.6642 - val_loss: 604.4028\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.5173 - val_loss: 595.4115\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.9785 - val_loss: 584.8712\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.8073 - val_loss: 572.5463\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.7221 - val_loss: 558.1055\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.3926 - val_loss: 541.3869\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.5867 - val_loss: 522.7888\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.3700 - val_loss: 504.4706\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 522.7633 - val_loss: 485.0495\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.0865 - val_loss: 464.1609\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.8925 - val_loss: 442.9378\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 450.5980 - val_loss: 421.3727\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.4071 - val_loss: 402.4846\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 409.4476 - val_loss: 380.8167\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 392.2232 - val_loss: 358.9309\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 369.8435 - val_loss: 336.4870\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 353.5531 - val_loss: 314.1293\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336.4350 - val_loss: 293.3257\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 313.6839 - val_loss: 271.2734\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 289.3437 - val_loss: 245.2719\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.8300 - val_loss: 220.6208\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.9707 - val_loss: 197.9910\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.6313 - val_loss: 176.2458\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.2993 - val_loss: 159.7932\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.0562 - val_loss: 143.6079\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 164.2930 - val_loss: 124.6807\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.8693 - val_loss: 118.1366\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.6826 - val_loss: 106.8591\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.9968 - val_loss: 104.6708\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.3371 - val_loss: 101.0206\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.5180 - val_loss: 103.4029\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.2719 - val_loss: 109.5168\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1500 - val_loss: 89.1201\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.3780 - val_loss: 95.7858\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.0800 - val_loss: 94.7111\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.8515 - val_loss: 86.4904\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 133.8360 - val_loss: 86.1041\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.4196 - val_loss: 88.3222\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.7593 - val_loss: 84.9035\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.1917 - val_loss: 90.2155\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.9458 - val_loss: 92.6472\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.4669 - val_loss: 93.7625\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.0298 - val_loss: 95.9908\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.8912 - val_loss: 89.1116\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.0029 - val_loss: 105.6360\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4316 - val_loss: 86.8344\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.7540 - val_loss: 74.8966\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9939 - val_loss: 83.8718\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9887 - val_loss: 74.3578\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3894 - val_loss: 79.1744\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9384 - val_loss: 77.6466\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2328 - val_loss: 75.9940\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.9069 - val_loss: 74.6593\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.6112 - val_loss: 98.2681\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.2069 - val_loss: 86.5062\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.2724 - val_loss: 85.4687\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.0139 - val_loss: 84.1365\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 103.5960 - val_loss: 74.3630\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2552 - val_loss: 73.8972\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4477 - val_loss: 74.4863\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.0274 - val_loss: 76.6300\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0100 - val_loss: 77.5601\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.6690 - val_loss: 94.7314\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4279 - val_loss: 77.9159\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0869 - val_loss: 79.8184\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.0019 - val_loss: 76.7320\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.9118 - val_loss: 72.4640\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.7560 - val_loss: 75.4662\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4949 - val_loss: 75.2663\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3116 - val_loss: 86.2513\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7963 - val_loss: 88.0223\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6712 - val_loss: 72.5297\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.2648 - val_loss: 98.6043\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.6467 - val_loss: 75.5285\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0510 - val_loss: 76.6950\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4126 - val_loss: 93.7612\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.2916 - val_loss: 96.8188\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.1319 - val_loss: 106.7194\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2816 - val_loss: 89.1185\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5914 - val_loss: 76.8658\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4539 - val_loss: 83.8981\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.1761 - val_loss: 73.5956\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.0176 - val_loss: 92.8095\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.6813 - val_loss: 72.3093\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.0350 - val_loss: 74.9783\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6816 - val_loss: 74.0848\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 132.6952 - val_loss: 74.9249\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9580 - val_loss: 72.9518\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3501 - val_loss: 73.7099\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8155 - val_loss: 79.5415\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1365 - val_loss: 97.7278\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0151 - val_loss: 94.8243\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0173 - val_loss: 77.6663\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5639 - val_loss: 87.6033\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.3803 - val_loss: 79.6143\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.2571 - val_loss: 87.9660\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2992 - val_loss: 75.0342\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.8778 - val_loss: 119.9090\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2384 - val_loss: 117.8008\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.8748 - val_loss: 102.9024\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.0665 - val_loss: 77.2209\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.6545 - val_loss: 101.6961\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 116.4714 - val_loss: 82.2027\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.1751 - val_loss: 76.6157\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8825 - val_loss: 69.6879\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.5912 - val_loss: 68.4742\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0455 - val_loss: 72.4621\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0954 - val_loss: 70.4639\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8428 - val_loss: 81.3206\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9928 - val_loss: 95.5364\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.5575 - val_loss: 99.7381\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.1571 - val_loss: 74.2298\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.0523 - val_loss: 96.8615\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1841 - val_loss: 82.3408\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.7286 - val_loss: 90.5352\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 103.1560 - val_loss: 72.4391\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 100.9162 - val_loss: 81.0075\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.5304 - val_loss: 127.5090\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 142.0101 - val_loss: 69.5900\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.2902 - val_loss: 70.3163\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3164 - val_loss: 75.9923\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4152 - val_loss: 79.9951\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7106 - val_loss: 82.0937\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7792 - val_loss: 108.5744\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.5441 - val_loss: 88.5809\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.3618 - val_loss: 106.7635\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6686 - val_loss: 92.0875\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5689 - val_loss: 78.6782\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.0556 - val_loss: 71.1033\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6883 - val_loss: 70.2525\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6015 - val_loss: 70.3754\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3158 - val_loss: 70.6139\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6378 - val_loss: 73.7858\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1781 - val_loss: 65.8501\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.9993 - val_loss: 68.3792\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4594 - val_loss: 92.0471\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.5081 - val_loss: 93.1269\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.8284 - val_loss: 84.4536\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.1330 - val_loss: 107.0075\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2159 - val_loss: 73.5217\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0373 - val_loss: 93.1425\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.3202 - val_loss: 80.0712\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5087 - val_loss: 74.3743\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1991 - val_loss: 70.3339\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4599 - val_loss: 71.1316\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7687 - val_loss: 67.6093\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2196 - val_loss: 97.3393\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.6497 - val_loss: 73.9844\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3763 - val_loss: 73.1328\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6758 - val_loss: 89.7434\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9748 - val_loss: 92.5476\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6211 - val_loss: 86.3201\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2516 - val_loss: 105.9878\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1394 - val_loss: 94.2296\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7537 - val_loss: 77.5216\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.5751 - val_loss: 74.8534\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.8063 - val_loss: 65.6615\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.3197 - val_loss: 85.1112\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6746 - val_loss: 66.9216\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6365 - val_loss: 72.4111\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.3255 - val_loss: 72.3350\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0954 - val_loss: 69.5957\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.7505 - val_loss: 69.5450\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9931 - val_loss: 64.0317\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.9804 - val_loss: 91.0871\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.8410 - val_loss: 144.5936\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2009 - val_loss: 73.0590\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1656 - val_loss: 96.8251\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0783 - val_loss: 69.4567\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3382 - val_loss: 89.5381\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3180 - val_loss: 66.1957\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0384 - val_loss: 81.2522\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.9323 - val_loss: 94.3613\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5742 - val_loss: 86.0216\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5174 - val_loss: 90.2634\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 87.0784 - val_loss: 77.8343\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.6226 - val_loss: 100.4783\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.6085 - val_loss: 65.0580\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7231 - val_loss: 75.5665\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0144 - val_loss: 92.0185\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1588 - val_loss: 109.5309\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4877 - val_loss: 79.9458\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.3101 - val_loss: 67.4588\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2952 - val_loss: 75.6908\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7801 - val_loss: 99.8774\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6411 - val_loss: 63.8519\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0476 - val_loss: 100.8783\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9529 - val_loss: 73.5512\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.6950 - val_loss: 65.7200\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2314 - val_loss: 62.7166\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.5602 - val_loss: 76.7420\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.3564 - val_loss: 80.8291\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7292 - val_loss: 64.5995\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4136 - val_loss: 110.0153\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.3807 - val_loss: 79.2894\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2217 - val_loss: 65.0694\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2483 - val_loss: 65.7144\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1984 - val_loss: 85.0348\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5660 - val_loss: 64.6562\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7156 - val_loss: 67.7915\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.7348 - val_loss: 107.0109\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.9260 - val_loss: 72.0244\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0290 - val_loss: 73.2171\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3132 - val_loss: 67.9118\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.9955 - val_loss: 67.9982\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.3282 - val_loss: 70.7784\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3552 - val_loss: 94.3562\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7904 - val_loss: 80.3986\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2986 - val_loss: 69.7468\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5408 - val_loss: 68.3091\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.0405 - val_loss: 90.4866\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8002 - val_loss: 92.2865\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3986 - val_loss: 92.9930\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 92.9476 - val_loss: 93.2991\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1520 - val_loss: 113.1208\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5820 - val_loss: 86.7402\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5463 - val_loss: 65.0354\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.8205 - val_loss: 93.8531\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.5310 - val_loss: 77.2495\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9588 - val_loss: 71.8547\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5926 - val_loss: 70.6425\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 50.5037\n",
      "--- Starting trial: run-24\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7158 - val_loss: 660.3898\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6183 - val_loss: 660.2953\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5106 - val_loss: 660.1830\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3911 - val_loss: 660.0657\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2579 - val_loss: 659.9228\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1097 - val_loss: 659.7706\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9453 - val_loss: 659.5953\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.7637 - val_loss: 659.4014\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5644 - val_loss: 659.1920\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3464 - val_loss: 658.9811\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1095 - val_loss: 658.7362\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8531 - val_loss: 658.4648\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5771 - val_loss: 658.1692\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2808 - val_loss: 657.8661\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9644 - val_loss: 657.5361\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6274 - val_loss: 657.1908\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.2698 - val_loss: 656.8250\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.8913 - val_loss: 656.4351\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.4917 - val_loss: 656.0190\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0710 - val_loss: 655.5891\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.6292 - val_loss: 655.1454\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 684.1661 - val_loss: 654.6693\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 683.6816 - val_loss: 654.1670\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.1758 - val_loss: 653.6572\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.6486 - val_loss: 653.1083\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.0999 - val_loss: 652.5273\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.5297 - val_loss: 651.9495\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.9380 - val_loss: 651.3312\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.3248 - val_loss: 650.7126\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.6902 - val_loss: 650.0527\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.0340 - val_loss: 649.3857\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.3563 - val_loss: 648.6921\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 677.6572 - val_loss: 647.9780\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.9366 - val_loss: 647.2415\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.1945 - val_loss: 646.5266\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.4312 - val_loss: 645.7519\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6464 - val_loss: 644.9751\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.8403 - val_loss: 644.1450\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.0128 - val_loss: 643.2903\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.1642 - val_loss: 642.4185\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.2942 - val_loss: 641.5209\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.4031 - val_loss: 640.6172\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.4908 - val_loss: 639.7108\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.5573 - val_loss: 638.7673\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.6028 - val_loss: 637.8218\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.6273 - val_loss: 636.8094\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.6309 - val_loss: 635.8265\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.6134 - val_loss: 634.8053\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.5752 - val_loss: 633.7306\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.5161 - val_loss: 632.6891\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 661.4362 - val_loss: 631.6291\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 660.3356 - val_loss: 630.5172\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.2143 - val_loss: 629.3806\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.0724 - val_loss: 628.2096\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.9098 - val_loss: 627.0390\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.7268 - val_loss: 625.8666\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.5233 - val_loss: 624.6481\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.2994 - val_loss: 623.4486\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.0552 - val_loss: 622.2276\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.7906 - val_loss: 620.9139\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.5058 - val_loss: 619.6303\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.2009 - val_loss: 618.3635\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.8757 - val_loss: 616.9850\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.5305 - val_loss: 615.6314\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.1652 - val_loss: 614.2797\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.7799 - val_loss: 612.8979\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.3748 - val_loss: 611.5123\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.9497 - val_loss: 610.1412\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 638.5049 - val_loss: 608.6945\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 637.0403 - val_loss: 607.1689\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 635.5560 - val_loss: 605.6650\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.0521 - val_loss: 604.0844\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.5286 - val_loss: 602.4998\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.9856 - val_loss: 600.9329\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.4230 - val_loss: 599.2808\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 627.8409 - val_loss: 597.7167\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.2396 - val_loss: 596.0453\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.6190 - val_loss: 594.3391\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.9791 - val_loss: 592.6614\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.3199 - val_loss: 591.0226\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.6416 - val_loss: 589.3162\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.9442 - val_loss: 587.5767\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.2278 - val_loss: 585.9178\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.4923 - val_loss: 584.2086\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.7380 - val_loss: 582.4461\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.9646 - val_loss: 580.6702\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 609.1726 - val_loss: 578.8056\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 607.3617 - val_loss: 576.9019\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 605.5321 - val_loss: 574.9639\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.6838 - val_loss: 573.1000\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.8169 - val_loss: 571.2739\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.9314 - val_loss: 569.3765\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.0275 - val_loss: 567.4611\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.1050 - val_loss: 565.5386\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.1641 - val_loss: 563.6445\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.2048 - val_loss: 561.6823\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.2273 - val_loss: 559.6942\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.2314 - val_loss: 557.6749\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.2173 - val_loss: 555.5852\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.1851 - val_loss: 553.5682\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.1348 - val_loss: 551.5170\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.0663 - val_loss: 549.5055\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.9800 - val_loss: 547.4456\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.8757 - val_loss: 545.3250\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.7534 - val_loss: 543.2365\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.6132 - val_loss: 541.1731\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.4552 - val_loss: 539.0490\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 567.2795 - val_loss: 536.9655\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.0861 - val_loss: 534.7986\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 562.9297 - val_loss: 541.8150\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.6562 - val_loss: 545.8343\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.4134 - val_loss: 545.3100\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.1509 - val_loss: 542.8286\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 553.8700 - val_loss: 540.1901\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.5713 - val_loss: 537.1155\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.2551 - val_loss: 534.0551\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.9214 - val_loss: 531.2325\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.5704 - val_loss: 528.3044\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.2021 - val_loss: 525.6405\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.8167 - val_loss: 522.6146\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.4140 - val_loss: 520.0266\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.9943 - val_loss: 517.2534\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 532.5574 - val_loss: 514.3038\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.1036 - val_loss: 511.6086\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.6328 - val_loss: 508.8528\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.1450 - val_loss: 506.3631\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 522.6404 - val_loss: 503.7941\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 520.1188 - val_loss: 501.2644\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 517.5806 - val_loss: 498.9198\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.0255 - val_loss: 496.1931\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.4537 - val_loss: 493.6708\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.8653 - val_loss: 490.9864\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.2603 - val_loss: 488.4311\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 504.6501 - val_loss: 491.5636\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.0121 - val_loss: 491.4690\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.3981 - val_loss: 496.1214\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 496.7036 - val_loss: 494.9699\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.0202 - val_loss: 492.0630\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 491.3177 - val_loss: 488.6454\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.5978 - val_loss: 484.1614\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.8611 - val_loss: 480.1664\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.1080 - val_loss: 476.7553\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 480.3385 - val_loss: 473.0247\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.5529 - val_loss: 469.5349\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.7511 - val_loss: 466.1047\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 471.9332 - val_loss: 462.3231\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.0993 - val_loss: 459.3275\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.2694 - val_loss: 459.9000\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.3966 - val_loss: 457.9417\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.5187 - val_loss: 455.2192\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.6224 - val_loss: 451.4433\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 454.7093 - val_loss: 448.0085\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 451.7800 - val_loss: 444.4110\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.8347 - val_loss: 440.6782\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 445.8736 - val_loss: 437.1820\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 442.9637 - val_loss: 436.7130\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 439.9297 - val_loss: 434.6690\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.9284 - val_loss: 431.9297\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 433.9073 - val_loss: 428.8598\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.8732 - val_loss: 425.4655\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.9406 - val_loss: 422.6159\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.0536 - val_loss: 420.9579\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.7026 - val_loss: 418.5400\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.8463 - val_loss: 415.1785\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 415.5206 - val_loss: 412.2849\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.4177 - val_loss: 408.5188\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 409.4337 - val_loss: 406.5871\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.1487 - val_loss: 404.8594\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 402.9925 - val_loss: 401.6583\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.8835 - val_loss: 398.6856\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 396.9318 - val_loss: 395.2786\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.0302 - val_loss: 392.5543\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 390.8163 - val_loss: 388.9047\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 387.4442 - val_loss: 386.0848\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.9944 - val_loss: 381.9212\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.9265 - val_loss: 376.5440\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.4965 - val_loss: 370.4897\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.1654 - val_loss: 367.3911\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 371.4717 - val_loss: 366.8850\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.9112 - val_loss: 364.5307\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 364.5749 - val_loss: 361.6523\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.4135 - val_loss: 358.3789\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 358.4350 - val_loss: 353.9927\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 355.5074 - val_loss: 350.4388\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 351.2234 - val_loss: 348.2461\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 348.3101 - val_loss: 344.4107\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 344.5573 - val_loss: 341.4672\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.3782 - val_loss: 337.7612\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 337.9703 - val_loss: 333.7618\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 334.9869 - val_loss: 330.4945\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.6154 - val_loss: 327.1911\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 328.7830 - val_loss: 323.8491\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.5593 - val_loss: 319.8987\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 321.0368 - val_loss: 315.8627\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 321.2251 - val_loss: 312.4350\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 316.3811 - val_loss: 309.0442\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 311.3989 - val_loss: 308.4088\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 311.2751 - val_loss: 307.4065\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 305.6840 - val_loss: 304.0662\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 301.2170 - val_loss: 300.6027\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.8120 - val_loss: 297.1683\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 296.2460 - val_loss: 293.1975\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 296.1828 - val_loss: 291.2402\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 296.2238 - val_loss: 288.7076\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.2415 - val_loss: 284.4767\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 284.8114 - val_loss: 279.4254\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.8756 - val_loss: 277.6062\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 277.8799 - val_loss: 272.0732\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 276.3630 - val_loss: 268.2197\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.2564 - val_loss: 264.7079\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 265.4782 - val_loss: 261.8934\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.4827 - val_loss: 258.1176\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 263.2160 - val_loss: 254.1739\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 257.8682 - val_loss: 249.6991\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 253.3450 - val_loss: 246.4040\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249.3073 - val_loss: 242.9479\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 248.5210 - val_loss: 238.6363\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.6734 - val_loss: 234.7244\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.7375 - val_loss: 229.7842\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.4409 - val_loss: 228.2334\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.4365 - val_loss: 227.1637\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 235.4989 - val_loss: 224.3136\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 226.8390 - val_loss: 221.2533\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 230.6321 - val_loss: 220.7764\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 223.8115 - val_loss: 218.4702\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.4940 - val_loss: 215.4367\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 221.8120 - val_loss: 213.1474\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 209.3362 - val_loss: 209.8855\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.5323 - val_loss: 207.8201\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.0716 - val_loss: 204.2255\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 200.5644 - val_loss: 198.7340\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.8532 - val_loss: 193.6512\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.7924 - val_loss: 189.7268\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 204.5288 - val_loss: 187.9524\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.2965 - val_loss: 187.3659\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.8778 - val_loss: 185.0885\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.1869 - val_loss: 181.8373\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.5316 - val_loss: 179.3734\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.7562 - val_loss: 176.7754\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.2882 - val_loss: 174.9674\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 183.3401 - val_loss: 171.9571\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 169.9096 - val_loss: 169.7267\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.0981 - val_loss: 168.1965\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 172.3538 - val_loss: 167.0629\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.5030 - val_loss: 164.3538\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169.5758 - val_loss: 162.4840\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169.2355 - val_loss: 161.5514\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.8621 - val_loss: 157.0188\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.9668 - val_loss: 154.9070\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.0532 - val_loss: 152.4271\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 130.1396\n",
      "--- Starting trial: run-25\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6639 - val_loss: 660.1044\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4390 - val_loss: 659.8799\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2090 - val_loss: 659.6461\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.9703 - val_loss: 659.4039\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7189 - val_loss: 659.1414\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4502 - val_loss: 658.8595\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1595 - val_loss: 658.5516\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8414 - val_loss: 658.2169\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.4899 - val_loss: 657.8400\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.0980 - val_loss: 657.4140\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6578 - val_loss: 656.9390\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1603 - val_loss: 656.3954\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.5945 - val_loss: 655.7758\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.9486 - val_loss: 655.0771\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.2077 - val_loss: 654.2721\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3553 - val_loss: 653.3312\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.3719 - val_loss: 652.2613\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.2341 - val_loss: 651.0134\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.9155 - val_loss: 649.5685\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.3843 - val_loss: 647.8897\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.6038 - val_loss: 645.9209\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 674.5308 - val_loss: 643.6276\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 672.1147 - val_loss: 640.9625\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.2961 - val_loss: 637.8548\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.0056 - val_loss: 634.2339\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.1613 - val_loss: 629.9964\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.6677 - val_loss: 625.0349\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.4129 - val_loss: 619.2244\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.2654 - val_loss: 612.4404\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.0710 - val_loss: 604.5202\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.6490 - val_loss: 595.2646\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 620.7877 - val_loss: 584.4244\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 609.2383 - val_loss: 571.7062\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.7098 - val_loss: 556.8003\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.8606 - val_loss: 539.3430\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.4729 - val_loss: 520.6592\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.2535 - val_loss: 499.6756\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.5867 - val_loss: 475.9715\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 486.9044 - val_loss: 448.3478\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 455.1121 - val_loss: 423.0730\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 421.3156 - val_loss: 390.5378\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 391.6871 - val_loss: 364.8749\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 360.7049 - val_loss: 339.9619\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 335.4211 - val_loss: 319.5727\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.3312 - val_loss: 299.9968\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 285.3743 - val_loss: 276.1360\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 253.5925 - val_loss: 255.6497\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232.7045 - val_loss: 225.0498\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.7844 - val_loss: 250.1482\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.9714 - val_loss: 253.6659\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 118.9908 - val_loss: 361.2380\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.4308 - val_loss: 269.7314\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0219 - val_loss: 293.8915\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1269 - val_loss: 385.1118\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.7691 - val_loss: 322.4673\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.8532 - val_loss: 275.4903\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.5251 - val_loss: 343.3860\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.9927 - val_loss: 365.1651\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6857 - val_loss: 211.5858\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2802 - val_loss: 211.5440\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.9184 - val_loss: 292.2936\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3341 - val_loss: 263.6431\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.2780 - val_loss: 266.3634\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.0019 - val_loss: 232.0590\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 68.0105 - val_loss: 242.4032\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9667 - val_loss: 252.0928\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.6899 - val_loss: 179.5918\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4578 - val_loss: 181.0135\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.6521 - val_loss: 162.5477\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4747 - val_loss: 149.5152\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.5853 - val_loss: 129.2323\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9544 - val_loss: 125.3426\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4030 - val_loss: 82.4673\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7203 - val_loss: 114.8512\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1848 - val_loss: 113.8047\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.8024 - val_loss: 88.9179\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1900 - val_loss: 97.3140\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3988 - val_loss: 123.6533\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.9415 - val_loss: 98.1772\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.0861 - val_loss: 86.6698\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7221 - val_loss: 102.1481\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8713 - val_loss: 97.9837\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5870 - val_loss: 119.8856\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.1664 - val_loss: 146.4324\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5135 - val_loss: 124.0460\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.5031 - val_loss: 90.8908\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9574 - val_loss: 77.5273\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0123 - val_loss: 90.1111\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115.0536 - val_loss: 87.4852\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.0094 - val_loss: 76.6511\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.0988 - val_loss: 88.6709\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1028 - val_loss: 83.3827\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3542 - val_loss: 76.8631\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.2730 - val_loss: 71.1520\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4163 - val_loss: 89.2025\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6109 - val_loss: 92.1570\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.7262 - val_loss: 78.6222\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4654 - val_loss: 82.8453\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0829 - val_loss: 85.8591\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6484 - val_loss: 96.9988\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.0592 - val_loss: 82.5322\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2340 - val_loss: 68.1312\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9929 - val_loss: 68.3850\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.6887 - val_loss: 83.4830\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.8466 - val_loss: 66.9857\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4890 - val_loss: 66.8955\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.0624 - val_loss: 66.0501\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.6250 - val_loss: 78.9933\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 62.0596 - val_loss: 70.1935\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.2450 - val_loss: 72.9133\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0347 - val_loss: 95.9877\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5609 - val_loss: 82.3731\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0277 - val_loss: 76.2024\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4358 - val_loss: 72.9470\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.9371 - val_loss: 75.8636\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.8708 - val_loss: 72.5811\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.4639 - val_loss: 69.3561\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3980 - val_loss: 86.3498\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1620 - val_loss: 80.7092\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.9519 - val_loss: 71.9519\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4493 - val_loss: 69.5684\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.1651 - val_loss: 64.7528\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.9002 - val_loss: 66.9426\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.5639 - val_loss: 74.2273\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7902 - val_loss: 77.6883\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7192 - val_loss: 71.9180\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.2712 - val_loss: 90.6769\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1694 - val_loss: 65.3909\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.1756 - val_loss: 79.3434\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3946 - val_loss: 72.8880\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7246 - val_loss: 68.1977\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9055 - val_loss: 67.6154\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5688 - val_loss: 65.6483\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.1406 - val_loss: 68.2196\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3070 - val_loss: 74.1861\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.4363 - val_loss: 70.3668\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.7836 - val_loss: 94.9281\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.9558 - val_loss: 91.0743\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.7340 - val_loss: 76.4825\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1438 - val_loss: 76.7303\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5908 - val_loss: 75.8421\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.6244 - val_loss: 77.0263\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4527 - val_loss: 66.2165\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3516 - val_loss: 70.1500\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8913 - val_loss: 74.4784\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2981 - val_loss: 71.5179\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8413 - val_loss: 63.5629\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5742 - val_loss: 66.8628\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.2890 - val_loss: 67.0079\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3590 - val_loss: 64.0615\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8510 - val_loss: 64.5049\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.2888 - val_loss: 72.6402\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2083 - val_loss: 66.8584\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6032 - val_loss: 87.2562\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2872 - val_loss: 73.7110\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3891 - val_loss: 65.6308\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.6601 - val_loss: 67.5290\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.4655 - val_loss: 72.5249\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.7116 - val_loss: 72.6414\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.6610 - val_loss: 69.9745\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7585 - val_loss: 65.2217\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0941 - val_loss: 77.5904\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0862 - val_loss: 66.5234\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0335 - val_loss: 66.3647\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0239 - val_loss: 74.8228\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1869 - val_loss: 68.0800\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7453 - val_loss: 65.9302\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 87.4607 - val_loss: 68.9192\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.0038 - val_loss: 70.8936\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9476 - val_loss: 68.7552\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9163 - val_loss: 72.9613\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3463 - val_loss: 68.5224\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8827 - val_loss: 68.2487\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0606 - val_loss: 69.4655\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.7222 - val_loss: 62.5699\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1544 - val_loss: 73.4400\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3416 - val_loss: 67.7463\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1767 - val_loss: 85.1564\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.4709 - val_loss: 71.0724\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0897 - val_loss: 68.4316\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3341 - val_loss: 64.9842\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8166 - val_loss: 64.3308\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0384 - val_loss: 66.4867\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7429 - val_loss: 64.9482\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2432 - val_loss: 67.8288\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1542 - val_loss: 68.6148\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.7522 - val_loss: 63.2674\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 75.9109 - val_loss: 64.4337\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.0827 - val_loss: 64.7828\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6847 - val_loss: 69.0304\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4808 - val_loss: 62.5751\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.4941 - val_loss: 66.3591\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.9177 - val_loss: 76.2665\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8495 - val_loss: 63.7254\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.0157 - val_loss: 64.4038\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.3758 - val_loss: 64.1828\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5797 - val_loss: 64.8963\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9132 - val_loss: 63.8121\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3545 - val_loss: 63.4077\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2209 - val_loss: 62.2185\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.1237 - val_loss: 71.1096\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7410 - val_loss: 65.6757\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7946 - val_loss: 66.2867\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.6151 - val_loss: 62.5022\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8337 - val_loss: 63.9572\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7968 - val_loss: 74.2580\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 85.0879 - val_loss: 64.1225\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.5480 - val_loss: 77.2852\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.7153 - val_loss: 62.7943\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6418 - val_loss: 62.4144\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.9174 - val_loss: 67.3297\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7271 - val_loss: 63.1382\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6794 - val_loss: 66.5324\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0594 - val_loss: 64.1857\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4701 - val_loss: 63.8253\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0144 - val_loss: 72.7781\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7583 - val_loss: 66.2873\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5400 - val_loss: 71.8448\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6186 - val_loss: 82.2130\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8723 - val_loss: 70.2917\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8500 - val_loss: 66.5687\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.0598 - val_loss: 67.2634\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7847 - val_loss: 82.9051\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 78.4989 - val_loss: 77.5506\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.2157 - val_loss: 71.7100\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9219 - val_loss: 76.0091\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6220 - val_loss: 62.9143\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0031 - val_loss: 66.0604\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8132 - val_loss: 65.2721\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2855 - val_loss: 68.8631\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3944 - val_loss: 73.9837\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.0660 - val_loss: 70.9356\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5685 - val_loss: 65.9941\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.4794 - val_loss: 66.0858\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.1461 - val_loss: 66.0452\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0725 - val_loss: 67.1912\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3877 - val_loss: 62.1210\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1654 - val_loss: 76.5908\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.7032 - val_loss: 67.8053\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9690 - val_loss: 64.9609\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7164 - val_loss: 64.2233\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9966 - val_loss: 63.8274\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.9133 - val_loss: 74.3723\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.4386 - val_loss: 63.7000\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6634 - val_loss: 71.5339\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9820 - val_loss: 80.9541\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3227 - val_loss: 71.1708\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.6140 - val_loss: 68.2632\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2958 - val_loss: 64.6817\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 67.0274 - val_loss: 64.9938\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 54.1026\n",
      "--- Starting trial: run-26\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.7219 - val_loss: 660.2456\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6397 - val_loss: 660.1663\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5475 - val_loss: 660.0795\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4433 - val_loss: 659.9828\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3253 - val_loss: 659.8645\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1918 - val_loss: 659.7316\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.0418 - val_loss: 659.5765\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8741 - val_loss: 659.4083\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.6882 - val_loss: 659.2220\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4832 - val_loss: 659.0184\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 688.2587 - val_loss: 658.7903\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0143 - val_loss: 658.5378\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.7495 - val_loss: 658.2706\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.4642 - val_loss: 657.9763\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.1581 - val_loss: 657.6710\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.8311 - val_loss: 657.3290\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.4828 - val_loss: 656.9731\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.1132 - val_loss: 656.5940\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.7224 - val_loss: 656.1903\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3099 - val_loss: 655.7671\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 684.8758 - val_loss: 655.3354\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 684.4203 - val_loss: 654.8515\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.9429 - val_loss: 654.3542\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.4438 - val_loss: 653.8441\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.9232 - val_loss: 653.3146\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.3807 - val_loss: 652.7255\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.8163 - val_loss: 652.1530\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.2304 - val_loss: 651.5437\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.6227 - val_loss: 650.9369\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.9933 - val_loss: 650.2940\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.3420 - val_loss: 649.6233\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.6693 - val_loss: 648.9146\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.9747 - val_loss: 648.1857\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.2587 - val_loss: 647.4432\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.5209 - val_loss: 646.6915\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.7616 - val_loss: 645.9334\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.9808 - val_loss: 645.1591\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.1785 - val_loss: 644.3445\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.3547 - val_loss: 643.5068\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.5096 - val_loss: 642.6213\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.6431 - val_loss: 641.6894\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.7552 - val_loss: 640.7822\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.8461 - val_loss: 639.8489\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.9158 - val_loss: 638.8369\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.9644 - val_loss: 637.8743\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.9917 - val_loss: 636.9393\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.9980 - val_loss: 635.9384\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.9834 - val_loss: 634.8801\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.9478 - val_loss: 633.7787\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.8912 - val_loss: 632.7090\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.8138 - val_loss: 631.5942\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 660.7157 - val_loss: 630.4293\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.5967 - val_loss: 629.2892\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.4572 - val_loss: 628.0720\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.2969 - val_loss: 626.7178\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.1161 - val_loss: 625.4796\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.9147 - val_loss: 624.2866\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.6930 - val_loss: 623.0882\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.4508 - val_loss: 621.8580\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.1883 - val_loss: 620.5892\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.9055 - val_loss: 619.3493\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.6025 - val_loss: 618.0911\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.2792 - val_loss: 616.8181\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.9359 - val_loss: 615.5052\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.5724 - val_loss: 614.1581\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.1890 - val_loss: 612.6464\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.7858 - val_loss: 611.1558\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.3624 - val_loss: 609.8138\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.9194 - val_loss: 608.4609\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.4566 - val_loss: 607.0953\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 635.9740 - val_loss: 605.6723\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 634.4717 - val_loss: 604.2224\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.9498 - val_loss: 602.7706\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.4084 - val_loss: 601.3696\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.8475 - val_loss: 599.7750\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.2672 - val_loss: 598.1230\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.6675 - val_loss: 596.4653\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.0484 - val_loss: 594.5895\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.4101 - val_loss: 592.8687\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.7526 - val_loss: 591.1562\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.0759 - val_loss: 589.4662\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.3799 - val_loss: 587.5637\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.6652 - val_loss: 585.5900\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.9312 - val_loss: 583.6762\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 613.1784 - val_loss: 581.9054\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.4067 - val_loss: 579.8589\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.6161 - val_loss: 577.9597\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.8068 - val_loss: 576.4113\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 605.9786 - val_loss: 574.5117\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.1320 - val_loss: 572.4745\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.2665 - val_loss: 570.5240\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.3826 - val_loss: 568.3979\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.4801 - val_loss: 566.3569\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.5592 - val_loss: 564.2693\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.6198 - val_loss: 562.3751\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.6620 - val_loss: 560.3390\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.7311 - val_loss: 559.3542\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.7010 - val_loss: 556.5714\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.6924 - val_loss: 554.3694\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.6633 - val_loss: 552.2638\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.6150 - val_loss: 550.4076\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.5482 - val_loss: 548.6021\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.4632 - val_loss: 546.7029\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.3602 - val_loss: 544.6830\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.2393 - val_loss: 542.6374\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.1005 - val_loss: 540.6029\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 569.9438 - val_loss: 538.6757\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 567.7693 - val_loss: 536.7264\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.5773 - val_loss: 534.6959\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.3674 - val_loss: 532.6620\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.1400 - val_loss: 530.5288\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.8950 - val_loss: 528.5560\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.6326 - val_loss: 526.5627\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.3526 - val_loss: 524.5864\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.0917 - val_loss: 519.7901\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.7487 - val_loss: 515.1362\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.4219 - val_loss: 513.0215\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.0746 - val_loss: 511.1743\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.7087 - val_loss: 509.2619\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.3251 - val_loss: 507.3583\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.9240 - val_loss: 505.3772\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.5057 - val_loss: 503.2870\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.1099 - val_loss: 503.5898\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.6292 - val_loss: 501.2503\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 528.2565 - val_loss: 498.2638\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 525.6848 - val_loss: 493.5626\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.1879 - val_loss: 490.0375\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.6702 - val_loss: 487.4939\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.1343 - val_loss: 485.9723\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.5808 - val_loss: 484.3170\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.0103 - val_loss: 482.7339\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 510.4229 - val_loss: 480.9264\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 507.8190 - val_loss: 479.1292\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.1984 - val_loss: 477.0130\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.6558 - val_loss: 477.8565\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.9166 - val_loss: 479.1078\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.2511 - val_loss: 478.4149\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.5665 - val_loss: 476.4739\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 491.8746 - val_loss: 476.0905\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.1542 - val_loss: 476.0312\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.4244 - val_loss: 473.9872\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.6748 - val_loss: 471.1501\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 480.9358 - val_loss: 469.0079\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 478.1498 - val_loss: 468.1388\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.3517 - val_loss: 465.5042\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.5392 - val_loss: 462.1985\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.8622 - val_loss: 457.3944\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 467.2425 - val_loss: 446.5750\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 464.1203 - val_loss: 439.8785\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.2700 - val_loss: 435.9937\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 458.3853 - val_loss: 433.4731\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 455.6183 - val_loss: 432.6792\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.5694 - val_loss: 430.8504\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.7966 - val_loss: 429.7297\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 446.8272 - val_loss: 435.7005\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.8398 - val_loss: 433.9910\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 441.1104 - val_loss: 431.0684\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.0030 - val_loss: 428.7050\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.9608 - val_loss: 424.7738\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.9705 - val_loss: 420.8554\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 429.1470 - val_loss: 416.2681\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.1763 - val_loss: 412.9384\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 423.0178 - val_loss: 409.8607\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 420.0244 - val_loss: 407.5305\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.1048 - val_loss: 407.6895\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 413.7464 - val_loss: 405.7764\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 411.0319 - val_loss: 404.5026\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.7997 - val_loss: 409.4565\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.3901 - val_loss: 408.5329\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 401.6084 - val_loss: 404.8116\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.3384 - val_loss: 402.0825\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.9300 - val_loss: 398.3007\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 391.6977 - val_loss: 394.5631\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.5899 - val_loss: 389.9536\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 385.1839 - val_loss: 385.5589\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.1292 - val_loss: 381.0715\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.8141 - val_loss: 377.3329\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.6203 - val_loss: 376.1524\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 372.6920 - val_loss: 372.1216\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 371.3630 - val_loss: 365.7669\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 375.1886 - val_loss: 363.4056\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 363.1530 - val_loss: 360.2813\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.5942 - val_loss: 358.0853\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 363.1812 - val_loss: 357.6003\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 356.9769 - val_loss: 357.6610\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 351.7586 - val_loss: 355.2905\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 349.7475 - val_loss: 353.3240\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 345.7769 - val_loss: 350.5627\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 342.8297 - val_loss: 349.2437\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.7444 - val_loss: 346.4833\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 335.9066 - val_loss: 342.9249\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.7643 - val_loss: 336.8585\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 329.8277 - val_loss: 334.8353\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 326.2315 - val_loss: 331.2066\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 323.3197 - val_loss: 325.6405\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.0373 - val_loss: 322.7844\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 317.4767 - val_loss: 320.5097\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 312.8651 - val_loss: 317.9155\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 312.4477 - val_loss: 314.6894\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 306.8206 - val_loss: 310.9952\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 307.0501 - val_loss: 306.6782\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 304.8324 - val_loss: 303.0224\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 300.4353 - val_loss: 300.5915\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.8349 - val_loss: 297.6859\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.1009 - val_loss: 291.6744\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.3273 - val_loss: 287.7482\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 288.2159 - val_loss: 284.7311\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 283.9969 - val_loss: 283.2724\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.5612 - val_loss: 280.8665\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.3431 - val_loss: 279.7006\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283.7151 - val_loss: 278.1439\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 269.3704 - val_loss: 275.7648\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 269.4495 - val_loss: 273.1415\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.5678 - val_loss: 271.1712\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.1927 - val_loss: 268.8318\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 263.6161 - val_loss: 266.3460\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.2121 - val_loss: 261.9190\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.9722 - val_loss: 258.2685\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249.1902 - val_loss: 257.4771\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.6945 - val_loss: 256.6237\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.2079 - val_loss: 254.1652\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 251.3466 - val_loss: 247.9803\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.5904 - val_loss: 241.6644\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 235.7202 - val_loss: 233.0317\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.4951 - val_loss: 228.3880\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 229.6405 - val_loss: 226.7564\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.3421 - val_loss: 225.4257\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.2540 - val_loss: 222.9984\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 225.2146 - val_loss: 221.4955\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.9781 - val_loss: 218.0909\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.1698 - val_loss: 213.1025\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.3883 - val_loss: 207.1549\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 205.3344 - val_loss: 203.1024\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 204.2553 - val_loss: 199.9559\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 197.9250 - val_loss: 196.5371\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 196.5537 - val_loss: 193.6085\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.9938 - val_loss: 192.9528\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.5561 - val_loss: 190.4430\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.6995 - val_loss: 187.5370\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.1438 - val_loss: 182.0927\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.3328 - val_loss: 177.3610\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.2559 - val_loss: 175.2601\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.7121 - val_loss: 176.9498\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.2074 - val_loss: 176.5558\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169.1740 - val_loss: 174.5167\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 178.6663 - val_loss: 168.2810\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 172.2001 - val_loss: 162.4374\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.6983 - val_loss: 160.0184\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.8396 - val_loss: 159.0487\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 172.5723 - val_loss: 158.0955\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 144.0344\n",
      "--- Starting trial: run-27\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6628 - val_loss: 660.1233\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4353 - val_loss: 659.9261\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2027 - val_loss: 659.7198\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9611 - val_loss: 659.4966\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7066 - val_loss: 659.2578\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4344 - val_loss: 658.9968\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1398 - val_loss: 658.7018\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8175 - val_loss: 658.3774\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.4610 - val_loss: 658.0222\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0636 - val_loss: 657.6201\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6169 - val_loss: 657.1646\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1116 - val_loss: 656.6362\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.5372 - val_loss: 656.0416\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.8809 - val_loss: 655.3360\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.1281 - val_loss: 654.5336\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 683.2618 - val_loss: 653.5979\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 682.2618 - val_loss: 652.5311\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.1050 - val_loss: 651.2833\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.7639 - val_loss: 649.8257\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.2064 - val_loss: 648.1465\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.3951 - val_loss: 646.1862\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.2860 - val_loss: 643.9266\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.8275 - val_loss: 641.2497\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.9594 - val_loss: 638.1163\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.6105 - val_loss: 634.4624\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.6979 - val_loss: 630.1898\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.1245 - val_loss: 625.1508\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.7759 - val_loss: 619.2957\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.5184 - val_loss: 612.4430\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.1951 - val_loss: 604.3660\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.6219 - val_loss: 594.9810\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 619.5833 - val_loss: 583.9675\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 607.8261 - val_loss: 571.0851\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.0538 - val_loss: 555.9542\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.9186 - val_loss: 538.3730\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.0128 - val_loss: 518.7623\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 537.4599 - val_loss: 501.5242\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.6735 - val_loss: 481.2354\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 483.9618 - val_loss: 452.7592\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 453.2971 - val_loss: 428.9981\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 420.8947 - val_loss: 406.2783\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 387.9551 - val_loss: 385.8200\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.6972 - val_loss: 364.6743\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336.3049 - val_loss: 339.7271\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 313.8197 - val_loss: 333.9228\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 292.7653 - val_loss: 306.9562\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 257.1624 - val_loss: 285.9508\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.2177 - val_loss: 217.1232\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 194.0597 - val_loss: 221.8650\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 168.1975 - val_loss: 177.6422\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.0460 - val_loss: 199.1110\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.8157 - val_loss: 221.8170\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7148 - val_loss: 253.1005\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5128 - val_loss: 247.4628\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.9279 - val_loss: 292.2950\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.9823 - val_loss: 282.9249\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6155 - val_loss: 286.7889\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.8613 - val_loss: 222.1678\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8015 - val_loss: 223.3077\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.3309 - val_loss: 203.2078\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2945 - val_loss: 191.1512\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.7196 - val_loss: 202.4487\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.9860 - val_loss: 189.3897\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.7412 - val_loss: 137.2857\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.5976 - val_loss: 156.7982\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.5435 - val_loss: 154.9919\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2569 - val_loss: 128.2641\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.8220 - val_loss: 151.8252\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0171 - val_loss: 118.2535\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5682 - val_loss: 135.9250\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1922 - val_loss: 108.5056\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.8963 - val_loss: 90.1915\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.7808 - val_loss: 125.4122\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2784 - val_loss: 112.2679\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.5147 - val_loss: 121.1630\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.8290 - val_loss: 98.1092\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8439 - val_loss: 86.6662\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.2950 - val_loss: 110.6168\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.3352 - val_loss: 91.1590\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5184 - val_loss: 75.9549\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2732 - val_loss: 76.5169\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3011 - val_loss: 82.2719\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9310 - val_loss: 79.4446\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4501 - val_loss: 80.8674\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.8506 - val_loss: 70.0101\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.4433 - val_loss: 75.6031\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7388 - val_loss: 91.6715\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8172 - val_loss: 72.4061\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4488 - val_loss: 64.5293\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4356 - val_loss: 72.6108\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.8331 - val_loss: 72.0736\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1851 - val_loss: 65.9888\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.6609 - val_loss: 60.0494\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 72.8229 - val_loss: 61.2630\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.8955 - val_loss: 73.8176\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 132.8939 - val_loss: 78.7642\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.3583 - val_loss: 61.5993\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9679 - val_loss: 68.5746\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8755 - val_loss: 68.0997\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.5249 - val_loss: 66.7503\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7090 - val_loss: 67.6680\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63.7849 - val_loss: 68.8388\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9046 - val_loss: 65.5869\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7332 - val_loss: 60.6143\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.3822 - val_loss: 62.9137\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6750 - val_loss: 65.4091\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2399 - val_loss: 59.8032\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 60.8384 - val_loss: 61.1815\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.6209 - val_loss: 57.0275\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5048 - val_loss: 77.0277\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9110 - val_loss: 59.9210\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2876 - val_loss: 64.0693\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.6857 - val_loss: 58.8432\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.3054 - val_loss: 59.8026\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.3595 - val_loss: 66.9992\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.5895 - val_loss: 63.6972\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1148 - val_loss: 74.7468\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.9725 - val_loss: 66.0540\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.0150 - val_loss: 81.9564\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.2457 - val_loss: 64.1495\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.5482 - val_loss: 69.2641\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6105 - val_loss: 71.3737\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1220 - val_loss: 96.3617\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 72.8286 - val_loss: 58.6919\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7650 - val_loss: 58.9865\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7912 - val_loss: 61.8742\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.2620 - val_loss: 68.2229\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1296 - val_loss: 64.4401\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 71.1716 - val_loss: 65.7239\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 68.9607 - val_loss: 68.2469\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 68.3635 - val_loss: 70.2692\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.5705 - val_loss: 66.0258\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5770 - val_loss: 72.0476\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.9294 - val_loss: 69.1849\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.5968 - val_loss: 68.7014\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 74.7697 - val_loss: 68.1312\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.0327 - val_loss: 65.8218\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5959 - val_loss: 72.2407\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4642 - val_loss: 66.7661\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1381 - val_loss: 74.7490\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8001 - val_loss: 60.2273\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0823 - val_loss: 58.5244\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6474 - val_loss: 60.4617\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.5423 - val_loss: 61.4228\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5175 - val_loss: 72.5083\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.3550 - val_loss: 76.0218\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.8270 - val_loss: 58.3401\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.0790 - val_loss: 61.0163\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7684 - val_loss: 67.3919\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.8714 - val_loss: 65.6494\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7579 - val_loss: 67.9730\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7749 - val_loss: 72.9209\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5447 - val_loss: 67.1684\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.3384 - val_loss: 72.2384\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7774 - val_loss: 61.4040\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6799 - val_loss: 64.2078\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.5152 - val_loss: 64.6967\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.6882 - val_loss: 63.7443\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0876 - val_loss: 84.5137\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7647 - val_loss: 89.0803\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7446 - val_loss: 75.8543\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 69.2023 - val_loss: 58.7595\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.7003 - val_loss: 65.6583\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6858 - val_loss: 58.9858\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4938 - val_loss: 76.7050\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.7570 - val_loss: 70.6219\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9038 - val_loss: 76.5974\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 92.5313 - val_loss: 63.0243\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 119.2372 - val_loss: 66.6571\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 115.9064 - val_loss: 62.2184\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 89.3317 - val_loss: 61.1848\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.4843 - val_loss: 71.9849\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2875 - val_loss: 64.6445\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.3990 - val_loss: 65.3273\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3803 - val_loss: 62.3862\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2931 - val_loss: 71.2086\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.2489 - val_loss: 65.4425\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.2131 - val_loss: 60.6877\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0686 - val_loss: 59.5316\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.7694 - val_loss: 63.2019\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6789 - val_loss: 72.4733\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.3816 - val_loss: 60.0027\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.9680 - val_loss: 67.9664\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8572 - val_loss: 59.7559\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7238 - val_loss: 58.9670\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3496 - val_loss: 67.4295\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7905 - val_loss: 62.8511\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9857 - val_loss: 62.5818\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.2626 - val_loss: 59.3286\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63.7376 - val_loss: 62.9959\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6824 - val_loss: 64.0634\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7025 - val_loss: 61.4541\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6465 - val_loss: 67.1239\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8851 - val_loss: 69.2090\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.0743 - val_loss: 65.1674\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0396 - val_loss: 69.9902\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9093 - val_loss: 72.2450\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0677 - val_loss: 89.1790\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.7060 - val_loss: 67.5549\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6004 - val_loss: 69.7439\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.9361 - val_loss: 64.6311\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.0087 - val_loss: 63.7934\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1291 - val_loss: 74.6946\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.8189 - val_loss: 70.4368\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.1586 - val_loss: 67.2584\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.4813 - val_loss: 61.1256\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 70.9221 - val_loss: 59.0865\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7404 - val_loss: 74.4305\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.1049 - val_loss: 59.4865\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 69.9698 - val_loss: 61.6523\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4337 - val_loss: 62.5362\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1637 - val_loss: 59.3009\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4043 - val_loss: 59.7002\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.8984 - val_loss: 59.3086\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0177 - val_loss: 63.0613\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.4339 - val_loss: 65.7270\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3646 - val_loss: 61.7072\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4237 - val_loss: 67.6746\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.6608 - val_loss: 61.6242\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.0493 - val_loss: 60.0909\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.0510 - val_loss: 60.3211\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.3810 - val_loss: 62.1758\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.9447 - val_loss: 67.2550\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.1670 - val_loss: 69.5452\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3356 - val_loss: 64.5856\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5364 - val_loss: 73.0372\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4966 - val_loss: 63.9291\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0419 - val_loss: 62.2645\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6743 - val_loss: 59.9993\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2816 - val_loss: 66.7785\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.2512 - val_loss: 65.1191\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3207 - val_loss: 71.7548\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3895 - val_loss: 64.6422\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1816 - val_loss: 60.4831\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.1565 - val_loss: 66.1222\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6970 - val_loss: 70.7965\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7648 - val_loss: 67.8343\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6699 - val_loss: 67.8927\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0111 - val_loss: 64.6426\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0659 - val_loss: 66.1310\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 110.5890 - val_loss: 67.5989\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6916 - val_loss: 60.0038\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2903 - val_loss: 66.0625\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3276 - val_loss: 66.5922\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8001 - val_loss: 59.2267\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.3993 - val_loss: 70.8848\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0711 - val_loss: 62.5640\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4644 - val_loss: 61.9104\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5207 - val_loss: 63.1437\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3544 - val_loss: 60.4408\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 36.1432\n",
      "--- Starting trial: run-28\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.7213 - val_loss: 659.7613\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6374 - val_loss: 659.6451\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5436 - val_loss: 659.5162\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.4379 - val_loss: 659.3700\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.3184 - val_loss: 659.2125\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1837 - val_loss: 659.0434\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0325 - val_loss: 658.8538\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8640 - val_loss: 658.6480\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6772 - val_loss: 658.4299\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4717 - val_loss: 658.1906\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2468 - val_loss: 657.9373\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0021 - val_loss: 657.6669\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7372 - val_loss: 657.3758\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.4521 - val_loss: 657.0692\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1462 - val_loss: 656.7435\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.8193 - val_loss: 656.3975\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.4715 - val_loss: 656.0338\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1024 - val_loss: 655.6526\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 685.7121 - val_loss: 655.2527\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.3003 - val_loss: 654.8307\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.8669 - val_loss: 654.3870\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 684.4120 - val_loss: 653.9358\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.9355 - val_loss: 653.4542\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.4373 - val_loss: 652.9673\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.9174 - val_loss: 652.4519\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.3758 - val_loss: 651.9044\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.8124 - val_loss: 651.3652\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.2274 - val_loss: 650.7964\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.6206 - val_loss: 650.1915\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.9921 - val_loss: 649.5958\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.3419 - val_loss: 648.9565\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.6700 - val_loss: 648.3029\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.9765 - val_loss: 647.6243\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.2614 - val_loss: 646.9058\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.5247 - val_loss: 646.1904\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.7663 - val_loss: 645.4187\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.9865 - val_loss: 644.6415\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.1851 - val_loss: 643.8726\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.3623 - val_loss: 643.0643\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 672.5180 - val_loss: 642.2593\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.6525 - val_loss: 641.4166\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.7656 - val_loss: 640.5475\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.8574 - val_loss: 639.6602\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.9280 - val_loss: 638.7720\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.9775 - val_loss: 637.8414\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.0057 - val_loss: 636.8950\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.0130 - val_loss: 635.9006\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.9993 - val_loss: 634.9228\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.9645 - val_loss: 633.8939\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.9089 - val_loss: 632.8298\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.8323 - val_loss: 631.7828\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.7350 - val_loss: 630.7496\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.6169 - val_loss: 629.6353\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.4782 - val_loss: 628.4878\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 657.3187 - val_loss: 627.3583\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.1388 - val_loss: 626.1388\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.9383 - val_loss: 624.9961\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.7173 - val_loss: 623.7932\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.4760 - val_loss: 622.5092\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.2142 - val_loss: 621.3502\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.9321 - val_loss: 620.0607\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 648.6299 - val_loss: 618.7382\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.3074 - val_loss: 617.4069\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.9648 - val_loss: 616.0229\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 644.6022 - val_loss: 614.6586\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 643.2195 - val_loss: 613.2852\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 641.8168 - val_loss: 611.8620\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.3943 - val_loss: 610.4663\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.9519 - val_loss: 609.0608\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.4898 - val_loss: 607.6425\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 636.0079 - val_loss: 606.1523\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.5063 - val_loss: 604.7097\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.9852 - val_loss: 603.1819\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.4444 - val_loss: 601.7175\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.8842 - val_loss: 600.1417\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.3046 - val_loss: 598.5977\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.7054 - val_loss: 596.9843\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.0869 - val_loss: 595.4208\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.4493 - val_loss: 593.8052\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.7924 - val_loss: 592.2278\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.1163 - val_loss: 590.6432\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.4211 - val_loss: 588.9588\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.7068 - val_loss: 587.2657\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.9735 - val_loss: 585.6821\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.2212 - val_loss: 584.0312\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.4501 - val_loss: 582.3386\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.6601 - val_loss: 580.4834\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 607.8514 - val_loss: 578.5203\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.0239 - val_loss: 576.4984\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.1777 - val_loss: 574.4642\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 602.3128 - val_loss: 572.5634\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.4294 - val_loss: 570.6896\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.5275 - val_loss: 568.7325\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.6071 - val_loss: 566.6693\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.6683 - val_loss: 564.6539\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.7111 - val_loss: 562.6933\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.7355 - val_loss: 560.7250\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.7417 - val_loss: 558.7692\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.7298 - val_loss: 556.7266\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.6995 - val_loss: 554.7540\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.6512 - val_loss: 552.7290\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.5848 - val_loss: 550.5900\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.5005 - val_loss: 548.4695\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.3983 - val_loss: 546.2720\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 574.2779 - val_loss: 544.2549\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.1398 - val_loss: 542.1562\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.9838 - val_loss: 540.0133\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.8101 - val_loss: 537.8555\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.6729 - val_loss: 540.3858\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.4219 - val_loss: 539.5659\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.1982 - val_loss: 537.8350\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.9551 - val_loss: 535.6690\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.6936 - val_loss: 533.3229\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.4142 - val_loss: 530.9846\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.1173 - val_loss: 528.7159\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.8030 - val_loss: 526.2872\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.4891 - val_loss: 526.9581\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.1315 - val_loss: 526.6196\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.7691 - val_loss: 524.8967\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 540.3872 - val_loss: 522.4667\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 537.9871 - val_loss: 519.9338\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.5695 - val_loss: 517.0804\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.1346 - val_loss: 514.7294\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.6827 - val_loss: 511.8357\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 528.2137 - val_loss: 509.3897\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.7277 - val_loss: 506.7905\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.2250 - val_loss: 504.1992\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 520.7053 - val_loss: 501.4329\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 518.1689 - val_loss: 498.6143\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 515.6157 - val_loss: 496.1232\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.0927 - val_loss: 496.0346\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 510.4692 - val_loss: 495.6195\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 507.8711 - val_loss: 493.6793\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.2534 - val_loss: 490.9473\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 502.6178 - val_loss: 488.3164\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 499.9651 - val_loss: 485.1831\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 497.2958 - val_loss: 482.0730\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 494.6100 - val_loss: 479.4597\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 491.9077 - val_loss: 476.4501\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.1892 - val_loss: 473.3711\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.4543 - val_loss: 470.7729\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.7032 - val_loss: 468.0597\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.9358 - val_loss: 465.6422\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 478.1547 - val_loss: 464.8798\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.3629 - val_loss: 463.2755\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.5526 - val_loss: 460.6150\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.7229 - val_loss: 457.5032\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 466.9180 - val_loss: 457.0215\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 464.0249 - val_loss: 454.0879\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.1483 - val_loss: 450.8496\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 458.2538 - val_loss: 447.5623\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 455.3652 - val_loss: 444.0987\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.4559 - val_loss: 440.5422\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 449.4978 - val_loss: 436.9934\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.6629 - val_loss: 435.2520\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.5940 - val_loss: 432.7561\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.7907 - val_loss: 428.5161\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 437.6461 - val_loss: 424.5331\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 434.6510 - val_loss: 420.9893\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.6242 - val_loss: 418.0396\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.7264 - val_loss: 417.8078\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.6104 - val_loss: 416.2540\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 423.0156 - val_loss: 414.2674\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 419.4725 - val_loss: 410.9997\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.5285 - val_loss: 407.3737\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 414.0525 - val_loss: 404.2638\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.3064 - val_loss: 401.1959\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.4069 - val_loss: 397.9158\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.6880 - val_loss: 394.8417\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 401.4111 - val_loss: 391.5863\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.8350 - val_loss: 388.2883\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 394.8063 - val_loss: 384.6486\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 391.6680 - val_loss: 380.6129\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.7639 - val_loss: 376.9050\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 386.1084 - val_loss: 372.1215\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.1691 - val_loss: 369.1753\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.2315 - val_loss: 366.2415\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 376.8141 - val_loss: 364.0230\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 372.9836 - val_loss: 362.0725\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.7970 - val_loss: 358.9931\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.0158 - val_loss: 356.6503\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 362.8270 - val_loss: 354.0262\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 359.6576 - val_loss: 350.3000\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.4803 - val_loss: 346.4805\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 353.7546 - val_loss: 342.6955\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.0974 - val_loss: 338.7314\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 346.4179 - val_loss: 335.1771\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 343.6911 - val_loss: 332.1888\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 339.8497 - val_loss: 328.9597\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336.3797 - val_loss: 326.0102\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 334.7292 - val_loss: 321.6535\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.1886 - val_loss: 318.5972\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 328.9735 - val_loss: 316.8251\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 323.5073 - val_loss: 313.4368\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.9533 - val_loss: 311.2091\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.6367 - val_loss: 308.0263\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 314.2528 - val_loss: 304.8581\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 311.1350 - val_loss: 300.9700\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 308.7411 - val_loss: 298.9179\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 304.7140 - val_loss: 296.2922\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.5968 - val_loss: 293.0301\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 300.2477 - val_loss: 289.9949\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.6442 - val_loss: 286.7585\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.5011 - val_loss: 284.6292\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 290.3480 - val_loss: 281.3573\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.9706 - val_loss: 279.8665\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283.9733 - val_loss: 277.6024\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.6737 - val_loss: 274.4450\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.6133 - val_loss: 271.6862\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 273.6012 - val_loss: 268.5147\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 275.3179 - val_loss: 265.4662\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.7823 - val_loss: 262.7985\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.7218 - val_loss: 259.7457\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 264.2626 - val_loss: 257.3548\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 257.4949 - val_loss: 253.3200\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.6914 - val_loss: 250.5446\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.2982 - val_loss: 247.3626\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.9816 - val_loss: 245.6156\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.1624 - val_loss: 242.6207\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.8605 - val_loss: 239.0670\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.4275 - val_loss: 234.7489\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 236.7486 - val_loss: 231.2414\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.8227 - val_loss: 228.3944\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232.9766 - val_loss: 225.6066\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.9116 - val_loss: 223.5447\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 221.5715 - val_loss: 221.1662\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 218.9137 - val_loss: 218.7995\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 218.3330 - val_loss: 215.9833\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.5016 - val_loss: 214.9639\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.5391 - val_loss: 212.5103\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 216.0650 - val_loss: 211.0054\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.0898 - val_loss: 208.1197\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.1340 - val_loss: 205.8447\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203.3628 - val_loss: 203.2509\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 192.4398 - val_loss: 200.7903\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.3564 - val_loss: 197.1720\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.3839 - val_loss: 194.7011\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 194.6723 - val_loss: 192.1663\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.4837 - val_loss: 190.5296\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.1150 - val_loss: 188.6488\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.6755 - val_loss: 187.4513\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 185.3988 - val_loss: 185.2953\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 171.4504 - val_loss: 182.1770\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 174.1413 - val_loss: 179.9794\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.7088 - val_loss: 177.1206\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 161.7011 - val_loss: 174.9697\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 168.8945 - val_loss: 172.1800\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.7137 - val_loss: 168.6021\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 165.8453 - val_loss: 166.0844\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.4132 - val_loss: 163.7700\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 159.0438\n",
      "--- Starting trial: run-29\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 689.6586 - val_loss: 660.0773\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4204 - val_loss: 659.8288\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1768 - val_loss: 659.5713\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.9236 - val_loss: 659.2982\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.6564 - val_loss: 659.0087\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3704 - val_loss: 658.6943\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0604 - val_loss: 658.3549\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7204 - val_loss: 657.9756\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3440 - val_loss: 657.5560\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9235 - val_loss: 657.0919\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4503 - val_loss: 656.5638\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9145 - val_loss: 655.9663\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.3044 - val_loss: 655.2837\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.6064 - val_loss: 654.4982\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.8050 - val_loss: 653.6048\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.8818 - val_loss: 652.5706\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.8155 - val_loss: 651.3831\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.5808 - val_loss: 649.9961\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.1486 - val_loss: 648.4067\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 677.4843 - val_loss: 646.5499\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.5480 - val_loss: 644.3849\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.2923 - val_loss: 641.8860\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.6619 - val_loss: 638.9588\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.5923 - val_loss: 635.5443\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.0073 - val_loss: 631.5710\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.8179 - val_loss: 626.9368\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.9198 - val_loss: 621.5095\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.1906 - val_loss: 615.1753\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.4868 - val_loss: 607.7214\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.6402 - val_loss: 599.0197\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.4534 - val_loss: 588.9067\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.6953 - val_loss: 576.9853\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.0945 - val_loss: 563.0577\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.3330 - val_loss: 546.7659\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 570.1891 - val_loss: 528.4965\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 550.4402 - val_loss: 508.9909\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.6512 - val_loss: 488.4867\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 501.6299 - val_loss: 465.1772\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 474.4033 - val_loss: 438.6630\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 442.8509 - val_loss: 409.0654\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.8780 - val_loss: 379.3413\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.7009 - val_loss: 348.5804\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.3969 - val_loss: 325.4300\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.6193 - val_loss: 294.0893\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.9303 - val_loss: 264.6604\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.0894 - val_loss: 236.3492\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.5131 - val_loss: 207.8239\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 217.7685 - val_loss: 182.0075\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 204.1700 - val_loss: 168.3915\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 185.2354 - val_loss: 148.0799\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 189.8716 - val_loss: 132.3340\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 143.8678 - val_loss: 122.6126\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 145.7086 - val_loss: 113.1794\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.0046 - val_loss: 106.6208\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.5094 - val_loss: 104.0234\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.3513 - val_loss: 112.5907\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.7575 - val_loss: 108.7880\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2432 - val_loss: 96.4609\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8274 - val_loss: 88.3854\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7397 - val_loss: 82.4925\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.1408 - val_loss: 94.3831\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3586 - val_loss: 103.1887\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.2548 - val_loss: 89.5167\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9245 - val_loss: 91.3952\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.7988 - val_loss: 89.9223\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2069 - val_loss: 84.2787\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.9815 - val_loss: 87.6863\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4946 - val_loss: 84.5478\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 86.2910 - val_loss: 98.6822\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.9159 - val_loss: 97.8654\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6080 - val_loss: 78.1121\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4569 - val_loss: 77.3044\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.1533 - val_loss: 71.8777\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3430 - val_loss: 79.1863\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.5288 - val_loss: 69.0460\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.3714 - val_loss: 67.7076\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.1928 - val_loss: 72.3182\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8272 - val_loss: 66.6395\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5410 - val_loss: 78.0125\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.5332 - val_loss: 71.1973\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.8933 - val_loss: 68.2360\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.6659 - val_loss: 84.3169\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.3787 - val_loss: 76.3049\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.4561 - val_loss: 84.2447\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.6532 - val_loss: 71.0173\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.6564 - val_loss: 87.8716\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.4207 - val_loss: 73.6062\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3255 - val_loss: 85.1364\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4091 - val_loss: 75.1818\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.9473 - val_loss: 67.7534\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.1029 - val_loss: 73.7794\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3739 - val_loss: 68.5779\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3214 - val_loss: 74.6209\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9367 - val_loss: 67.7315\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8063 - val_loss: 70.3180\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5232 - val_loss: 66.7608\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8017 - val_loss: 64.6771\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2347 - val_loss: 78.5390\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7650 - val_loss: 65.3371\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.8400 - val_loss: 93.5623\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.7735 - val_loss: 65.2254\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2961 - val_loss: 69.8150\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1409 - val_loss: 64.6733\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.4243 - val_loss: 65.2825\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6122 - val_loss: 64.3540\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.7566 - val_loss: 67.1933\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.6440 - val_loss: 65.3839\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4071 - val_loss: 66.1407\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.8285 - val_loss: 74.8829\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.3631 - val_loss: 67.8980\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.4822 - val_loss: 64.5881\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0556 - val_loss: 66.4778\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.6223 - val_loss: 65.8931\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.2679 - val_loss: 86.6050\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.8269 - val_loss: 64.0536\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1676 - val_loss: 62.4772\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.9853 - val_loss: 69.9533\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1940 - val_loss: 66.1883\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.2357 - val_loss: 68.3861\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.8312 - val_loss: 81.0754\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.1965 - val_loss: 65.5466\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 89.7040 - val_loss: 72.1310\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4609 - val_loss: 89.6607\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.2634 - val_loss: 64.5945\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4090 - val_loss: 71.9489\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.8518 - val_loss: 65.3549\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7610 - val_loss: 67.8946\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.6260 - val_loss: 64.3773\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.3544 - val_loss: 68.5177\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.7395 - val_loss: 68.4348\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9225 - val_loss: 63.8433\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.7315 - val_loss: 65.0399\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9321 - val_loss: 76.2360\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9918 - val_loss: 83.7899\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.2195 - val_loss: 96.8972\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3248 - val_loss: 67.2890\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.9104 - val_loss: 66.9935\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.8018 - val_loss: 66.2393\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.5676 - val_loss: 63.8741\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5504 - val_loss: 61.0622\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9132 - val_loss: 67.9232\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.4942 - val_loss: 73.9455\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4856 - val_loss: 73.9671\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.4244 - val_loss: 76.7570\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.2374 - val_loss: 78.1119\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.3791 - val_loss: 80.2854\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3826 - val_loss: 72.6092\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.4306 - val_loss: 61.5138\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9127 - val_loss: 63.6383\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8158 - val_loss: 69.0242\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4864 - val_loss: 67.7463\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9433 - val_loss: 66.2868\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.7960 - val_loss: 72.1223\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.7484 - val_loss: 80.3727\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2004 - val_loss: 78.6462\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.8646 - val_loss: 65.7806\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.4512 - val_loss: 66.2249\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1855 - val_loss: 65.7357\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.8022 - val_loss: 66.8775\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.7306 - val_loss: 64.4361\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.5852 - val_loss: 68.0999\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.4415 - val_loss: 64.2363\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.5413 - val_loss: 67.3068\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6969 - val_loss: 81.8431\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5812 - val_loss: 65.3494\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.0406 - val_loss: 72.1106\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.0267 - val_loss: 73.1906\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9067 - val_loss: 61.3645\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.0151 - val_loss: 91.9253\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1434 - val_loss: 64.2444\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.9423 - val_loss: 73.0883\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7140 - val_loss: 63.5695\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.5518 - val_loss: 64.6804\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 131.3047 - val_loss: 61.0391\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52.6932 - val_loss: 60.2940\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.8098 - val_loss: 81.9862\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2076 - val_loss: 68.2832\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8437 - val_loss: 73.8600\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1226 - val_loss: 62.0382\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3513 - val_loss: 60.7311\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5685 - val_loss: 62.9511\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.0917 - val_loss: 62.2565\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2480 - val_loss: 64.1700\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.0740 - val_loss: 66.0817\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.3162 - val_loss: 62.9314\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.1173 - val_loss: 64.8208\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6259 - val_loss: 60.9407\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5253 - val_loss: 77.5718\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 67.3141 - val_loss: 88.9566\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0760 - val_loss: 79.4595\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4687 - val_loss: 70.5035\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3501 - val_loss: 59.7770\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.7955 - val_loss: 62.6529\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.9825 - val_loss: 68.8190\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4750 - val_loss: 73.8537\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 63.3605 - val_loss: 70.9206\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3726 - val_loss: 64.4115\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3838 - val_loss: 74.3022\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9939 - val_loss: 62.9381\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0270 - val_loss: 61.0664\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.5664 - val_loss: 59.2204\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.4437 - val_loss: 69.0486\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8603 - val_loss: 69.8211\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.8640 - val_loss: 65.4001\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.9328 - val_loss: 59.2713\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.3604 - val_loss: 61.1227\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.4399 - val_loss: 60.0953\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0806 - val_loss: 62.4393\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0698 - val_loss: 80.9301\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8350 - val_loss: 63.2266\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4928 - val_loss: 60.7249\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.6303 - val_loss: 62.6734\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6203 - val_loss: 61.4993\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3639 - val_loss: 57.7350\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9896 - val_loss: 67.9445\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.3155 - val_loss: 63.6754\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.9341 - val_loss: 69.9578\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.0113 - val_loss: 63.4216\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.3999 - val_loss: 62.4948\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9871 - val_loss: 60.2839\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.8695 - val_loss: 63.9984\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8874 - val_loss: 70.3456\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 100.4503 - val_loss: 64.4272\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5845 - val_loss: 74.0028\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.3597 - val_loss: 70.4315\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2557 - val_loss: 65.1348\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.1267 - val_loss: 64.3927\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 96.6800 - val_loss: 70.9226\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.0544 - val_loss: 59.4785\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.9253 - val_loss: 71.6358\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 59.4020 - val_loss: 67.7117\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2889 - val_loss: 83.1591\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.2218 - val_loss: 72.6266\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.7670 - val_loss: 58.5160\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.9623 - val_loss: 79.9518\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 61.5333 - val_loss: 77.6989\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 62.4696 - val_loss: 94.6636\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4504 - val_loss: 63.4767\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.0200 - val_loss: 57.0818\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63.1242 - val_loss: 60.1386\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.6205 - val_loss: 61.4093\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1737 - val_loss: 64.8395\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.7642 - val_loss: 66.3752\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.4638 - val_loss: 65.3597\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1276 - val_loss: 74.0225\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5257 - val_loss: 63.4505\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2344 - val_loss: 74.0700\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.9471 - val_loss: 73.0512\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 48.7589 - val_loss: 63.6168\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.9790 - val_loss: 79.9311\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 84.4688\n",
      "--- Starting trial: run-30\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7159 - val_loss: 660.2845\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6189 - val_loss: 660.1897\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5119 - val_loss: 660.0732\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.3928 - val_loss: 659.9437\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.2603 - val_loss: 659.8133\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1127 - val_loss: 659.6639\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9489 - val_loss: 659.4966\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7679 - val_loss: 659.3093\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5692 - val_loss: 659.0967\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3521 - val_loss: 658.8820\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1158 - val_loss: 658.6347\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.8603 - val_loss: 658.3718\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5851 - val_loss: 658.0784\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2896 - val_loss: 657.7770\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9739 - val_loss: 657.4667\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6379 - val_loss: 657.1304\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.2811 - val_loss: 656.7681\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9034 - val_loss: 656.3915\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.5048 - val_loss: 655.9858\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.0850 - val_loss: 655.5670\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 684.6440 - val_loss: 655.1133\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.1818 - val_loss: 654.6482\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.6982 - val_loss: 654.1423\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.1932 - val_loss: 653.6422\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.6668 - val_loss: 653.0870\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.1191 - val_loss: 652.5206\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.5497 - val_loss: 651.9390\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.9589 - val_loss: 651.3118\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.3465 - val_loss: 650.6858\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.7126 - val_loss: 650.0446\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.0573 - val_loss: 649.3828\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.3804 - val_loss: 648.7245\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.6821 - val_loss: 648.0281\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.9623 - val_loss: 647.2711\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.2210 - val_loss: 646.5245\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.4584 - val_loss: 645.7509\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6744 - val_loss: 644.9634\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 673.8689 - val_loss: 644.1581\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 673.0423 - val_loss: 643.3303\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.1943 - val_loss: 642.5148\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.3251 - val_loss: 641.6480\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.4346 - val_loss: 640.7419\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.5229 - val_loss: 639.8257\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.5903 - val_loss: 638.8799\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.6365 - val_loss: 637.9133\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.6616 - val_loss: 636.9675\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.6657 - val_loss: 635.9542\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 664.6490 - val_loss: 634.8959\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.6113 - val_loss: 633.8459\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.5528 - val_loss: 632.7532\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.4736 - val_loss: 631.6462\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.3735 - val_loss: 630.5397\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.2528 - val_loss: 629.3704\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.1115 - val_loss: 628.1954\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.9496 - val_loss: 627.0413\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.7671 - val_loss: 625.8931\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.5641 - val_loss: 624.7076\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.3408 - val_loss: 623.4425\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.0971 - val_loss: 622.2028\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.8331 - val_loss: 620.8754\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.5488 - val_loss: 619.5861\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.2443 - val_loss: 618.2947\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.9197 - val_loss: 616.9730\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 645.5749 - val_loss: 615.6017\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.2101 - val_loss: 614.2515\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 642.8254 - val_loss: 612.9315\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.4207 - val_loss: 611.5272\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.9962 - val_loss: 610.1083\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.5519 - val_loss: 608.7167\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.0878 - val_loss: 607.2372\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.6039 - val_loss: 605.6838\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.1004 - val_loss: 604.2192\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.5773 - val_loss: 602.6945\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.0348 - val_loss: 601.1280\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.4727 - val_loss: 599.5707\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 627.8911 - val_loss: 598.0002\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 626.2902 - val_loss: 596.3437\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.6700 - val_loss: 594.6636\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.0305 - val_loss: 593.0132\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.3718 - val_loss: 591.3972\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.6939 - val_loss: 589.7744\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 617.9969 - val_loss: 588.1302\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.2809 - val_loss: 586.4671\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.5459 - val_loss: 584.8321\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.7919 - val_loss: 583.0308\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.0191 - val_loss: 581.3030\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.2274 - val_loss: 579.5052\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.4169 - val_loss: 577.7084\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 605.5876 - val_loss: 575.7830\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 603.7397 - val_loss: 573.8916\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.8733 - val_loss: 572.0109\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.9881 - val_loss: 570.1514\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.0846 - val_loss: 568.1413\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.1625 - val_loss: 566.2672\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.2220 - val_loss: 564.3584\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.2631 - val_loss: 562.3858\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 590.2858 - val_loss: 560.4468\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.2904 - val_loss: 558.5175\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.2767 - val_loss: 556.5506\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.2449 - val_loss: 554.5280\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.1949 - val_loss: 552.4933\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.2920 - val_loss: 556.8786\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.0527 - val_loss: 556.4702\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.9517 - val_loss: 554.7790\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.8308 - val_loss: 552.3212\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.6913 - val_loss: 549.7873\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.5337 - val_loss: 547.1918\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.3582 - val_loss: 544.5827\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.1649 - val_loss: 542.1152\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.9539 - val_loss: 539.8222\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.7252 - val_loss: 537.5671\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.4789 - val_loss: 535.4320\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 556.2153 - val_loss: 532.9327\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.9340 - val_loss: 530.6212\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.6353 - val_loss: 528.1354\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.3193 - val_loss: 525.6525\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.9859 - val_loss: 523.2280\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.6351 - val_loss: 520.7300\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.2672 - val_loss: 518.3283\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 539.8820 - val_loss: 515.9153\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 537.4797 - val_loss: 513.4359\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.0603 - val_loss: 511.2122\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 532.6238 - val_loss: 508.9785\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.1703 - val_loss: 506.6359\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.6998 - val_loss: 504.3648\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 525.2123 - val_loss: 501.8948\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 522.7081 - val_loss: 499.3397\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.3571 - val_loss: 500.7605\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 517.6673 - val_loss: 503.3194\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.1219 - val_loss: 502.3906\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.5543 - val_loss: 499.9088\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.9675 - val_loss: 497.3647\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.3632 - val_loss: 494.4891\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 504.7417 - val_loss: 491.4441\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.1036 - val_loss: 487.8098\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 499.4488 - val_loss: 484.8108\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 496.7776 - val_loss: 481.8557\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 494.1036 - val_loss: 482.1037\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 491.3998 - val_loss: 479.4082\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 488.6829 - val_loss: 476.5810\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.9475 - val_loss: 472.8853\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 483.1950 - val_loss: 469.4111\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 480.4259 - val_loss: 466.3565\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.9315 - val_loss: 466.2663\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.8866 - val_loss: 465.7401\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.3165 - val_loss: 465.1144\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.3004 - val_loss: 463.3421\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.4641 - val_loss: 460.2479\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.6033 - val_loss: 456.9450\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.7228 - val_loss: 454.0093\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.8301 - val_loss: 450.9444\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 454.9187 - val_loss: 448.2674\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 451.9935 - val_loss: 444.8060\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 449.0493 - val_loss: 441.5358\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 446.1596 - val_loss: 438.6736\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 443.1418 - val_loss: 436.3118\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.1409 - val_loss: 433.5735\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.4457 - val_loss: 430.4093\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.2054 - val_loss: 427.4536\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.1071 - val_loss: 424.6856\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 428.1499 - val_loss: 422.5690\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 425.1520 - val_loss: 419.6016\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.9734 - val_loss: 417.5219\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 419.0416 - val_loss: 414.4203\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.8153 - val_loss: 411.5122\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.9784 - val_loss: 409.1035\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.0376 - val_loss: 408.9007\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 406.8351 - val_loss: 406.4699\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.6900 - val_loss: 403.0396\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 400.4079 - val_loss: 400.3882\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.3658 - val_loss: 396.0667\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.4371 - val_loss: 391.8076\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 391.2046 - val_loss: 387.4402\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 387.8020 - val_loss: 383.3469\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 384.7461 - val_loss: 379.6812\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 381.5846 - val_loss: 377.8048\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.0412 - val_loss: 375.7609\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.4855 - val_loss: 371.6675\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 372.0146 - val_loss: 369.6012\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 369.2395 - val_loss: 366.1934\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.8502 - val_loss: 362.2274\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 364.1896 - val_loss: 359.4856\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 359.4608 - val_loss: 354.9413\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 357.3890 - val_loss: 351.3378\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 353.0310 - val_loss: 347.8821\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 349.0716 - val_loss: 344.7252\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 348.8790 - val_loss: 340.5731\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 343.4081 - val_loss: 337.7638\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.9662 - val_loss: 334.6481\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 335.9042 - val_loss: 331.3321\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 337.0383 - val_loss: 327.3499\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 332.9614 - val_loss: 325.2647\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 327.6728 - val_loss: 323.2931\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.9165 - val_loss: 319.1714\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.7239 - val_loss: 316.8333\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.0022 - val_loss: 313.1028\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 314.1547 - val_loss: 309.4632\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.9009 - val_loss: 305.0688\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 308.3060 - val_loss: 300.2554\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 305.1285 - val_loss: 296.4803\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 300.5273 - val_loss: 293.6552\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.1473 - val_loss: 291.0717\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 300.5992 - val_loss: 287.1062\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 291.3907 - val_loss: 283.8682\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 287.9404 - val_loss: 280.4313\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 284.9740 - val_loss: 277.7487\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 282.3678 - val_loss: 274.3881\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.6669 - val_loss: 271.9085\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.1417 - val_loss: 267.9367\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.9896 - val_loss: 263.8788\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 268.6600 - val_loss: 259.6867\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.7987 - val_loss: 255.2653\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 263.1517 - val_loss: 251.2033\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 264.9496 - val_loss: 248.2916\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.3428 - val_loss: 245.7423\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.7149 - val_loss: 243.3962\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 251.1997 - val_loss: 239.7262\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.3639 - val_loss: 237.9004\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 242.4966 - val_loss: 235.2945\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 242.4978 - val_loss: 230.9785\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.4532 - val_loss: 227.7484\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.5288 - val_loss: 224.5515\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 230.1760 - val_loss: 220.7045\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.8481 - val_loss: 217.3663\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 230.8058 - val_loss: 214.8356\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 234.0144 - val_loss: 211.6066\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.1941 - val_loss: 210.0310\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.0147 - val_loss: 208.2515\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.8430 - val_loss: 206.4551\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.9084 - val_loss: 207.2276\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.7586 - val_loss: 205.2465\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.5961 - val_loss: 200.2068\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 227.9845 - val_loss: 196.8362\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205.0533 - val_loss: 192.6719\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 204.4744 - val_loss: 190.5758\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.8483 - val_loss: 188.1093\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.8162 - val_loss: 184.6318\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.1771 - val_loss: 181.4294\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.3001 - val_loss: 179.2901\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.1420 - val_loss: 176.6917\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.0461 - val_loss: 176.2787\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.5867 - val_loss: 173.3928\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 180.7394 - val_loss: 173.1685\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.2239 - val_loss: 169.4444\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 171.2521 - val_loss: 164.8952\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169.5159 - val_loss: 159.4265\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 163.9629 - val_loss: 156.0916\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.7330 - val_loss: 152.6358\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.3940 - val_loss: 151.4902\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 161.7505 - val_loss: 149.8646\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 129.1976\n",
      "--- Starting trial: run-31\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6515 - val_loss: 659.9406\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.3951 - val_loss: 659.6818\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.1328 - val_loss: 659.4155\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8596 - val_loss: 659.1212\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5710 - val_loss: 658.8023\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2613 - val_loss: 658.4761\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9249 - val_loss: 658.1147\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5551 - val_loss: 657.7041\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1447 - val_loss: 657.2532\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6852 - val_loss: 656.7479\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1668 - val_loss: 656.1525\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.5786 - val_loss: 655.4869\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.9075 - val_loss: 654.7247\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.1386 - val_loss: 653.8529\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.2544 - val_loss: 652.8469\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.2344 - val_loss: 651.7072\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.0547 - val_loss: 650.3654\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.6876 - val_loss: 648.8063\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.1001 - val_loss: 647.0060\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.2541 - val_loss: 644.9143\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.1046 - val_loss: 642.4943\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.5990 - val_loss: 639.6583\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.6760 - val_loss: 636.3704\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.2631 - val_loss: 632.5281\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.2756 - val_loss: 628.0391\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.6144 - val_loss: 622.8435\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 651.1633 - val_loss: 616.7465\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 644.7855 - val_loss: 609.5836\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.3213 - val_loss: 601.2720\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.5830 - val_loss: 591.5815\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.3508 - val_loss: 580.1039\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.3667 - val_loss: 566.6839\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.3284 - val_loss: 551.1107\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.0210 - val_loss: 534.3781\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 557.1175 - val_loss: 515.7668\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.4658 - val_loss: 494.9305\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.9675 - val_loss: 470.1367\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.4829 - val_loss: 441.4514\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.7722 - val_loss: 413.6285\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.1663 - val_loss: 382.9988\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.0351 - val_loss: 360.3047\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 357.0134 - val_loss: 331.5891\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.7728 - val_loss: 312.8985\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.1658 - val_loss: 280.2644\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.1054 - val_loss: 263.5100\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 261.0421 - val_loss: 241.5108\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 227.8771 - val_loss: 229.6392\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.2111 - val_loss: 202.3105\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.1907 - val_loss: 189.2673\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 139.7570 - val_loss: 198.7711\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 123.1760 - val_loss: 346.3501\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7853 - val_loss: 417.5472\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9523 - val_loss: 482.2732\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8903 - val_loss: 408.3275\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8694 - val_loss: 273.4120\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.7611 - val_loss: 119.0103\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.2289 - val_loss: 430.0128\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.0449 - val_loss: 317.9430\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.2145 - val_loss: 283.7409\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8739 - val_loss: 276.1736\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6969 - val_loss: 263.3635\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.0383 - val_loss: 243.9409\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.7036 - val_loss: 210.6154\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.7566 - val_loss: 190.5150\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.1491 - val_loss: 161.7001\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.1514 - val_loss: 216.0777\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9775 - val_loss: 187.1989\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9824 - val_loss: 175.2857\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.2723 - val_loss: 170.5346\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2491 - val_loss: 96.9984\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.9756 - val_loss: 202.8218\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0990 - val_loss: 130.9895\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7232 - val_loss: 181.3488\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.2072 - val_loss: 181.5927\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0756 - val_loss: 147.8271\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7585 - val_loss: 136.2333\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7178 - val_loss: 108.1622\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.5689 - val_loss: 73.4760\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2006 - val_loss: 123.0601\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.3262 - val_loss: 118.2445\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.0540 - val_loss: 107.3106\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.5363 - val_loss: 121.8343\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.2489 - val_loss: 87.2371\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.6441 - val_loss: 71.1339\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4920 - val_loss: 85.0200\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.9025 - val_loss: 102.9831\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3211 - val_loss: 104.2230\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.6488 - val_loss: 99.0415\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1646 - val_loss: 94.3220\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.5823 - val_loss: 93.4666\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3382 - val_loss: 80.4790\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1105 - val_loss: 70.2673\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9313 - val_loss: 99.9902\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8290 - val_loss: 82.6912\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2267 - val_loss: 85.3246\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.5125 - val_loss: 74.8631\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 131.3686 - val_loss: 63.8138\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0715 - val_loss: 73.3584\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.6308 - val_loss: 91.5069\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7786 - val_loss: 105.9406\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.8188 - val_loss: 88.2616\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.8398 - val_loss: 76.3524\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2431 - val_loss: 67.7562\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5355 - val_loss: 72.7304\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8038 - val_loss: 81.0206\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9635 - val_loss: 103.6879\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5462 - val_loss: 90.4291\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5534 - val_loss: 75.3928\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1190 - val_loss: 83.1487\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3245 - val_loss: 89.4726\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.7401 - val_loss: 67.2166\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.7854 - val_loss: 69.7178\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.3945 - val_loss: 67.7697\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 120.2973 - val_loss: 71.2041\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.3534 - val_loss: 67.9556\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.0719 - val_loss: 74.0135\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.4068 - val_loss: 75.3835\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2886 - val_loss: 78.8715\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1693 - val_loss: 78.2980\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.0542 - val_loss: 67.4994\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8836 - val_loss: 66.4746\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9852 - val_loss: 75.5371\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117.7132 - val_loss: 65.6438\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5971 - val_loss: 68.7176\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.8910 - val_loss: 65.9897\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2271 - val_loss: 66.7938\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5562 - val_loss: 68.8837\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.5328 - val_loss: 65.0754\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.4555 - val_loss: 80.1394\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.6610 - val_loss: 67.2192\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.1956 - val_loss: 63.6789\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.3873 - val_loss: 65.0300\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.7515 - val_loss: 71.3282\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.7293 - val_loss: 63.3367\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4909 - val_loss: 70.1268\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5146 - val_loss: 65.2188\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1549 - val_loss: 67.4389\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0928 - val_loss: 65.8960\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.9332 - val_loss: 67.4388\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.8271 - val_loss: 74.8431\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5742 - val_loss: 65.2695\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.1978 - val_loss: 68.4406\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.3949 - val_loss: 69.0941\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.0305 - val_loss: 66.2071\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.0183 - val_loss: 75.3552\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.3745 - val_loss: 68.5757\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.7975 - val_loss: 67.4475\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.9231 - val_loss: 67.4887\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1216 - val_loss: 65.8683\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.6277 - val_loss: 69.3017\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.5971 - val_loss: 69.3234\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.1561 - val_loss: 63.7629\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3746 - val_loss: 70.1738\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9524 - val_loss: 70.8026\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.4073 - val_loss: 68.5986\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 64.1936 - val_loss: 65.9129\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.6170 - val_loss: 76.4620\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.4618 - val_loss: 84.0523\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.2705 - val_loss: 68.5833\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7604 - val_loss: 73.3908\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3407 - val_loss: 69.1337\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0365 - val_loss: 74.1817\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8743 - val_loss: 81.7292\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6386 - val_loss: 81.2949\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8380 - val_loss: 73.6071\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.3655 - val_loss: 65.1907\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7997 - val_loss: 70.0072\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5476 - val_loss: 72.8729\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 89.2470 - val_loss: 92.7605\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.7145 - val_loss: 81.7521\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 89.2715 - val_loss: 74.0254\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.6350 - val_loss: 69.4748\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.6939 - val_loss: 72.9964\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 115.3602 - val_loss: 70.2879\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.6749 - val_loss: 84.3010\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6013 - val_loss: 68.1253\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.2077 - val_loss: 65.1357\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9884 - val_loss: 63.6552\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.3864 - val_loss: 68.4748\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 97.5271 - val_loss: 66.2501\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.5194 - val_loss: 65.6249\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4625 - val_loss: 68.3183\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.5081 - val_loss: 68.6054\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 68.5388 - val_loss: 61.8914\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.8304 - val_loss: 66.3635\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.3018 - val_loss: 64.7627\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8111 - val_loss: 66.0791\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.1926 - val_loss: 64.3729\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.1019 - val_loss: 66.2661\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.6941 - val_loss: 69.0566\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0126 - val_loss: 68.6940\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.6038 - val_loss: 64.2623\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1905 - val_loss: 67.0089\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5848 - val_loss: 68.3633\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.8472 - val_loss: 67.6977\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6211 - val_loss: 66.8769\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7366 - val_loss: 68.8818\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5269 - val_loss: 71.1240\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.6618 - val_loss: 79.0141\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2231 - val_loss: 66.0590\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7831 - val_loss: 71.0506\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.7885 - val_loss: 70.1303\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.5768 - val_loss: 66.9940\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0122 - val_loss: 79.1308\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.5330 - val_loss: 64.3361\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.0212 - val_loss: 67.7222\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58.2115 - val_loss: 76.7448\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.2332 - val_loss: 67.4283\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3347 - val_loss: 70.2719\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4963 - val_loss: 84.5420\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9161 - val_loss: 83.9316\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.8596 - val_loss: 68.2391\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0432 - val_loss: 67.6551\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 77.4307 - val_loss: 68.1426\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9367 - val_loss: 70.0210\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.2103 - val_loss: 69.5328\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8299 - val_loss: 67.3139\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0908 - val_loss: 65.9626\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1020 - val_loss: 70.2023\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7981 - val_loss: 64.1221\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 82.7558 - val_loss: 72.0802\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3377 - val_loss: 66.7574\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6361 - val_loss: 72.9552\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2569 - val_loss: 69.1660\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.3045 - val_loss: 71.1068\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.1313 - val_loss: 71.2294\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6851 - val_loss: 72.3328\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1745 - val_loss: 69.7173\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.9111 - val_loss: 68.4304\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2128 - val_loss: 64.3749\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7200 - val_loss: 64.1248\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8907 - val_loss: 64.9880\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9648 - val_loss: 68.9794\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.8655 - val_loss: 67.1032\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0450 - val_loss: 63.6730\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2296 - val_loss: 74.0932\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.1589 - val_loss: 67.3315\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5840 - val_loss: 68.1896\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.5725 - val_loss: 70.8468\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4489 - val_loss: 63.7888\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5270 - val_loss: 64.9759\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.7974 - val_loss: 64.9579\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.3625 - val_loss: 63.7071\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7475 - val_loss: 63.3873\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5307 - val_loss: 68.4896\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1333 - val_loss: 72.0118\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2957 - val_loss: 66.4057\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.5753 - val_loss: 67.4611\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.3616 - val_loss: 63.1037\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.6246 - val_loss: 64.0847\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46.1880\n",
      "--- Starting trial: run-32\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.7168 - val_loss: 660.2189\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6215 - val_loss: 660.1077\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.5165 - val_loss: 659.9768\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.3993 - val_loss: 659.8314\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.2686 - val_loss: 659.6870\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1229 - val_loss: 659.5295\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9609 - val_loss: 659.3486\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.7819 - val_loss: 659.1609\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.5848 - val_loss: 658.9485\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3693 - val_loss: 658.7183\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1348 - val_loss: 658.4648\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.8808 - val_loss: 658.2018\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 687.6071 - val_loss: 657.9161\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3134 - val_loss: 657.6239\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9992 - val_loss: 657.3055\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.6645 - val_loss: 656.9604\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.3090 - val_loss: 656.6049\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9327 - val_loss: 656.2399\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.5353 - val_loss: 655.8555\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1167 - val_loss: 655.4301\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.6769 - val_loss: 654.9993\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 684.2159 - val_loss: 654.5414\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.7334 - val_loss: 654.0717\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.2295 - val_loss: 653.5446\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.7042 - val_loss: 653.0056\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.1574 - val_loss: 652.4722\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.5889 - val_loss: 651.8955\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.9990 - val_loss: 651.2944\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.3876 - val_loss: 650.6806\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.7545 - val_loss: 650.0307\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.1000 - val_loss: 649.3992\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.4240 - val_loss: 648.7409\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.7264 - val_loss: 648.0341\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.0073 - val_loss: 647.3079\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.2668 - val_loss: 646.5523\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.5050 - val_loss: 645.7794\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 674.7216 - val_loss: 644.9802\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 673.9168 - val_loss: 644.1920\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.0908 - val_loss: 643.3767\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.2435 - val_loss: 642.4932\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.3748 - val_loss: 641.5539\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 670.4849 - val_loss: 640.6117\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.5738 - val_loss: 639.7281\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.6417 - val_loss: 638.8292\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.6884 - val_loss: 637.8990\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.7140 - val_loss: 636.9572\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.7187 - val_loss: 635.9521\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.7024 - val_loss: 634.9208\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.6652 - val_loss: 633.8729\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 662.6072 - val_loss: 632.8049\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.5283 - val_loss: 631.6675\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.4288 - val_loss: 630.4893\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.3085 - val_loss: 629.3439\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 658.1676 - val_loss: 628.1761\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 657.0062 - val_loss: 627.0256\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.8240 - val_loss: 625.8865\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.6215 - val_loss: 624.6755\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.3986 - val_loss: 623.4076\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.1553 - val_loss: 622.2131\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.8915 - val_loss: 621.0282\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.6077 - val_loss: 619.7328\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 648.3035 - val_loss: 618.4327\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.9793 - val_loss: 617.0437\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.6349 - val_loss: 615.6631\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 644.2705 - val_loss: 614.2172\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.8862 - val_loss: 612.8412\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 641.4818 - val_loss: 611.4644\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.0576 - val_loss: 610.0984\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.6136 - val_loss: 608.6382\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.1498 - val_loss: 607.2164\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.6662 - val_loss: 605.6928\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.1631 - val_loss: 604.2988\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.6403 - val_loss: 602.7967\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.0980 - val_loss: 601.1655\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.5363 - val_loss: 599.5493\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 627.9550 - val_loss: 597.8684\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.3544 - val_loss: 596.4837\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.7344 - val_loss: 595.0544\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 623.0953 - val_loss: 593.5477\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 621.4368 - val_loss: 591.8002\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.7593 - val_loss: 590.0630\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.0626 - val_loss: 588.3330\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.3469 - val_loss: 586.6252\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 614.6121 - val_loss: 584.9671\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.8585 - val_loss: 583.2773\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.0858 - val_loss: 581.4786\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.2945 - val_loss: 579.5165\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.4843 - val_loss: 577.4938\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 605.6553 - val_loss: 575.6670\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 603.8077 - val_loss: 574.0038\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 601.9415 - val_loss: 572.3183\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 600.0567 - val_loss: 570.5739\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.1534 - val_loss: 568.8344\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.2314 - val_loss: 567.2589\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.2912 - val_loss: 565.4856\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.3326 - val_loss: 563.3537\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 590.3557 - val_loss: 561.3339\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 588.3605 - val_loss: 559.4288\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.3471 - val_loss: 557.8139\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.3155 - val_loss: 555.8838\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 582.2659 - val_loss: 554.0819\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 580.1981 - val_loss: 551.9579\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 578.1123 - val_loss: 549.8860\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.0086 - val_loss: 547.7415\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.8870 - val_loss: 545.5873\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.7910 - val_loss: 543.9778\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.6082 - val_loss: 544.4000\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.4527 - val_loss: 542.6561\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.2679 - val_loss: 540.5444\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 563.0605 - val_loss: 538.1635\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.8334 - val_loss: 535.8051\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.6348 - val_loss: 532.2506\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.3319 - val_loss: 528.5130\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 554.1094 - val_loss: 524.6489\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.7771 - val_loss: 517.8129\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.4816 - val_loss: 514.5700\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.1669 - val_loss: 512.7941\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.1432 - val_loss: 510.8060\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.4629 - val_loss: 507.5932\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 540.0905 - val_loss: 504.8052\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 537.8173 - val_loss: 503.1647\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.2897 - val_loss: 501.4843\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 532.8590 - val_loss: 499.7984\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.4197 - val_loss: 496.9605\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 527.9951 - val_loss: 494.5479\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 525.4913 - val_loss: 492.2756\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 523.0129 - val_loss: 490.1415\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.5012 - val_loss: 488.1863\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 517.9656 - val_loss: 486.1269\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.4289 - val_loss: 484.5483\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.8448 - val_loss: 483.1270\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 510.3107 - val_loss: 481.7695\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.7796 - val_loss: 480.0440\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.0681 - val_loss: 477.9989\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.4351 - val_loss: 475.5073\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.7808 - val_loss: 473.2558\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 497.2721 - val_loss: 470.7246\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.4801 - val_loss: 467.4595\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 491.7431 - val_loss: 464.1269\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.0326 - val_loss: 461.4952\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.3032 - val_loss: 460.1640\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.5548 - val_loss: 458.1159\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.9253 - val_loss: 456.4860\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 478.0081 - val_loss: 455.2408\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.3758 - val_loss: 453.1899\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.4179 - val_loss: 450.8930\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.8163 - val_loss: 449.3832\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.8134 - val_loss: 447.8070\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.9620 - val_loss: 446.5817\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.0727 - val_loss: 443.4703\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.1772 - val_loss: 439.8861\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 455.9589 - val_loss: 436.8593\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 452.3871 - val_loss: 433.4026\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.6765 - val_loss: 431.4797\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 446.6170 - val_loss: 430.2922\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.7652 - val_loss: 429.3255\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.7769 - val_loss: 427.6108\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.6448 - val_loss: 425.0718\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.8874 - val_loss: 420.8231\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.7181 - val_loss: 421.9178\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 428.7883 - val_loss: 418.6502\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.6008 - val_loss: 416.9423\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 422.6377 - val_loss: 415.9090\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 422.1729 - val_loss: 412.7253\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.2664 - val_loss: 409.0056\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 414.4371 - val_loss: 410.8698\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 410.6927 - val_loss: 407.5892\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.8282 - val_loss: 405.3597\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.7197 - val_loss: 401.7333\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.5433 - val_loss: 394.1162\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.3853 - val_loss: 387.6211\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.5955 - val_loss: 384.2662\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 392.8671 - val_loss: 382.3149\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.4367 - val_loss: 382.0192\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 386.3968 - val_loss: 380.6903\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.4032 - val_loss: 378.1375\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.7038 - val_loss: 378.3200\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.0335 - val_loss: 377.0653\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.9497 - val_loss: 374.6214\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 372.4879 - val_loss: 372.2397\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368.3843 - val_loss: 369.5730\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 366.0400 - val_loss: 367.9469\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.8538 - val_loss: 367.7773\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 359.5478 - val_loss: 365.7081\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.1371 - val_loss: 361.5563\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 352.4778 - val_loss: 357.8088\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.8021 - val_loss: 354.1895\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347.5411 - val_loss: 347.6838\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 344.3717 - val_loss: 341.0973\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 341.8143 - val_loss: 333.5535\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.4161 - val_loss: 325.5852\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.5806 - val_loss: 323.2433\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 332.5280 - val_loss: 322.9321\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 328.1989 - val_loss: 321.8305\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.3748 - val_loss: 318.8016\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.3029 - val_loss: 314.8596\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.3249 - val_loss: 314.7442\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.6501 - val_loss: 312.4769\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 316.3490 - val_loss: 311.7115\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.4542 - val_loss: 311.5066\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.0777 - val_loss: 309.0852\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 312.1274 - val_loss: 303.8303\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.4751 - val_loss: 300.3099\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.3207 - val_loss: 297.3370\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 300.4250 - val_loss: 294.6357\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 293.9983 - val_loss: 291.7824\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 292.0218 - val_loss: 291.2878\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 290.3525 - val_loss: 290.6841\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.9937 - val_loss: 288.6407\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 284.7423 - val_loss: 285.3319\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.6749 - val_loss: 281.7313\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 274.9784 - val_loss: 279.4033\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.7442 - val_loss: 275.8503\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 273.3410 - val_loss: 272.5633\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.7256 - val_loss: 268.8950\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.3813 - val_loss: 265.1083\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 259.4131 - val_loss: 260.7679\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.0815 - val_loss: 256.3842\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.8106 - val_loss: 252.3737\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.7025 - val_loss: 248.9281\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 253.2745 - val_loss: 245.4892\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 246.4042 - val_loss: 240.7140\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 241.9022 - val_loss: 236.9207\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 239.4501 - val_loss: 236.0031\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 235.1687 - val_loss: 233.9431\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.4206 - val_loss: 232.0172\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 231.2157 - val_loss: 230.8232\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 227.8566 - val_loss: 227.3725\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.1555 - val_loss: 224.9187\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 223.5483 - val_loss: 219.8180\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 221.4903 - val_loss: 216.1203\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 215.0496 - val_loss: 213.0756\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 227.5097 - val_loss: 211.5406\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 221.2145 - val_loss: 210.0137\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.7648 - val_loss: 209.8645\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.2907 - val_loss: 210.4209\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 216.3892 - val_loss: 205.1113\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 214.4885 - val_loss: 200.9453\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.6122 - val_loss: 197.5138\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.6750 - val_loss: 198.4293\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.1096 - val_loss: 197.2857\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.0914 - val_loss: 195.0304\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.8212 - val_loss: 190.5658\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 189.1824 - val_loss: 187.8315\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.4521 - val_loss: 184.4276\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.7389 - val_loss: 180.9020\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 171.7319 - val_loss: 176.8620\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 183.8017 - val_loss: 173.4285\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 168.5969 - val_loss: 172.1992\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 162.8922 - val_loss: 169.9532\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 155.2805\n",
      "--- Starting trial: run-33\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6574 - val_loss: 660.2097\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4160 - val_loss: 659.9675\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1691 - val_loss: 659.7141\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9124 - val_loss: 659.4584\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6414 - val_loss: 659.1834\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3513 - val_loss: 658.8841\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0366 - val_loss: 658.5621\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 687.6915 - val_loss: 658.2089\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.3091 - val_loss: 657.8195\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.8818 - val_loss: 657.3678\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4007 - val_loss: 656.8640\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.8557 - val_loss: 656.2883\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.2349 - val_loss: 655.6315\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.5245 - val_loss: 654.9005\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.7086 - val_loss: 654.0527\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.7685 - val_loss: 653.0555\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.6823 - val_loss: 651.9097\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.4243 - val_loss: 650.5696\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.9650 - val_loss: 649.0154\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.2690 - val_loss: 647.2167\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.2953 - val_loss: 645.1028\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.9957 - val_loss: 642.6403\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.3141 - val_loss: 639.7658\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.1843 - val_loss: 636.4312\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.5289 - val_loss: 632.4894\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659.2569 - val_loss: 627.8649\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.2619 - val_loss: 622.4913\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.4191 - val_loss: 616.1894\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.5822 - val_loss: 608.8849\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.5793 - val_loss: 600.2071\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.2095 - val_loss: 590.0946\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 613.2366 - val_loss: 578.3187\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.3841 - val_loss: 564.3710\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 585.3273 - val_loss: 547.9296\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.6862 - val_loss: 529.2753\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.1371 - val_loss: 509.1511\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.8240 - val_loss: 483.3884\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.2631 - val_loss: 458.3536\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.4718 - val_loss: 425.2849\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.9933 - val_loss: 397.8544\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 409.6639 - val_loss: 368.0201\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.2074 - val_loss: 345.4671\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 362.1078 - val_loss: 335.8763\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 340.5123 - val_loss: 298.9405\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 316.7699 - val_loss: 277.1899\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.5905 - val_loss: 277.3022\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 270.3400 - val_loss: 254.6808\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 253.0971 - val_loss: 211.6488\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.2984 - val_loss: 194.3837\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.0885 - val_loss: 131.6145\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 166.5217 - val_loss: 128.2052\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 164.8001 - val_loss: 163.0838\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 162.5587 - val_loss: 161.8697\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4974 - val_loss: 214.8641\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.2869 - val_loss: 185.0230\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1943 - val_loss: 199.0384\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.8335 - val_loss: 201.1740\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.7261 - val_loss: 232.2899\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.2357 - val_loss: 235.9207\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.3082 - val_loss: 197.8842\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4991 - val_loss: 189.7849\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8450 - val_loss: 153.8661\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4324 - val_loss: 176.4065\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.2891 - val_loss: 172.0696\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2275 - val_loss: 179.5933\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6802 - val_loss: 162.6628\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.4917 - val_loss: 131.2775\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2426 - val_loss: 124.6065\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6299 - val_loss: 150.7800\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.0720 - val_loss: 94.9467\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2462 - val_loss: 110.7906\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.5759 - val_loss: 128.4383\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2433 - val_loss: 91.5651\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1750 - val_loss: 125.0010\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9744 - val_loss: 105.9179\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9102 - val_loss: 91.4902\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8004 - val_loss: 89.7866\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1817 - val_loss: 90.2843\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5756 - val_loss: 82.5790\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9077 - val_loss: 102.5718\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 88.7233 - val_loss: 100.6181\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7940 - val_loss: 121.5030\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5812 - val_loss: 118.1549\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6194 - val_loss: 92.8045\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8020 - val_loss: 88.4136\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2446 - val_loss: 84.5477\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6398 - val_loss: 77.7827\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.8028 - val_loss: 70.5557\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8693 - val_loss: 73.0347\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1990 - val_loss: 68.2085\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0237 - val_loss: 71.0991\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.2846 - val_loss: 70.9241\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7203 - val_loss: 63.3683\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4540 - val_loss: 67.3578\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3812 - val_loss: 67.1745\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2154 - val_loss: 65.5176\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.5586 - val_loss: 72.2181\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3932 - val_loss: 63.5713\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.9771 - val_loss: 74.7298\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.8495 - val_loss: 73.5826\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4528 - val_loss: 68.1891\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.6645 - val_loss: 74.6198\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5938 - val_loss: 66.1569\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0181 - val_loss: 64.9080\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.6327 - val_loss: 64.1538\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 143.5568 - val_loss: 61.2619\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6613 - val_loss: 66.4507\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2004 - val_loss: 72.3811\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3103 - val_loss: 65.9276\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9224 - val_loss: 64.5209\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4388 - val_loss: 64.2592\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.9761 - val_loss: 69.7111\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.2078 - val_loss: 68.7454\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1384 - val_loss: 65.8580\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5014 - val_loss: 68.6736\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.2553 - val_loss: 64.4553\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4801 - val_loss: 62.0979\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9026 - val_loss: 73.8094\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1129 - val_loss: 66.3412\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6778 - val_loss: 69.9312\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7512 - val_loss: 65.4403\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.7436 - val_loss: 68.9323\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5888 - val_loss: 69.9613\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8063 - val_loss: 80.9220\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.9145 - val_loss: 69.7120\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8871 - val_loss: 70.8172\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9305 - val_loss: 63.5854\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2916 - val_loss: 60.8282\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9114 - val_loss: 66.2768\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.4688 - val_loss: 74.8457\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1435 - val_loss: 70.9144\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4623 - val_loss: 64.4913\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8064 - val_loss: 62.6357\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4599 - val_loss: 67.2674\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3887 - val_loss: 68.8705\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5961 - val_loss: 66.0414\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.9220 - val_loss: 63.0189\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6263 - val_loss: 66.8676\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 119.3512 - val_loss: 66.3852\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9928 - val_loss: 67.1573\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8736 - val_loss: 65.7042\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6545 - val_loss: 65.2006\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3873 - val_loss: 63.7382\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8989 - val_loss: 69.5295\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5973 - val_loss: 69.4225\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4973 - val_loss: 65.0633\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7176 - val_loss: 63.6884\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.2647 - val_loss: 64.3028\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.5290 - val_loss: 67.2613\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4293 - val_loss: 62.7908\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6132 - val_loss: 62.3294\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8195 - val_loss: 66.7924\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.9250 - val_loss: 63.5606\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.7530 - val_loss: 63.7059\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2958 - val_loss: 62.9397\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.6370 - val_loss: 61.9450\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.4935 - val_loss: 64.5407\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8070 - val_loss: 70.3372\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0451 - val_loss: 61.6975\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2648 - val_loss: 62.1871\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9114 - val_loss: 63.2339\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1668 - val_loss: 63.2427\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6874 - val_loss: 60.7491\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7169 - val_loss: 65.3434\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.8000 - val_loss: 67.8522\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0841 - val_loss: 72.9275\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9194 - val_loss: 65.8487\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6556 - val_loss: 66.5257\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5845 - val_loss: 65.9677\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4880 - val_loss: 62.7940\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 72.3910 - val_loss: 63.2139\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.6289 - val_loss: 61.1482\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3130 - val_loss: 63.6325\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6496 - val_loss: 67.7002\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0559 - val_loss: 61.9578\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4183 - val_loss: 67.0047\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5754 - val_loss: 65.9488\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3039 - val_loss: 66.2239\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4887 - val_loss: 67.3194\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7522 - val_loss: 72.0915\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.8455 - val_loss: 78.4987\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9717 - val_loss: 77.1520\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.3838 - val_loss: 70.7437\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9735 - val_loss: 67.4905\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7226 - val_loss: 65.1125\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4878 - val_loss: 63.5428\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.1531 - val_loss: 64.3593\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.3553 - val_loss: 65.7579\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6906 - val_loss: 66.3667\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5543 - val_loss: 70.4193\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7417 - val_loss: 75.0870\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7520 - val_loss: 62.1552\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5374 - val_loss: 61.8378\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8726 - val_loss: 70.9074\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4232 - val_loss: 70.3028\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9460 - val_loss: 60.1719\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7077 - val_loss: 60.5755\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6561 - val_loss: 61.0146\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3037 - val_loss: 62.2892\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5318 - val_loss: 66.9720\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4325 - val_loss: 64.3512\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9479 - val_loss: 69.4077\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.1653 - val_loss: 67.0810\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9347 - val_loss: 65.9685\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8947 - val_loss: 64.2781\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1979 - val_loss: 70.4052\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.8229 - val_loss: 62.9408\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1504 - val_loss: 63.1054\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2070 - val_loss: 62.6937\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3031 - val_loss: 62.8894\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.2780 - val_loss: 60.8845\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.8262 - val_loss: 61.2361\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.8460 - val_loss: 64.6765\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.7208 - val_loss: 73.3640\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.7862 - val_loss: 69.2475\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1877 - val_loss: 62.4896\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6908 - val_loss: 81.8242\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0984 - val_loss: 73.5939\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4033 - val_loss: 74.9637\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7700 - val_loss: 76.7486\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8286 - val_loss: 65.3373\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4748 - val_loss: 67.5985\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.5516 - val_loss: 73.8643\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.3380 - val_loss: 82.3871\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9137 - val_loss: 73.3565\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3593 - val_loss: 72.7720\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3199 - val_loss: 66.9000\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2484 - val_loss: 60.5592\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9485 - val_loss: 65.5442\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7897 - val_loss: 66.0949\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1780 - val_loss: 64.6750\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5361 - val_loss: 58.7814\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.2951 - val_loss: 60.0863\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.6154 - val_loss: 60.3749\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8281 - val_loss: 60.4723\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.7878 - val_loss: 63.0660\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1182 - val_loss: 64.6923\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0279 - val_loss: 67.1484\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4753 - val_loss: 62.2191\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.8595 - val_loss: 64.1247\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.6101 - val_loss: 68.1063\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0110 - val_loss: 62.4660\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8950 - val_loss: 65.4714\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9052 - val_loss: 69.0713\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3921 - val_loss: 61.3839\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7679 - val_loss: 67.8459\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3669 - val_loss: 61.7661\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4358 - val_loss: 61.8279\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2483 - val_loss: 62.9796\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8140 - val_loss: 68.7325\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 31.9053\n",
      "--- Starting trial: run-34\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 64, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7192 - val_loss: 660.7307\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.6299 - val_loss: 660.5945\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5308 - val_loss: 660.4415\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4196 - val_loss: 660.2805\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2947 - val_loss: 660.1107\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1548 - val_loss: 659.9178\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.9984 - val_loss: 659.7103\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8246 - val_loss: 659.4869\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6328 - val_loss: 659.2459\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4222 - val_loss: 658.9948\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1924 - val_loss: 658.7157\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9431 - val_loss: 658.4216\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6735 - val_loss: 658.1189\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3838 - val_loss: 657.7928\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0737 - val_loss: 657.4364\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7426 - val_loss: 657.0790\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 686.3906 - val_loss: 656.6810\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.0176 - val_loss: 656.2830\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6233 - val_loss: 655.8658\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.2076 - val_loss: 655.4279\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.7707 - val_loss: 654.9543\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3124 - val_loss: 654.4691\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.8324 - val_loss: 653.9575\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 683.3309 - val_loss: 653.4359\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.8079 - val_loss: 652.8732\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.2631 - val_loss: 652.3000\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.6968 - val_loss: 651.7286\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.1089 - val_loss: 651.1225\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.4993 - val_loss: 650.5127\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.8680 - val_loss: 649.8461\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.2153 - val_loss: 649.1899\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.5409 - val_loss: 648.4831\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.8449 - val_loss: 647.7407\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.1273 - val_loss: 646.9812\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.3882 - val_loss: 646.1625\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.6276 - val_loss: 645.4189\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.8456 - val_loss: 644.6058\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.0421 - val_loss: 643.7849\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 673.2172 - val_loss: 642.9184\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 672.3710 - val_loss: 642.0507\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.5035 - val_loss: 641.2195\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.6146 - val_loss: 640.3137\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.7046 - val_loss: 639.3750\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.7734 - val_loss: 638.4315\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.8210 - val_loss: 637.4786\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.8476 - val_loss: 636.5103\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.8531 - val_loss: 635.5241\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.8378 - val_loss: 634.5286\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.8014 - val_loss: 633.4337\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.7442 - val_loss: 632.3118\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.6662 - val_loss: 631.2356\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.5673 - val_loss: 630.1191\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.4477 - val_loss: 628.9909\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 658.3076 - val_loss: 627.8669\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 657.1467 - val_loss: 626.6775\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.9654 - val_loss: 625.4995\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.7635 - val_loss: 624.2891\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.5412 - val_loss: 623.0650\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.2985 - val_loss: 621.8458\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.0355 - val_loss: 620.6331\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.7522 - val_loss: 619.2982\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.4486 - val_loss: 617.9800\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.1250 - val_loss: 616.6498\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.7812 - val_loss: 615.2755\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.4174 - val_loss: 613.8633\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.0334 - val_loss: 612.3764\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.6297 - val_loss: 610.9555\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.2060 - val_loss: 609.5103\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.7626 - val_loss: 608.0675\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.2992 - val_loss: 606.6818\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 635.8162 - val_loss: 605.1985\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.3136 - val_loss: 603.6837\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.7913 - val_loss: 602.1558\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.2496 - val_loss: 600.5964\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.6883 - val_loss: 598.9902\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.1075 - val_loss: 597.2991\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.5075 - val_loss: 595.7524\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.8879 - val_loss: 594.0795\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.2493 - val_loss: 592.4380\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.5914 - val_loss: 590.8500\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 619.9142 - val_loss: 589.1528\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.2180 - val_loss: 587.4131\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.5027 - val_loss: 585.5795\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.7685 - val_loss: 583.9334\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.0153 - val_loss: 582.2120\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.2432 - val_loss: 580.4233\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.4522 - val_loss: 578.5944\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 607.6425 - val_loss: 576.8130\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.8140 - val_loss: 574.9536\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.9669 - val_loss: 573.1647\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.1011 - val_loss: 571.3401\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.2168 - val_loss: 569.4686\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.3138 - val_loss: 567.5473\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 596.3926 - val_loss: 565.6625\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.4528 - val_loss: 563.7522\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.4946 - val_loss: 561.7491\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.5182 - val_loss: 559.8225\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 588.5236 - val_loss: 557.8163\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.5106 - val_loss: 555.8574\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.5463 - val_loss: 554.9453\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.4390 - val_loss: 554.1528\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.3761 - val_loss: 552.5126\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.2926 - val_loss: 550.8080\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.1899 - val_loss: 548.6830\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 574.0689 - val_loss: 546.5819\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 571.9297 - val_loss: 544.4974\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.7727 - val_loss: 542.2798\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 567.5980 - val_loss: 539.8315\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.4054 - val_loss: 537.7937\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.1952 - val_loss: 535.4932\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.9673 - val_loss: 533.2917\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.7218 - val_loss: 531.1393\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.4589 - val_loss: 528.9308\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.2084 - val_loss: 528.0383\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.8914 - val_loss: 526.3830\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.5798 - val_loss: 524.3623\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.2488 - val_loss: 522.0493\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.8994 - val_loss: 519.7056\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.5322 - val_loss: 517.4590\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.1479 - val_loss: 515.1826\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 537.7462 - val_loss: 512.7509\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.3273 - val_loss: 510.3180\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 532.9560 - val_loss: 508.5203\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.4453 - val_loss: 507.4216\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.9810 - val_loss: 505.4081\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.4963 - val_loss: 503.1804\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 523.0893 - val_loss: 501.5032\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.4801 - val_loss: 499.8417\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 517.9484 - val_loss: 497.5973\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 515.4946 - val_loss: 495.9145\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.8447 - val_loss: 495.5506\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 510.2635 - val_loss: 493.6805\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 507.6658 - val_loss: 491.4007\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.0473 - val_loss: 488.5926\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 502.4106 - val_loss: 485.7465\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.7565 - val_loss: 483.2258\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.0857 - val_loss: 480.5585\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.3983 - val_loss: 477.4799\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 491.6945 - val_loss: 474.8243\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 489.1567 - val_loss: 473.3405\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.3061 - val_loss: 471.2874\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.5302 - val_loss: 469.4607\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.7763 - val_loss: 466.8210\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.9971 - val_loss: 464.1527\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.1980 - val_loss: 461.1113\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.3811 - val_loss: 457.9398\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.6688 - val_loss: 454.2288\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 466.7088 - val_loss: 450.7103\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 463.8461 - val_loss: 447.5141\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.0717 - val_loss: 444.6451\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.0853 - val_loss: 441.7250\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 455.1828 - val_loss: 439.2335\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.2734 - val_loss: 435.6894\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.3228 - val_loss: 431.8755\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 446.4889 - val_loss: 429.9668\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.4922 - val_loss: 427.7550\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 440.5474 - val_loss: 425.3299\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.5912 - val_loss: 421.7728\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.8786 - val_loss: 418.9323\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 431.7703 - val_loss: 416.0914\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 429.1757 - val_loss: 413.0847\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.7820 - val_loss: 411.6671\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 422.4929 - val_loss: 408.7381\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 419.7399 - val_loss: 405.2792\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.4532 - val_loss: 402.0046\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 414.6856 - val_loss: 398.3757\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.5863 - val_loss: 395.4395\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.5042 - val_loss: 392.8110\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.9824 - val_loss: 390.1794\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 401.5211 - val_loss: 387.6604\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.5830 - val_loss: 385.9445\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 395.8076 - val_loss: 383.8460\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 393.4768 - val_loss: 381.0536\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.3044 - val_loss: 378.2267\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 386.0005 - val_loss: 374.3350\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.0184 - val_loss: 370.8073\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.5731 - val_loss: 367.6768\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.3139 - val_loss: 364.7088\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.8940 - val_loss: 361.9258\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.3935 - val_loss: 358.9380\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.3513 - val_loss: 355.4980\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 364.4653 - val_loss: 352.0004\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.6678 - val_loss: 350.3683\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 358.0579 - val_loss: 347.4778\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.8434 - val_loss: 344.3506\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 353.8911 - val_loss: 341.1151\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 348.0065 - val_loss: 338.0945\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 345.8933 - val_loss: 334.5206\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.8896 - val_loss: 332.0417\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 340.5329 - val_loss: 329.2780\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.6952 - val_loss: 326.6364\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.0910 - val_loss: 324.4302\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 329.4812 - val_loss: 321.7546\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 329.2131 - val_loss: 318.9100\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.9405 - val_loss: 315.9764\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 322.6836 - val_loss: 312.6573\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 319.0352 - val_loss: 310.2843\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 315.7293 - val_loss: 307.3130\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 314.0880 - val_loss: 304.2857\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 309.4598 - val_loss: 301.0186\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 306.2663 - val_loss: 298.4137\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 303.9764 - val_loss: 296.0351\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 300.9334 - val_loss: 292.5436\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.2864 - val_loss: 289.8349\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 298.1263 - val_loss: 287.2076\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 289.7755 - val_loss: 284.0262\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 292.8996 - val_loss: 281.5551\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 285.9036 - val_loss: 278.3783\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 283.7489 - val_loss: 275.0585\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.5808 - val_loss: 271.5838\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.9154 - val_loss: 268.3373\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.8803 - val_loss: 266.0831\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.4417 - val_loss: 263.5636\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 268.2208 - val_loss: 260.2446\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 263.8920 - val_loss: 256.9800\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 273.8740 - val_loss: 253.3067\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 264.5485 - val_loss: 250.4528\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 256.5957 - val_loss: 248.6633\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.1602 - val_loss: 246.7280\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.9947 - val_loss: 244.5675\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.0987 - val_loss: 241.1930\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241.8637 - val_loss: 237.7283\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.2096 - val_loss: 234.4337\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.1399 - val_loss: 231.1260\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 243.8172 - val_loss: 229.5096\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.3114 - val_loss: 227.6804\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.1774 - val_loss: 225.1691\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 222.7345 - val_loss: 222.2401\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.1932 - val_loss: 218.8493\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.5422 - val_loss: 215.9994\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.5970 - val_loss: 212.6860\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.0689 - val_loss: 211.1519\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 209.7921 - val_loss: 208.0555\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.4469 - val_loss: 205.7326\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 201.5057 - val_loss: 203.4096\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.0320 - val_loss: 200.8545\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.3070 - val_loss: 198.4655\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 199.3252 - val_loss: 196.7808\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 191.3943 - val_loss: 194.1262\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 194.5133 - val_loss: 192.2376\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.5141 - val_loss: 190.4112\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 185.5004 - val_loss: 188.5039\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.5894 - val_loss: 186.4361\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.5331 - val_loss: 184.2986\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 183.2697 - val_loss: 181.4721\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.2263 - val_loss: 179.7241\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.5005 - val_loss: 176.9777\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 178.0556 - val_loss: 175.2132\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.6582 - val_loss: 172.3456\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 161.9645 - val_loss: 170.3525\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 165.2094\n",
      "--- Starting trial: run-35\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 64, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6639 - val_loss: 659.8641\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4390 - val_loss: 659.6514\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.2091 - val_loss: 659.4281\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9705 - val_loss: 659.1946\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7191 - val_loss: 658.9437\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4504 - val_loss: 658.6716\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 688.1597 - val_loss: 658.3681\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.8417 - val_loss: 658.0353\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.4903 - val_loss: 657.6569\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0985 - val_loss: 657.2365\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6584 - val_loss: 656.7631\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1609 - val_loss: 656.2274\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.5954 - val_loss: 655.6133\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.9495 - val_loss: 654.9180\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.2088 - val_loss: 654.1071\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.3567 - val_loss: 653.1798\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.3734 - val_loss: 652.0941\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.2360 - val_loss: 650.8505\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.9176 - val_loss: 649.3995\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.3868 - val_loss: 647.7108\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.6068 - val_loss: 645.7458\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.5343 - val_loss: 643.4657\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.1187 - val_loss: 640.7952\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.3008 - val_loss: 637.6838\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.0110 - val_loss: 634.0637\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.1677 - val_loss: 629.8381\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.6754 - val_loss: 624.8679\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.4219 - val_loss: 619.0969\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.2759 - val_loss: 612.2952\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.0833 - val_loss: 604.3166\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 630.6635 - val_loss: 595.0377\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.8046 - val_loss: 584.1857\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.2581 - val_loss: 571.5175\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.7331 - val_loss: 556.6029\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.8878 - val_loss: 539.4055\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.5491 - val_loss: 520.4275\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 540.4269 - val_loss: 501.6737\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 518.3282 - val_loss: 480.8671\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 493.1985 - val_loss: 457.5511\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 464.9800 - val_loss: 431.8638\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.2335 - val_loss: 405.1754\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 409.9592 - val_loss: 378.0438\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 385.7539 - val_loss: 351.9007\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.2270 - val_loss: 326.1411\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.2977 - val_loss: 303.8013\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 321.5548 - val_loss: 282.5612\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.2696 - val_loss: 255.2868\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.6446 - val_loss: 226.1102\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 244.2971 - val_loss: 200.7701\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.5361 - val_loss: 173.8929\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 188.4816 - val_loss: 152.9765\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 165.0728 - val_loss: 136.2820\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 154.5817 - val_loss: 124.3820\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.3988 - val_loss: 123.2516\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.5274 - val_loss: 118.4949\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.2030 - val_loss: 108.5823\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.6368 - val_loss: 106.7970\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.6114 - val_loss: 104.3344\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.6065 - val_loss: 102.1301\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9451 - val_loss: 101.9146\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.4576 - val_loss: 93.3896\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 112.3535 - val_loss: 91.5736\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.7698 - val_loss: 94.6098\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.3078 - val_loss: 90.0990\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.8665 - val_loss: 96.8453\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.5109 - val_loss: 88.1423\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0427 - val_loss: 97.1377\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 92.9120 - val_loss: 103.0112\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4627 - val_loss: 92.1019\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2586 - val_loss: 86.1619\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1191 - val_loss: 86.8904\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.2701 - val_loss: 99.1496\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.0254 - val_loss: 74.7044\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.5714 - val_loss: 73.5073\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.3972 - val_loss: 92.4705\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0952 - val_loss: 79.3647\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0504 - val_loss: 77.3189\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9781 - val_loss: 76.7313\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.4232 - val_loss: 71.4806\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9042 - val_loss: 84.1558\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.8487 - val_loss: 70.2531\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.1250 - val_loss: 68.4119\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.5705 - val_loss: 67.4007\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.1157 - val_loss: 67.4337\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.5647 - val_loss: 75.2611\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4047 - val_loss: 77.1753\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.9112 - val_loss: 79.3813\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.7423 - val_loss: 72.5211\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4861 - val_loss: 84.2249\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0688 - val_loss: 79.7606\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1587 - val_loss: 79.6827\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1509 - val_loss: 70.6049\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7040 - val_loss: 75.4081\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3064 - val_loss: 66.5080\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.3075 - val_loss: 79.2524\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7916 - val_loss: 72.1855\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8287 - val_loss: 70.3849\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 117.3521 - val_loss: 75.2427\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.2609 - val_loss: 68.4899\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.2133 - val_loss: 70.8046\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.6351 - val_loss: 66.8517\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.6514 - val_loss: 67.8696\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3416 - val_loss: 78.4011\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4374 - val_loss: 68.6347\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1012 - val_loss: 69.6074\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8607 - val_loss: 68.5602\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9792 - val_loss: 78.6498\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9368 - val_loss: 69.3305\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3608 - val_loss: 71.6246\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4006 - val_loss: 69.4948\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2790 - val_loss: 70.1753\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4805 - val_loss: 67.7486\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.3347 - val_loss: 73.7434\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8688 - val_loss: 70.0904\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.3069 - val_loss: 77.0570\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4918 - val_loss: 76.4054\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 109.6089 - val_loss: 71.6975\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.6610 - val_loss: 69.4103\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3293 - val_loss: 67.7775\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2999 - val_loss: 68.6269\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9179 - val_loss: 74.1624\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9248 - val_loss: 70.5366\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2226 - val_loss: 69.4428\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7312 - val_loss: 67.6977\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.6551 - val_loss: 66.9972\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.3378 - val_loss: 71.5339\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.1576 - val_loss: 77.0738\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9834 - val_loss: 82.1194\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9418 - val_loss: 74.0354\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5848 - val_loss: 65.9557\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3016 - val_loss: 69.5274\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.7407 - val_loss: 67.6170\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4013 - val_loss: 67.4092\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.0179 - val_loss: 73.5167\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.9303 - val_loss: 87.8645\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.9798 - val_loss: 83.7145\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.2886 - val_loss: 75.1170\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 107.3332 - val_loss: 66.7808\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.9646 - val_loss: 73.8901\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6516 - val_loss: 68.1663\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.8871 - val_loss: 69.2012\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.5884 - val_loss: 65.2163\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4267 - val_loss: 80.0437\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2342 - val_loss: 85.2336\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3969 - val_loss: 69.6434\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0646 - val_loss: 62.9534\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.7052 - val_loss: 104.7625\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.1089 - val_loss: 65.1523\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1095 - val_loss: 74.9638\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5393 - val_loss: 82.0790\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.2391 - val_loss: 84.6243\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1717 - val_loss: 91.8455\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.8158 - val_loss: 66.7182\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4020 - val_loss: 84.4479\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 106.2314 - val_loss: 75.6942\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 96.1602 - val_loss: 72.5270\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2027 - val_loss: 65.1646\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.0482 - val_loss: 83.0221\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6386 - val_loss: 71.9207\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5695 - val_loss: 71.2735\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0133 - val_loss: 78.7216\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.9309 - val_loss: 71.9635\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.6993 - val_loss: 68.8956\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.6460 - val_loss: 86.8676\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4382 - val_loss: 64.0578\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8865 - val_loss: 77.5580\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9287 - val_loss: 64.5544\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.8328 - val_loss: 66.7005\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6707 - val_loss: 70.7021\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8335 - val_loss: 73.1524\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2146 - val_loss: 81.1561\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.2179 - val_loss: 67.3432\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.0105 - val_loss: 69.4009\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2667 - val_loss: 75.5669\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.6216 - val_loss: 71.8358\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.9318 - val_loss: 65.5737\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6944 - val_loss: 79.1995\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5640 - val_loss: 73.2160\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1219 - val_loss: 62.7240\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.1841 - val_loss: 64.1552\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.8616 - val_loss: 80.1632\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0604 - val_loss: 62.5636\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.9866 - val_loss: 63.8869\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8928 - val_loss: 66.8510\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2868 - val_loss: 67.4271\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.7734 - val_loss: 74.4578\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.5483 - val_loss: 80.7335\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1148 - val_loss: 60.7504\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2538 - val_loss: 60.1814\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3825 - val_loss: 67.4013\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7613 - val_loss: 66.1018\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4189 - val_loss: 66.7775\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.9794 - val_loss: 89.3484\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6756 - val_loss: 77.0750\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.8062 - val_loss: 87.9488\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 107.5913 - val_loss: 75.2915\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3064 - val_loss: 69.3040\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0128 - val_loss: 59.9706\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6319 - val_loss: 79.9666\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.5102 - val_loss: 64.9848\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2832 - val_loss: 60.9186\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9496 - val_loss: 69.2928\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 98.2920 - val_loss: 67.1377\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.7073 - val_loss: 83.5983\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.2059 - val_loss: 100.0488\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.8579 - val_loss: 62.9145\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7362 - val_loss: 65.6434\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9073 - val_loss: 61.1689\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1998 - val_loss: 68.7951\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.6208 - val_loss: 68.5592\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.2107 - val_loss: 71.3386\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.1852 - val_loss: 70.2305\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.0351 - val_loss: 85.1188\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1793 - val_loss: 67.6200\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.2660 - val_loss: 76.1942\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6036 - val_loss: 78.5042\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.5556 - val_loss: 62.4395\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6059 - val_loss: 67.5248\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9701 - val_loss: 72.9190\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5362 - val_loss: 73.0938\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5509 - val_loss: 73.4244\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4416 - val_loss: 63.6525\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.3166 - val_loss: 72.2050\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3044 - val_loss: 64.3003\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0123 - val_loss: 65.8870\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.7278 - val_loss: 69.9306\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.7702 - val_loss: 71.2966\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.2616 - val_loss: 67.4651\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5587 - val_loss: 80.6893\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6425 - val_loss: 79.8688\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.2255 - val_loss: 69.6848\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.3347 - val_loss: 64.8222\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.1267 - val_loss: 95.7162\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.7264 - val_loss: 83.8789\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.5739 - val_loss: 65.9215\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9378 - val_loss: 65.4547\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7099 - val_loss: 66.5158\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0056 - val_loss: 76.8664\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7994 - val_loss: 88.0713\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.3989 - val_loss: 60.5618\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7374 - val_loss: 67.3572\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7840 - val_loss: 60.2552\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.0007 - val_loss: 89.2446\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.6517 - val_loss: 99.1033\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5820 - val_loss: 66.8561\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7554 - val_loss: 98.0858\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7141 - val_loss: 73.2265\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.9482 - val_loss: 69.4406\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1995 - val_loss: 73.1137\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.5536 - val_loss: 96.0708\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 95.9516\n",
      "--- Starting trial: run-36\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 128, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7036 - val_loss: 660.3984\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5702 - val_loss: 660.2602\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 689.4167 - val_loss: 660.1010\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2392 - val_loss: 659.9195\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0341 - val_loss: 659.7088\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7982 - val_loss: 659.4657\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5290 - val_loss: 659.1849\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2247 - val_loss: 658.8735\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8834 - val_loss: 658.5161\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5040 - val_loss: 658.1234\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0854 - val_loss: 657.6880\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6266 - val_loss: 657.2174\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1271 - val_loss: 656.6938\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.5861 - val_loss: 656.1400\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0031 - val_loss: 655.5441\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3779 - val_loss: 654.9033\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.7098 - val_loss: 654.2189\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.9988 - val_loss: 653.4904\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.2446 - val_loss: 652.7263\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 681.4472 - val_loss: 651.9009\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.6060 - val_loss: 651.0767\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.7213 - val_loss: 650.1575\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.7928 - val_loss: 649.2078\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.8205 - val_loss: 648.2280\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.8044 - val_loss: 647.2092\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.7443 - val_loss: 646.1357\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6404 - val_loss: 645.0298\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.4925 - val_loss: 643.8716\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.3010 - val_loss: 642.6708\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.0655 - val_loss: 641.4216\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.7863 - val_loss: 640.1411\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.4633 - val_loss: 638.8353\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.0968 - val_loss: 637.4544\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.6866 - val_loss: 636.0272\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.2328 - val_loss: 634.6010\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 662.7358 - val_loss: 633.1261\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.1954 - val_loss: 631.6184\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.6116 - val_loss: 630.0380\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.9847 - val_loss: 628.4469\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.3147 - val_loss: 626.7859\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.6017 - val_loss: 625.0597\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.8459 - val_loss: 623.3214\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.0473 - val_loss: 621.4542\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.2061 - val_loss: 619.6180\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.3223 - val_loss: 617.7145\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.3961 - val_loss: 615.7855\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.4275 - val_loss: 613.8645\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.4167 - val_loss: 611.8491\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.3637 - val_loss: 609.8824\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.2687 - val_loss: 607.7974\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.1320 - val_loss: 605.6567\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 632.9534 - val_loss: 603.4862\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 630.7333 - val_loss: 601.2266\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.4716 - val_loss: 598.9624\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.1683 - val_loss: 596.6536\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.8240 - val_loss: 594.2881\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.4384 - val_loss: 591.8499\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.0117 - val_loss: 589.4347\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.5441 - val_loss: 586.8915\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.0356 - val_loss: 584.3339\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.4865 - val_loss: 581.8212\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.8969 - val_loss: 579.2230\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.2667 - val_loss: 576.5325\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.5961 - val_loss: 573.8365\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.8854 - val_loss: 571.1329\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.1345 - val_loss: 568.2961\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.3437 - val_loss: 565.5751\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.5129 - val_loss: 562.7272\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.6425 - val_loss: 559.7867\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 586.7324 - val_loss: 556.8273\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 583.7827 - val_loss: 553.8187\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.7936 - val_loss: 550.8373\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.7654 - val_loss: 547.8090\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.6979 - val_loss: 544.6728\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.6129 - val_loss: 558.4167\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.4615 - val_loss: 561.0723\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.2810 - val_loss: 559.3580\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.0592 - val_loss: 555.1801\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.7979 - val_loss: 551.0428\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.4977 - val_loss: 546.4857\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.1588 - val_loss: 542.1772\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.7816 - val_loss: 538.3619\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.3662 - val_loss: 534.3206\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.9127 - val_loss: 529.7474\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.4214 - val_loss: 525.5688\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.8921 - val_loss: 521.3883\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.3252 - val_loss: 517.3334\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.7206 - val_loss: 513.6499\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 524.0786 - val_loss: 509.8786\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.4550 - val_loss: 519.2081\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.6983 - val_loss: 520.8199\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.9500 - val_loss: 517.2247\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.1610 - val_loss: 512.3639\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.3337 - val_loss: 507.9514\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.4689 - val_loss: 502.6653\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.5671 - val_loss: 497.5704\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.6286 - val_loss: 492.3515\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.6534 - val_loss: 487.4848\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 485.6417 - val_loss: 482.6537\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.6041 - val_loss: 489.2056\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.5269 - val_loss: 487.5428\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.4117 - val_loss: 481.9727\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.2572 - val_loss: 476.6103\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 465.0654 - val_loss: 470.4482\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 460.8372 - val_loss: 464.9383\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.5731 - val_loss: 459.8668\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.2732 - val_loss: 454.7208\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.0789 - val_loss: 451.2292\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.5796 - val_loss: 449.9921\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.1837 - val_loss: 446.1010\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.7463 - val_loss: 440.7058\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.2711 - val_loss: 436.3381\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.7597 - val_loss: 431.6770\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.2130 - val_loss: 425.8965\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.8161 - val_loss: 420.5003\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.0508 - val_loss: 417.3636\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.4390 - val_loss: 412.0556\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.1485 - val_loss: 408.3560\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 398.1189 - val_loss: 403.5818\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 393.3819 - val_loss: 398.4852\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.5989 - val_loss: 392.8698\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.8048 - val_loss: 391.6924\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 378.9329 - val_loss: 391.0833\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.0471 - val_loss: 387.1000\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 369.6299 - val_loss: 382.0802\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 364.4203 - val_loss: 377.2058\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 359.3501 - val_loss: 371.3682\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.3617 - val_loss: 364.5266\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 349.3144 - val_loss: 359.1004\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 344.2229 - val_loss: 352.7037\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.3481 - val_loss: 347.5458\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 334.1089 - val_loss: 347.2819\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 329.1620 - val_loss: 348.1365\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 323.6818 - val_loss: 344.4077\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 318.8677 - val_loss: 337.3700\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 313.8488 - val_loss: 329.8762\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 308.0475 - val_loss: 322.7296\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.8173 - val_loss: 316.5475\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 297.3889 - val_loss: 310.7627\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.4789 - val_loss: 303.3990\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.4697 - val_loss: 295.0992\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.6516 - val_loss: 288.9512\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.4578 - val_loss: 289.8738\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.5493 - val_loss: 288.2935\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.3363 - val_loss: 286.4293\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 263.4248 - val_loss: 282.6834\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 255.3960 - val_loss: 277.4872\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.0736 - val_loss: 271.5441\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 245.5760 - val_loss: 265.5622\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 238.4667 - val_loss: 257.8230\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.2809 - val_loss: 250.8228\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.3611 - val_loss: 241.2315\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 226.2001 - val_loss: 235.4400\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 218.0099 - val_loss: 232.4337\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.0995 - val_loss: 226.0271\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.2549 - val_loss: 217.3127\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.9293 - val_loss: 212.4368\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.1832 - val_loss: 205.4816\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 200.7214 - val_loss: 199.1528\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.8467 - val_loss: 193.4471\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.6423 - val_loss: 188.9916\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.3625 - val_loss: 186.4408\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 171.0589 - val_loss: 180.4697\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.2426 - val_loss: 175.4270\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 164.8809 - val_loss: 166.5571\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 166.2856 - val_loss: 156.5910\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.9590 - val_loss: 152.2777\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.5268 - val_loss: 149.3396\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 149.8378 - val_loss: 148.9603\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.4570 - val_loss: 147.1938\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.7269 - val_loss: 137.3281\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 140.6161 - val_loss: 127.1093\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 127.2029 - val_loss: 120.6379\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 131.0358 - val_loss: 119.7427\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.7569 - val_loss: 118.1994\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.8384 - val_loss: 112.8995\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.8594 - val_loss: 109.8883\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.2636 - val_loss: 106.8429\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5671 - val_loss: 104.2281\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2583 - val_loss: 97.5424\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.8516 - val_loss: 94.3442\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.0372 - val_loss: 95.9919\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.8918 - val_loss: 93.1474\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8926 - val_loss: 90.3266\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2061 - val_loss: 91.8947\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9946 - val_loss: 96.2598\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.0096 - val_loss: 98.9471\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 84.6366 - val_loss: 97.3608\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3935 - val_loss: 95.3631\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2614 - val_loss: 91.0048\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.7218 - val_loss: 90.1320\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1556 - val_loss: 82.7030\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1927 - val_loss: 79.6338\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3496 - val_loss: 86.2065\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.6373 - val_loss: 86.8489\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0648 - val_loss: 84.1801\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1971 - val_loss: 79.2367\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8608 - val_loss: 77.0148\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1483 - val_loss: 76.1274\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6400 - val_loss: 77.4511\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0757 - val_loss: 74.7524\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.7324 - val_loss: 72.5780\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.7050 - val_loss: 84.4521\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8578 - val_loss: 80.6398\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2823 - val_loss: 76.0949\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.7343 - val_loss: 80.7389\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.8092 - val_loss: 77.9602\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2004 - val_loss: 71.4080\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.6774 - val_loss: 69.3930\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6460 - val_loss: 72.8674\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.2376 - val_loss: 67.5885\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5328 - val_loss: 65.3225\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.8287 - val_loss: 66.4520\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8960 - val_loss: 77.2509\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2528 - val_loss: 81.6108\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3419 - val_loss: 84.0624\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1647 - val_loss: 81.5167\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.7582 - val_loss: 78.1440\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5864 - val_loss: 76.5244\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3545 - val_loss: 77.1975\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9148 - val_loss: 73.2323\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6365 - val_loss: 69.3312\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.9007 - val_loss: 66.3953\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 97.8372 - val_loss: 66.2303\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0840 - val_loss: 64.5073\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2274 - val_loss: 63.2523\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1702 - val_loss: 66.6936\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9876 - val_loss: 68.3816\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4188 - val_loss: 64.5809\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1933 - val_loss: 64.1866\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0498 - val_loss: 63.4726\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0482 - val_loss: 65.3656\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8682 - val_loss: 71.2879\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0104 - val_loss: 67.4871\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8748 - val_loss: 67.4205\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.4001 - val_loss: 67.8572\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9667 - val_loss: 68.6500\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0767 - val_loss: 66.5907\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7060 - val_loss: 65.0937\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0067 - val_loss: 66.8213\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3818 - val_loss: 69.3011\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.7043 - val_loss: 70.1766\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9487 - val_loss: 69.5016\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.1089 - val_loss: 68.3728\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4766 - val_loss: 68.4776\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5170 - val_loss: 69.6513\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.3376 - val_loss: 70.0505\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.2954 - val_loss: 68.6606\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.7118 - val_loss: 65.7718\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1404 - val_loss: 65.3259\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 42.8231\n",
      "--- Starting trial: run-37\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 128, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 13ms/step - loss: 689.6600 - val_loss: 660.2860\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 689.4255 - val_loss: 660.0495\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1856 - val_loss: 659.8101\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9363 - val_loss: 659.5575\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6733 - val_loss: 659.2962\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3921 - val_loss: 659.0063\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0873 - val_loss: 658.6880\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7534 - val_loss: 658.3444\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 687.3837 - val_loss: 657.9643\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9710 - val_loss: 657.5372\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.5068 - val_loss: 657.0555\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9814 - val_loss: 656.5087\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3834 - val_loss: 655.8776\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.6996 - val_loss: 655.1548\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.9147 - val_loss: 654.3235\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.0107 - val_loss: 653.3696\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.9669 - val_loss: 652.2493\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.7587 - val_loss: 650.9620\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.3574 - val_loss: 649.4681\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.7294 - val_loss: 647.7125\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.8354 - val_loss: 645.6792\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.6295 - val_loss: 643.3000\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.0576 - val_loss: 640.5167\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.0562 - val_loss: 637.2516\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 664.5514 - val_loss: 633.4947\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 660.4560 - val_loss: 629.0643\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.6681 - val_loss: 623.8810\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.0681 - val_loss: 617.8456\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.5157 - val_loss: 610.6974\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.8467 - val_loss: 602.3774\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.8683 - val_loss: 592.5793\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.3543 - val_loss: 581.1210\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.0399 - val_loss: 567.7256\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.6142 - val_loss: 551.9958\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.8003 - val_loss: 535.0966\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 553.0777 - val_loss: 514.2654\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.1289 - val_loss: 493.4131\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.4164 - val_loss: 466.4015\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 471.8515 - val_loss: 440.9017\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.6107 - val_loss: 408.7114\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 395.4760 - val_loss: 378.3086\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 354.7290 - val_loss: 348.9749\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 318.7428 - val_loss: 315.6327\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 283.8567 - val_loss: 282.4656\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 257.5224 - val_loss: 249.9113\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.6929 - val_loss: 233.5732\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.6770 - val_loss: 244.9464\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.2220 - val_loss: 288.5175\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.2514 - val_loss: 347.2877\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2639 - val_loss: 299.4844\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9571 - val_loss: 428.2973\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0353 - val_loss: 198.0691\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6821 - val_loss: 267.1272\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1578 - val_loss: 343.5513\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2595 - val_loss: 365.4706\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2959 - val_loss: 262.6133\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.9171 - val_loss: 136.0231\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6162 - val_loss: 227.8291\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.5615 - val_loss: 372.9434\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.8519 - val_loss: 263.9168\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.5843 - val_loss: 172.2959\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.4528 - val_loss: 241.4931\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4772 - val_loss: 226.3699\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9241 - val_loss: 194.4447\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1516 - val_loss: 95.1861\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7559 - val_loss: 108.1039\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.5530 - val_loss: 147.4883\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0015 - val_loss: 166.2038\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6885 - val_loss: 109.5868\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.8679 - val_loss: 141.4600\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1033 - val_loss: 143.7856\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.4618 - val_loss: 149.9895\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2735 - val_loss: 120.0220\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1316 - val_loss: 150.5732\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.9909 - val_loss: 107.1508\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.0898 - val_loss: 108.5605\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.0888 - val_loss: 92.6740\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5642 - val_loss: 153.6555\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.7145 - val_loss: 131.5488\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4112 - val_loss: 95.3968\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8470 - val_loss: 122.1768\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6264 - val_loss: 115.4259\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.4740 - val_loss: 130.9335\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9026 - val_loss: 113.0783\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5296 - val_loss: 100.8977\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1068 - val_loss: 96.4935\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5607 - val_loss: 87.9350\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8638 - val_loss: 83.4341\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.9983 - val_loss: 120.1108\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.8193 - val_loss: 95.9667\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.7214 - val_loss: 85.3751\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6327 - val_loss: 78.3798\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.3029 - val_loss: 66.2528\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.1426 - val_loss: 88.1257\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7954 - val_loss: 78.6483\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3862 - val_loss: 92.7188\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4515 - val_loss: 79.4240\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7311 - val_loss: 76.1228\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.8862 - val_loss: 71.5849\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5578 - val_loss: 78.4846\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3347 - val_loss: 74.2708\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0888 - val_loss: 88.5870\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0073 - val_loss: 79.0381\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6968 - val_loss: 75.4811\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.1933 - val_loss: 80.8967\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5365 - val_loss: 78.9860\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5753 - val_loss: 95.6299\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2026 - val_loss: 87.1469\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1494 - val_loss: 84.0669\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.9560 - val_loss: 65.1758\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.9761 - val_loss: 65.1353\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1471 - val_loss: 76.8321\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.9147 - val_loss: 86.9132\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.0586 - val_loss: 81.5646\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.7776 - val_loss: 73.8032\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2952 - val_loss: 74.5837\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4095 - val_loss: 66.8729\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6677 - val_loss: 76.0739\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8808 - val_loss: 90.8696\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.4788 - val_loss: 79.8569\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.2019 - val_loss: 76.3464\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2666 - val_loss: 67.7577\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.8630 - val_loss: 71.1342\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.2804 - val_loss: 71.5803\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9294 - val_loss: 72.9065\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.8558 - val_loss: 77.2279\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8235 - val_loss: 67.2724\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4035 - val_loss: 86.0802\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.3908 - val_loss: 83.5757\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.0819 - val_loss: 85.0488\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.7275 - val_loss: 92.2247\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.8847 - val_loss: 80.9841\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.4012 - val_loss: 66.5203\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6495 - val_loss: 77.3264\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4431 - val_loss: 67.8708\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 86.5581 - val_loss: 71.7420\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.1946 - val_loss: 75.5778\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.3681 - val_loss: 64.8416\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3793 - val_loss: 69.5153\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.7414 - val_loss: 82.8713\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.8236 - val_loss: 70.9986\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6080 - val_loss: 66.9404\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6086 - val_loss: 62.0190\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8936 - val_loss: 68.7259\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.0533 - val_loss: 70.2671\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3711 - val_loss: 69.4656\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.7438 - val_loss: 92.7531\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.4130 - val_loss: 69.9026\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0918 - val_loss: 69.7123\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4271 - val_loss: 64.2536\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5292 - val_loss: 81.2344\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.8026 - val_loss: 66.7385\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.1850 - val_loss: 72.7878\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 60.9191 - val_loss: 64.7439\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5358 - val_loss: 67.1524\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.5444 - val_loss: 74.2442\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4647 - val_loss: 70.5214\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.2693 - val_loss: 66.4461\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0832 - val_loss: 75.4774\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.8059 - val_loss: 63.5793\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5031 - val_loss: 62.5821\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8290 - val_loss: 73.8007\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.4235 - val_loss: 64.2828\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1142 - val_loss: 65.6832\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6202 - val_loss: 64.9312\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2465 - val_loss: 64.3365\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6910 - val_loss: 64.2973\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8215 - val_loss: 64.2123\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4329 - val_loss: 75.3160\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.4714 - val_loss: 68.3675\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.2125 - val_loss: 64.0768\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.4941 - val_loss: 68.9663\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2498 - val_loss: 66.8460\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0942 - val_loss: 64.8794\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8168 - val_loss: 65.8543\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.3411 - val_loss: 61.1186\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9378 - val_loss: 72.7909\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.5602 - val_loss: 69.5456\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3106 - val_loss: 66.7418\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0043 - val_loss: 72.9148\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.5678 - val_loss: 72.6066\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3531 - val_loss: 71.6375\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7002 - val_loss: 77.2851\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0211 - val_loss: 70.3266\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6865 - val_loss: 64.4083\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5075 - val_loss: 88.9757\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2729 - val_loss: 75.0595\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.3991 - val_loss: 65.2285\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.4785 - val_loss: 66.6104\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9798 - val_loss: 73.7527\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6531 - val_loss: 65.2449\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1732 - val_loss: 64.8305\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.0864 - val_loss: 67.5254\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.7493 - val_loss: 66.0695\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5865 - val_loss: 64.8397\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3911 - val_loss: 60.9610\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1083 - val_loss: 68.1422\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.9513 - val_loss: 73.1578\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6165 - val_loss: 69.6544\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2507 - val_loss: 67.8039\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.0513 - val_loss: 75.4794\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 80.6127 - val_loss: 81.4942\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 73.4762 - val_loss: 73.4664\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 86.0538 - val_loss: 67.3251\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5756 - val_loss: 69.4421\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8664 - val_loss: 66.1104\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8607 - val_loss: 73.2691\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.6983 - val_loss: 68.2812\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.9694 - val_loss: 66.0375\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2841 - val_loss: 65.0250\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4531 - val_loss: 68.9538\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9137 - val_loss: 64.8112\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.2024 - val_loss: 62.7665\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5370 - val_loss: 65.9957\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.4678 - val_loss: 63.6160\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8552 - val_loss: 66.3467\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7846 - val_loss: 65.9906\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6255 - val_loss: 61.9916\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.2225 - val_loss: 67.9968\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3283 - val_loss: 69.2383\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.3440 - val_loss: 84.3201\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.9530 - val_loss: 74.7406\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3190 - val_loss: 69.4320\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2278 - val_loss: 69.7199\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4579 - val_loss: 67.7571\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9898 - val_loss: 66.2294\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1730 - val_loss: 63.5218\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9272 - val_loss: 64.0956\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0986 - val_loss: 64.2122\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9774 - val_loss: 70.5637\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9762 - val_loss: 63.4973\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9028 - val_loss: 77.9145\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0174 - val_loss: 68.7491\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.9268 - val_loss: 62.2061\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1109 - val_loss: 66.3895\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9444 - val_loss: 66.5209\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9712 - val_loss: 63.8440\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.6107 - val_loss: 61.7190\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.7558 - val_loss: 65.2646\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.3166 - val_loss: 64.1433\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.9854 - val_loss: 61.6954\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4164 - val_loss: 66.5828\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4517 - val_loss: 70.0333\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.4520 - val_loss: 67.6509\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8984 - val_loss: 67.8016\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0258 - val_loss: 70.4396\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.2649 - val_loss: 64.3317\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8310 - val_loss: 67.5768\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0189 - val_loss: 65.4054\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.3425 - val_loss: 66.8503\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 47.0064\n",
      "--- Starting trial: run-38\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 128, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.7045 - val_loss: 660.4625\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5730 - val_loss: 660.2722\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.4216 - val_loss: 660.0489\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2460 - val_loss: 659.7941\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0428 - val_loss: 659.5074\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8090 - val_loss: 659.1792\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5417 - val_loss: 658.8041\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2393 - val_loss: 658.3857\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 687.9000 - val_loss: 657.9217\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5225 - val_loss: 657.4209\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1056 - val_loss: 656.8787\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6484 - val_loss: 656.2903\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1506 - val_loss: 655.6585\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6111 - val_loss: 654.9912\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0296 - val_loss: 654.2790\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.4057 - val_loss: 653.5497\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.7390 - val_loss: 652.7615\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.0293 - val_loss: 651.9425\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.2763 - val_loss: 651.0567\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.4799 - val_loss: 650.1316\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.6398 - val_loss: 649.1349\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.7560 - val_loss: 648.1219\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.8284 - val_loss: 647.0891\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.8572 - val_loss: 646.0203\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.8418 - val_loss: 644.9093\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 675.7825 - val_loss: 643.7352\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6794 - val_loss: 642.5281\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.5323 - val_loss: 641.2757\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.3414 - val_loss: 639.9633\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.1066 - val_loss: 638.6194\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.8281 - val_loss: 637.2141\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.5057 - val_loss: 635.7768\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.1396 - val_loss: 634.3356\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.7300 - val_loss: 632.8869\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.2769 - val_loss: 631.4007\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.7802 - val_loss: 629.9044\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.2402 - val_loss: 628.3162\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.6569 - val_loss: 626.6425\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.0305 - val_loss: 624.9021\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.3609 - val_loss: 623.1658\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 654.6483 - val_loss: 621.4304\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 652.8928 - val_loss: 619.6722\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.0946 - val_loss: 617.7423\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.2538 - val_loss: 615.7642\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.3702 - val_loss: 613.8469\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.4443 - val_loss: 611.9897\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.4760 - val_loss: 610.1608\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.4655 - val_loss: 608.2306\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.4128 - val_loss: 606.1925\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.3182 - val_loss: 604.0814\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.1817 - val_loss: 601.7820\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.0034 - val_loss: 599.5834\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.7834 - val_loss: 597.5108\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.5220 - val_loss: 595.4330\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.2190 - val_loss: 593.3857\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.8748 - val_loss: 591.1462\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.4895 - val_loss: 588.6998\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.0630 - val_loss: 586.3740\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 616.5956 - val_loss: 583.9091\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 614.0873 - val_loss: 581.4083\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.5385 - val_loss: 579.0060\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.9490 - val_loss: 576.4578\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.3190 - val_loss: 573.8174\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.6487 - val_loss: 570.8845\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.9381 - val_loss: 567.9539\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.1874 - val_loss: 565.1459\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.3968 - val_loss: 562.4135\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.5662 - val_loss: 559.3510\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.6959 - val_loss: 556.2892\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.7860 - val_loss: 553.4507\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.8365 - val_loss: 550.2268\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.8476 - val_loss: 546.8851\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.8195 - val_loss: 543.2411\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.7521 - val_loss: 540.0894\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 571.6608 - val_loss: 541.8585\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 568.5112 - val_loss: 547.0220\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.3337 - val_loss: 547.0350\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.1135 - val_loss: 544.4659\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.8528 - val_loss: 540.9525\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.5530 - val_loss: 537.0181\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.2144 - val_loss: 532.7791\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.8374 - val_loss: 529.0020\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.4222 - val_loss: 525.1138\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.9689 - val_loss: 521.0353\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.4777 - val_loss: 517.2923\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.9486 - val_loss: 513.9524\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.3818 - val_loss: 510.0355\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.7775 - val_loss: 506.0670\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 524.1356 - val_loss: 502.2680\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.5738 - val_loss: 496.9451\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.7522 - val_loss: 496.6715\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.0063 - val_loss: 494.9441\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 509.2187 - val_loss: 491.4519\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 505.3918 - val_loss: 487.3007\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.5274 - val_loss: 482.9118\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.6259 - val_loss: 478.4430\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.6875 - val_loss: 474.0332\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.7126 - val_loss: 469.7248\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.7010 - val_loss: 465.6195\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.7071 - val_loss: 469.9458\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.5857 - val_loss: 471.5542\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.4724 - val_loss: 468.7999\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.3189 - val_loss: 464.4363\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.2153 - val_loss: 463.6151\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.9769 - val_loss: 461.4622\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.6838 - val_loss: 452.0771\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.4815 - val_loss: 450.6954\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.0943 - val_loss: 447.5129\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.7328 - val_loss: 442.7510\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.3297 - val_loss: 437.2781\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.8886 - val_loss: 431.8105\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.4113 - val_loss: 426.7804\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 426.5353 - val_loss: 425.8904\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 421.4768 - val_loss: 443.7074\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.3380 - val_loss: 446.2363\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.8885 - val_loss: 431.3546\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.3989 - val_loss: 421.8716\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.5085 - val_loss: 415.7845\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.8273 - val_loss: 428.6348\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.1904 - val_loss: 432.6680\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.4219 - val_loss: 429.7687\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.8307 - val_loss: 424.3625\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.0341 - val_loss: 417.9069\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 374.9498 - val_loss: 407.9566\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.6680 - val_loss: 399.9189\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.3347 - val_loss: 395.1035\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.3582 - val_loss: 386.3520\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.8315 - val_loss: 386.8539\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.4220 - val_loss: 382.0414\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 346.7218 - val_loss: 376.2289\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 340.9924 - val_loss: 370.6038\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 335.6735 - val_loss: 364.0592\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.5682 - val_loss: 356.4621\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.5640 - val_loss: 351.4630\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.1166 - val_loss: 349.2769\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 315.9340 - val_loss: 348.0858\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.3173 - val_loss: 348.0413\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 309.2398 - val_loss: 341.1078\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 301.1234 - val_loss: 333.1945\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.9231 - val_loss: 330.0687\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 290.4602 - val_loss: 326.7970\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 286.9797 - val_loss: 324.3839\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.6665 - val_loss: 326.2007\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.5273 - val_loss: 319.0409\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.3438 - val_loss: 310.8519\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 273.4826 - val_loss: 304.8419\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.8314 - val_loss: 299.3220\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 257.8019 - val_loss: 295.2970\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249.8046 - val_loss: 294.1261\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.5568 - val_loss: 284.3262\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 240.2234 - val_loss: 275.5152\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 233.6064 - val_loss: 263.8022\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 229.6608 - val_loss: 248.0712\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 223.5405 - val_loss: 238.2233\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219.9235 - val_loss: 235.3207\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.6473 - val_loss: 229.6620\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 209.3825 - val_loss: 220.1989\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.1267 - val_loss: 213.1877\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.4869 - val_loss: 206.4553\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.6064 - val_loss: 200.4604\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.1974 - val_loss: 196.5209\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.1997 - val_loss: 190.1924\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.6210 - val_loss: 185.9937\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.5130 - val_loss: 178.3676\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.8484 - val_loss: 170.8516\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 164.6071 - val_loss: 165.0621\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 168.1353 - val_loss: 161.1366\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.0150 - val_loss: 157.9781\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.3726 - val_loss: 158.3880\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 164.2272 - val_loss: 156.8075\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 151.8446 - val_loss: 156.2699\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.6413 - val_loss: 149.9415\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 145.5418 - val_loss: 146.5276\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 147.2262 - val_loss: 149.6375\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.7825 - val_loss: 155.5535\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.9921 - val_loss: 150.9709\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.7385 - val_loss: 144.0240\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.1220 - val_loss: 133.6086\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.9393 - val_loss: 121.0145\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.0767 - val_loss: 112.4393\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4918 - val_loss: 111.0297\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.1301 - val_loss: 114.8414\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.8793 - val_loss: 116.9809\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.6985 - val_loss: 111.8766\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0540 - val_loss: 112.1743\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8103 - val_loss: 107.3067\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3452 - val_loss: 105.2935\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6628 - val_loss: 109.8233\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1150 - val_loss: 114.9291\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.3659 - val_loss: 117.3927\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5974 - val_loss: 113.0782\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.5278 - val_loss: 107.5004\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 92.6050 - val_loss: 92.2617\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 101.8218 - val_loss: 88.9125\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2487 - val_loss: 96.1301\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9117 - val_loss: 84.6856\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.7803 - val_loss: 80.5384\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4770 - val_loss: 82.3104\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0362 - val_loss: 76.7072\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4355 - val_loss: 75.3889\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7886 - val_loss: 76.1900\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4414 - val_loss: 77.1150\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3040 - val_loss: 75.4123\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2159 - val_loss: 73.9180\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8920 - val_loss: 76.2631\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 71.0515 - val_loss: 74.1943\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9393 - val_loss: 72.8049\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3949 - val_loss: 73.1296\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.6837 - val_loss: 75.2907\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.1015 - val_loss: 70.9484\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1727 - val_loss: 73.1103\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7684 - val_loss: 64.8280\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.6545 - val_loss: 59.7573\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.5182 - val_loss: 60.0212\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.9800 - val_loss: 64.3094\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.1644 - val_loss: 69.3709\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2927 - val_loss: 71.8204\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8855 - val_loss: 75.2985\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6940 - val_loss: 75.5692\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5612 - val_loss: 70.2602\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.3562 - val_loss: 67.2858\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5551 - val_loss: 64.1425\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.9284 - val_loss: 61.7480\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.7050 - val_loss: 61.3074\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.2701 - val_loss: 59.6301\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5031 - val_loss: 61.2693\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2727 - val_loss: 63.6648\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.6815 - val_loss: 63.3406\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.2278 - val_loss: 61.6866\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3945 - val_loss: 59.1983\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8889 - val_loss: 61.4417\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4069 - val_loss: 66.6465\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.3978 - val_loss: 67.3627\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2713 - val_loss: 61.0239\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.7056 - val_loss: 60.4709\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1074 - val_loss: 61.7646\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0024 - val_loss: 62.8933\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1619 - val_loss: 66.5146\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.7285 - val_loss: 58.5320\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.3527 - val_loss: 54.8205\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.6790 - val_loss: 54.7551\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.7100 - val_loss: 55.9144\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.2335 - val_loss: 56.8834\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.4625 - val_loss: 59.0052\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3256 - val_loss: 61.7410\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0331 - val_loss: 64.2007\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.1444 - val_loss: 60.2569\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.7924 - val_loss: 57.7060\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2681 - val_loss: 58.7029\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6467 - val_loss: 61.4575\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 35.8310\n",
      "--- Starting trial: run-39\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 128, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 16ms/step - loss: 689.6586 - val_loss: 660.2971\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4203 - val_loss: 660.0697\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1768 - val_loss: 659.8386\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9235 - val_loss: 659.5986\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6562 - val_loss: 659.3446\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3702 - val_loss: 659.0621\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0602 - val_loss: 658.7512\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7202 - val_loss: 658.4096\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3436 - val_loss: 658.0241\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9232 - val_loss: 657.6013\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4498 - val_loss: 657.1172\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9139 - val_loss: 656.5610\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3036 - val_loss: 655.9261\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.6056 - val_loss: 655.1996\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.8040 - val_loss: 654.3625\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.8806 - val_loss: 653.3952\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.8141 - val_loss: 652.2702\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.5792 - val_loss: 650.9395\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.1467 - val_loss: 649.4227\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.4822 - val_loss: 647.6462\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.5454 - val_loss: 645.5577\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 673.2893 - val_loss: 643.1267\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.6584 - val_loss: 640.2764\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.5882 - val_loss: 636.9478\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.0024 - val_loss: 633.0621\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.8123 - val_loss: 628.4930\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.9132 - val_loss: 623.1743\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.1829 - val_loss: 616.9371\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.4778 - val_loss: 609.6260\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.6296 - val_loss: 601.0891\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.4410 - val_loss: 591.0380\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.6807 - val_loss: 579.2528\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.0774 - val_loss: 565.4403\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.4127 - val_loss: 550.3884\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 570.5211 - val_loss: 531.8123\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.4213 - val_loss: 510.3396\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.3334 - val_loss: 492.1588\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 500.3157 - val_loss: 468.5057\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.9543 - val_loss: 441.1935\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.6343 - val_loss: 424.4714\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.0341 - val_loss: 386.7801\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 362.7357 - val_loss: 383.5121\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.2462 - val_loss: 343.5430\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.2157 - val_loss: 304.8826\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 267.6159 - val_loss: 268.2514\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 230.4267 - val_loss: 280.5638\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.2648 - val_loss: 206.4075\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.3714 - val_loss: 160.9011\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.6039 - val_loss: 253.1071\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.3725 - val_loss: 214.0012\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8709 - val_loss: 231.6864\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5575 - val_loss: 259.9738\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.8136 - val_loss: 265.4000\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1830 - val_loss: 299.3551\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.5221 - val_loss: 285.1227\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8291 - val_loss: 180.9812\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0553 - val_loss: 234.3949\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.9660 - val_loss: 213.9645\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.1292 - val_loss: 170.1249\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1596 - val_loss: 189.3251\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0549 - val_loss: 157.0881\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.9823 - val_loss: 128.2196\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4076 - val_loss: 160.8475\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 91.2256 - val_loss: 169.0457\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1477 - val_loss: 141.3033\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.6408 - val_loss: 126.1825\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.6690 - val_loss: 153.9253\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4330 - val_loss: 145.4527\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2844 - val_loss: 139.8632\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1434 - val_loss: 137.5058\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.8777 - val_loss: 133.8319\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8385 - val_loss: 144.0261\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.8558 - val_loss: 107.1918\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3111 - val_loss: 116.7170\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.8351 - val_loss: 90.5935\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1829 - val_loss: 104.3407\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.7971 - val_loss: 98.8113\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2038 - val_loss: 100.9409\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6935 - val_loss: 110.4051\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4961 - val_loss: 87.7416\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5389 - val_loss: 113.7134\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8396 - val_loss: 108.7850\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 62.5637 - val_loss: 83.9118\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 94.5848 - val_loss: 108.8063\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7459 - val_loss: 84.6032\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0258 - val_loss: 96.0407\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4476 - val_loss: 85.5019\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.4428 - val_loss: 72.9418\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 72.3042 - val_loss: 71.0741\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2236 - val_loss: 73.1128\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4171 - val_loss: 76.4829\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.2339 - val_loss: 79.7088\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8755 - val_loss: 72.7064\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.8073 - val_loss: 78.0666\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.0641 - val_loss: 72.2950\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.0115 - val_loss: 84.0484\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0752 - val_loss: 78.9181\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 90.0964 - val_loss: 72.8949\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.6519 - val_loss: 76.5508\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3163 - val_loss: 67.6661\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8838 - val_loss: 76.9690\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0176 - val_loss: 68.5581\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5031 - val_loss: 82.1792\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.3267 - val_loss: 80.5025\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2895 - val_loss: 76.0779\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.5557 - val_loss: 66.1343\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.8001 - val_loss: 72.3555\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.1915 - val_loss: 60.7539\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 61.6628 - val_loss: 65.5877\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6594 - val_loss: 65.8484\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0254 - val_loss: 70.4881\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1262 - val_loss: 66.2531\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1116 - val_loss: 58.7405\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.7982 - val_loss: 75.1751\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.3976 - val_loss: 64.6924\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.2441 - val_loss: 62.7963\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.5523 - val_loss: 75.9690\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1629 - val_loss: 63.3967\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.5916 - val_loss: 73.4436\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.5613 - val_loss: 64.5684\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.5654 - val_loss: 62.1492\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7561 - val_loss: 58.6956\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.6354 - val_loss: 59.8449\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.5953 - val_loss: 63.5401\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.1898 - val_loss: 59.6155\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8890 - val_loss: 61.9260\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.0089 - val_loss: 64.6663\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0104 - val_loss: 62.4225\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.9322 - val_loss: 60.2316\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8407 - val_loss: 64.7780\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7335 - val_loss: 64.9720\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.6148 - val_loss: 67.6586\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.0729 - val_loss: 62.9074\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9577 - val_loss: 63.9802\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.9662 - val_loss: 70.1799\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4682 - val_loss: 79.9689\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2641 - val_loss: 63.4938\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0108 - val_loss: 64.0741\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3463 - val_loss: 59.7517\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6260 - val_loss: 60.6464\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.5686 - val_loss: 64.1657\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.4839 - val_loss: 59.6949\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3269 - val_loss: 60.1693\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2145 - val_loss: 70.8895\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.1604 - val_loss: 72.0862\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4099 - val_loss: 68.5691\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.4272 - val_loss: 61.9336\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.4091 - val_loss: 57.0438\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.5955 - val_loss: 63.5915\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 83.5092 - val_loss: 60.2196\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.8556 - val_loss: 61.5356\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.3362 - val_loss: 62.0082\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6608 - val_loss: 61.9078\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.9082 - val_loss: 59.5512\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.0776 - val_loss: 60.9109\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6817 - val_loss: 65.6166\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1951 - val_loss: 57.7724\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7300 - val_loss: 59.2843\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3126 - val_loss: 59.2186\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8216 - val_loss: 62.0981\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8529 - val_loss: 58.5157\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8094 - val_loss: 62.2965\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.0509 - val_loss: 65.0498\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5442 - val_loss: 66.4838\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.8267 - val_loss: 65.5824\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0364 - val_loss: 68.2081\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9892 - val_loss: 59.6884\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.4331 - val_loss: 69.6327\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.7835 - val_loss: 84.4321\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 90.7719 - val_loss: 67.4880\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5524 - val_loss: 57.7921\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.6131 - val_loss: 60.8153\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4031 - val_loss: 62.2648\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5342 - val_loss: 61.5540\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5573 - val_loss: 64.3503\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.1006 - val_loss: 62.4780\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9778 - val_loss: 65.2216\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52.2791 - val_loss: 65.2806\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4533 - val_loss: 62.2284\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.7404 - val_loss: 64.9254\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7698 - val_loss: 58.6517\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2319 - val_loss: 62.7101\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6613 - val_loss: 68.0408\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6351 - val_loss: 65.2533\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4792 - val_loss: 68.1311\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 53.7201 - val_loss: 61.7315\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.2320 - val_loss: 68.6145\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2307 - val_loss: 70.0530\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5317 - val_loss: 66.4925\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.2182 - val_loss: 61.8857\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 70.3732 - val_loss: 66.6946\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.0135 - val_loss: 66.8426\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8601 - val_loss: 61.0403\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 61.2427 - val_loss: 65.9004\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.3897 - val_loss: 60.1184\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8441 - val_loss: 67.0558\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6374 - val_loss: 59.1321\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.0950 - val_loss: 76.9254\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7988 - val_loss: 60.9016\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.5414 - val_loss: 58.1327\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2668 - val_loss: 65.6951\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.0515 - val_loss: 64.6105\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.0938 - val_loss: 64.7651\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3048 - val_loss: 62.3618\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8321 - val_loss: 58.0362\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2234 - val_loss: 62.0126\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9027 - val_loss: 61.9934\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.6648 - val_loss: 74.1093\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6825 - val_loss: 65.3489\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.4460 - val_loss: 59.4629\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 103.2334 - val_loss: 55.7436\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 86.1589 - val_loss: 58.5558\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.0139 - val_loss: 67.7140\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9221 - val_loss: 58.9200\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6151 - val_loss: 63.5775\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0170 - val_loss: 58.9680\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7937 - val_loss: 64.4838\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1655 - val_loss: 60.2336\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1479 - val_loss: 57.6858\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3612 - val_loss: 58.1549\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 86.2516 - val_loss: 61.9438\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.3807 - val_loss: 67.2232\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6779 - val_loss: 61.3744\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.6083 - val_loss: 66.6423\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1356 - val_loss: 58.6241\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5578 - val_loss: 57.3144\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9441 - val_loss: 59.1073\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.9001 - val_loss: 60.4383\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.5546 - val_loss: 60.2780\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2653 - val_loss: 61.6747\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.2611 - val_loss: 59.0458\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.1584 - val_loss: 68.5352\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4313 - val_loss: 72.0467\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1420 - val_loss: 66.9431\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.2965 - val_loss: 61.1597\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.3212 - val_loss: 60.7908\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4934 - val_loss: 60.0636\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3641 - val_loss: 59.6876\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9974 - val_loss: 58.0643\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6807 - val_loss: 60.6602\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.5712 - val_loss: 63.8370\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6602 - val_loss: 69.4825\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.9097 - val_loss: 61.4537\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5803 - val_loss: 56.9816\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5473 - val_loss: 75.0256\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.5698 - val_loss: 57.1753\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.7186 - val_loss: 58.3480\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9175 - val_loss: 62.5642\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.7073 - val_loss: 70.1403\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4207 - val_loss: 70.1960\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 32.6986\n",
      "--- Starting trial: run-40\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 128, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.7089 - val_loss: 660.5853\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5891 - val_loss: 660.4654\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4490 - val_loss: 660.3195\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2850 - val_loss: 660.1506\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0931 - val_loss: 659.9481\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8703 - val_loss: 659.7144\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6139 - val_loss: 659.4507\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3218 - val_loss: 659.1509\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9926 - val_loss: 658.8107\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6247 - val_loss: 658.4260\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2171 - val_loss: 658.0073\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7689 - val_loss: 657.5372\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.2793 - val_loss: 657.0330\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.7479 - val_loss: 656.4883\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1741 - val_loss: 655.8999\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.5574 - val_loss: 655.2597\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.8977 - val_loss: 654.5726\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.1945 - val_loss: 653.8354\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.4476 - val_loss: 653.0621\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.6572 - val_loss: 652.2543\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.8226 - val_loss: 651.3980\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.9442 - val_loss: 650.4968\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.0216 - val_loss: 649.5500\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.0551 - val_loss: 648.5543\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.0442 - val_loss: 647.5330\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.9893 - val_loss: 646.4502\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.8902 - val_loss: 645.3274\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.7471 - val_loss: 644.1661\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.5598 - val_loss: 642.9436\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.3284 - val_loss: 641.7236\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.0532 - val_loss: 640.4309\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.7341 - val_loss: 639.0950\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.3710 - val_loss: 637.6995\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.9642 - val_loss: 636.2668\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.5137 - val_loss: 634.7857\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.0198 - val_loss: 633.2876\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.4822 - val_loss: 631.7455\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.9013 - val_loss: 630.0776\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.2771 - val_loss: 628.4562\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.6096 - val_loss: 626.7618\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.8992 - val_loss: 625.0353\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.1456 - val_loss: 623.2200\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.3493 - val_loss: 621.4034\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.5102 - val_loss: 619.5658\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 647.6285 - val_loss: 617.6458\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.7042 - val_loss: 615.6326\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.7374 - val_loss: 613.5938\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.7285 - val_loss: 611.5261\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.6774 - val_loss: 609.4411\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.5840 - val_loss: 607.2827\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.4489 - val_loss: 605.0580\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.2719 - val_loss: 602.9156\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.0532 - val_loss: 600.6827\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.7929 - val_loss: 598.4315\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.4913 - val_loss: 596.1189\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.1483 - val_loss: 593.7038\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.7639 - val_loss: 591.2655\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.3386 - val_loss: 588.7826\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.8722 - val_loss: 586.3771\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.3651 - val_loss: 583.8321\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.8171 - val_loss: 581.4373\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.2286 - val_loss: 578.8541\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.5995 - val_loss: 576.3100\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.9301 - val_loss: 573.6041\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.2204 - val_loss: 570.8323\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.4707 - val_loss: 568.1487\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.6809 - val_loss: 565.3093\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.8513 - val_loss: 562.4681\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.9816 - val_loss: 559.5344\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.0726 - val_loss: 556.7521\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 584.1238 - val_loss: 553.7587\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 581.1357 - val_loss: 550.8126\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.1084 - val_loss: 547.7833\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.0419 - val_loss: 544.6770\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.9361 - val_loss: 541.4534\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.7915 - val_loss: 538.2891\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.6081 - val_loss: 535.0815\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.3987 - val_loss: 540.6741\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 559.1409 - val_loss: 540.7893\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.8455 - val_loss: 538.6571\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.5092 - val_loss: 536.0068\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.1336 - val_loss: 532.7595\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.7194 - val_loss: 528.8569\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.2669 - val_loss: 525.2446\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.7764 - val_loss: 521.4110\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.2480 - val_loss: 517.4848\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.6820 - val_loss: 514.0838\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 528.0783 - val_loss: 510.7089\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 524.4371 - val_loss: 506.4688\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.7585 - val_loss: 503.2703\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 517.0426 - val_loss: 499.5842\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.2896 - val_loss: 495.8876\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.4995 - val_loss: 492.2691\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.6723 - val_loss: 487.9398\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.8083 - val_loss: 483.8705\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.9411 - val_loss: 480.3730\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 494.0065 - val_loss: 478.5157\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 490.0718 - val_loss: 474.7335\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.1602 - val_loss: 475.0399\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 482.0557 - val_loss: 472.2316\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.9793 - val_loss: 468.5154\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 473.8620 - val_loss: 464.5837\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 470.0868 - val_loss: 461.2506\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.5283 - val_loss: 458.2824\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.3088 - val_loss: 454.4750\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 457.0481 - val_loss: 449.9812\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 452.7495 - val_loss: 445.1129\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.4145 - val_loss: 440.5526\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 444.0592 - val_loss: 438.6745\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.6590 - val_loss: 434.5137\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 435.2243 - val_loss: 430.8340\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.8790 - val_loss: 428.5923\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 426.2744 - val_loss: 424.0311\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.7382 - val_loss: 418.8249\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.1603 - val_loss: 413.5056\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.5966 - val_loss: 408.7181\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.1880 - val_loss: 404.9440\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 405.0114 - val_loss: 399.8632\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.7016 - val_loss: 396.1015\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.1921 - val_loss: 392.1782\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.9982 - val_loss: 388.0046\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.7161 - val_loss: 383.4275\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.4975 - val_loss: 377.3546\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.5668 - val_loss: 372.1558\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.6805 - val_loss: 367.9694\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 366.0066 - val_loss: 362.9507\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.8507 - val_loss: 357.0752\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.3560 - val_loss: 351.0320\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 351.5396 - val_loss: 345.2982\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347.4622 - val_loss: 339.5859\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.1899 - val_loss: 334.0056\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 336.1761 - val_loss: 328.9086\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 332.6416 - val_loss: 323.5800\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 326.5316 - val_loss: 319.0070\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 322.3907 - val_loss: 313.0601\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 316.8990 - val_loss: 308.7727\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 314.3136 - val_loss: 303.7648\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 308.0968 - val_loss: 299.0605\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 301.8565 - val_loss: 294.0634\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 296.5451 - val_loss: 288.5078\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.5525 - val_loss: 282.5293\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 290.5847 - val_loss: 277.1724\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 282.5791 - val_loss: 273.5942\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 276.5451 - val_loss: 269.3519\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 270.7886 - val_loss: 264.5229\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 266.5887 - val_loss: 259.6815\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.3974 - val_loss: 254.5084\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.4142 - val_loss: 249.0060\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 250.6147 - val_loss: 243.1095\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.6109 - val_loss: 238.2601\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 240.8600 - val_loss: 233.0670\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.3626 - val_loss: 227.7747\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 228.5746 - val_loss: 224.0571\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 224.5814 - val_loss: 219.6623\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 218.5440 - val_loss: 214.8567\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232.7738 - val_loss: 210.8426\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.7293 - val_loss: 207.0399\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.5795 - val_loss: 202.3037\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.3519 - val_loss: 198.7169\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.0024 - val_loss: 194.9629\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.0200 - val_loss: 191.1596\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.6799 - val_loss: 187.5137\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.6138 - val_loss: 184.0938\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.1912 - val_loss: 180.2888\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.3920 - val_loss: 177.1651\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.9505 - val_loss: 175.3434\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.3758 - val_loss: 172.7786\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.8169 - val_loss: 171.0340\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.9624 - val_loss: 165.5876\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 150.4471 - val_loss: 160.3248\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 148.5454 - val_loss: 156.0319\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.6289 - val_loss: 152.2786\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 173.4843 - val_loss: 149.9678\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.7144 - val_loss: 152.8026\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.7488 - val_loss: 151.7993\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.7609 - val_loss: 153.3660\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.2512 - val_loss: 147.7611\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 147.4758 - val_loss: 139.4720\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.9438 - val_loss: 142.0097\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.9779 - val_loss: 144.4392\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3539 - val_loss: 142.9501\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.2746 - val_loss: 145.7576\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.0601 - val_loss: 138.8155\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.5295 - val_loss: 126.8806\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.6775 - val_loss: 121.0739\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.9128 - val_loss: 118.4119\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1926 - val_loss: 117.7811\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1068 - val_loss: 119.7461\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8644 - val_loss: 117.1898\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 116.9045 - val_loss: 120.4572\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4380 - val_loss: 125.0973\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4107 - val_loss: 128.0348\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6965 - val_loss: 117.7998\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8018 - val_loss: 104.7743\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.8560 - val_loss: 104.7800\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5872 - val_loss: 113.3008\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.0324 - val_loss: 119.1928\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6984 - val_loss: 107.5659\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5396 - val_loss: 85.4900\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.5043 - val_loss: 79.2704\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1831 - val_loss: 93.3589\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.3193 - val_loss: 110.7782\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.5402 - val_loss: 103.5109\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2656 - val_loss: 81.2418\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.3158 - val_loss: 74.1774\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1576 - val_loss: 74.9531\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1944 - val_loss: 80.3953\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4174 - val_loss: 84.7360\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.4976 - val_loss: 85.2204\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8332 - val_loss: 89.8004\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2247 - val_loss: 85.0912\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.6774 - val_loss: 80.8779\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.8598 - val_loss: 74.9213\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2158 - val_loss: 69.0270\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9307 - val_loss: 74.1455\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9637 - val_loss: 80.7786\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4092 - val_loss: 78.3549\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2763 - val_loss: 72.7337\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 94.6376 - val_loss: 66.2578\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5231 - val_loss: 63.9496\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8695 - val_loss: 65.7838\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7703 - val_loss: 70.7619\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.6423 - val_loss: 69.2083\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.7649 - val_loss: 72.5817\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8283 - val_loss: 66.9446\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1722 - val_loss: 64.3405\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2353 - val_loss: 62.9983\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.9471 - val_loss: 62.9568\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0453 - val_loss: 63.0903\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.8390 - val_loss: 63.5718\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5916 - val_loss: 65.1288\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2692 - val_loss: 63.9601\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.9665 - val_loss: 62.8809\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5036 - val_loss: 61.7169\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 73.5753 - val_loss: 62.3273\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7612 - val_loss: 65.1418\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5805 - val_loss: 71.9661\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.5605 - val_loss: 70.8523\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.2321 - val_loss: 68.4719\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4470 - val_loss: 66.5187\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.3191 - val_loss: 61.9472\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4123 - val_loss: 61.1232\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.4730 - val_loss: 60.9850\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4784 - val_loss: 62.3417\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64.1167 - val_loss: 66.7354\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8295 - val_loss: 61.8000\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.9874 - val_loss: 61.6543\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.0352 - val_loss: 61.1733\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4571 - val_loss: 61.1866\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3612 - val_loss: 62.7874\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 39.0178\n",
      "--- Starting trial: run-41\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 128, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6654 - val_loss: 661.0693\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4444 - val_loss: 660.8073\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2187 - val_loss: 660.5445\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.9843 - val_loss: 660.2739\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7375 - val_loss: 659.9974\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.4740 - val_loss: 659.7026\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1890 - val_loss: 659.3865\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8774 - val_loss: 659.0414\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5334 - val_loss: 658.6666\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1500 - val_loss: 658.2503\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7197 - val_loss: 657.7874\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.2335 - val_loss: 657.2642\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6812 - val_loss: 656.6638\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0505 - val_loss: 655.9841\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3279 - val_loss: 655.2078\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.4966 - val_loss: 654.3100\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.5378 - val_loss: 653.2630\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.4290 - val_loss: 652.0563\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.1442 - val_loss: 650.6617\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.6528 - val_loss: 649.0457\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.9188 - val_loss: 647.1628\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.9003 - val_loss: 644.9692\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.5480 - val_loss: 642.4106\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.8043 - val_loss: 639.4073\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 666.6014 - val_loss: 635.9164\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 662.8600 - val_loss: 631.8267\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.4872 - val_loss: 627.0541\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.3739 - val_loss: 621.4722\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.3923 - val_loss: 614.9440\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.3925 - val_loss: 607.3152\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.1986 - val_loss: 598.3373\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.6046 - val_loss: 587.8380\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.3689 - val_loss: 575.5146\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.2081 - val_loss: 561.0692\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.7899 - val_loss: 544.2131\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.7249 - val_loss: 524.8472\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 543.6021 - val_loss: 503.6631\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.8171 - val_loss: 481.8997\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.8937 - val_loss: 455.5771\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.1066 - val_loss: 426.0222\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 427.0970 - val_loss: 392.7704\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 391.7180 - val_loss: 360.1474\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 355.1883 - val_loss: 326.6736\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 322.9344 - val_loss: 290.1088\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 297.5120 - val_loss: 256.8988\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.3628 - val_loss: 224.8662\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 226.8665 - val_loss: 201.7969\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 190.9232 - val_loss: 172.4628\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 163.9586 - val_loss: 157.5826\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.9957 - val_loss: 144.8772\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.6595 - val_loss: 134.0837\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.8817 - val_loss: 119.0446\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.7276 - val_loss: 113.4215\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.4294 - val_loss: 93.7429\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.0689 - val_loss: 96.7137\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3766 - val_loss: 92.4324\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8183 - val_loss: 100.0492\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.3670 - val_loss: 99.9386\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.8411 - val_loss: 115.4053\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.2724 - val_loss: 102.9175\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1231 - val_loss: 97.0585\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.7096 - val_loss: 106.6305\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.2867 - val_loss: 110.6650\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4757 - val_loss: 109.7135\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3728 - val_loss: 103.0233\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7509 - val_loss: 123.8558\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0248 - val_loss: 125.6176\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.9087 - val_loss: 90.4712\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.2116 - val_loss: 83.3752\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0840 - val_loss: 81.9030\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.6598 - val_loss: 75.7564\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7555 - val_loss: 83.2539\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2578 - val_loss: 83.6497\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7813 - val_loss: 73.9453\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1154 - val_loss: 77.7918\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3558 - val_loss: 88.3296\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0836 - val_loss: 67.9583\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2883 - val_loss: 67.8002\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3980 - val_loss: 70.2060\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.5556 - val_loss: 73.3151\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2485 - val_loss: 76.4289\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9224 - val_loss: 67.5100\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.8534 - val_loss: 66.2740\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7500 - val_loss: 68.5507\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.8790 - val_loss: 73.8722\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.5198 - val_loss: 79.5770\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.5667 - val_loss: 70.6976\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.3961 - val_loss: 76.4274\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.4943 - val_loss: 74.0585\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7284 - val_loss: 67.0544\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 137.5351 - val_loss: 73.7564\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 67.8271 - val_loss: 67.8998\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6099 - val_loss: 95.6125\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.6820 - val_loss: 71.1456\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1603 - val_loss: 70.4162\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2704 - val_loss: 72.3922\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5477 - val_loss: 69.1802\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5864 - val_loss: 64.6773\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6853 - val_loss: 67.4513\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1217 - val_loss: 67.2376\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.4013 - val_loss: 74.1381\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6921 - val_loss: 65.2653\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1016 - val_loss: 63.8213\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2954 - val_loss: 64.8246\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.1377 - val_loss: 64.8579\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1130 - val_loss: 65.3432\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.3256 - val_loss: 69.6619\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0704 - val_loss: 70.1378\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4558 - val_loss: 68.9002\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.9368 - val_loss: 71.5285\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 88.4537 - val_loss: 65.3883\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1725 - val_loss: 72.1803\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9242 - val_loss: 62.3025\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8276 - val_loss: 66.6990\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6807 - val_loss: 62.8670\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1268 - val_loss: 84.3203\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5064 - val_loss: 68.0181\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6221 - val_loss: 65.3142\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.8250 - val_loss: 65.9958\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7028 - val_loss: 67.8831\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0880 - val_loss: 65.3883\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 98.3739 - val_loss: 67.2798\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2673 - val_loss: 62.0008\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4071 - val_loss: 70.9884\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2316 - val_loss: 76.9652\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.8191 - val_loss: 64.6470\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5506 - val_loss: 65.6776\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0182 - val_loss: 64.2534\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8442 - val_loss: 70.1469\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8476 - val_loss: 65.3247\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6024 - val_loss: 67.6005\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.5079 - val_loss: 63.1083\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6437 - val_loss: 73.5342\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2194 - val_loss: 69.3856\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.0355 - val_loss: 69.3319\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.1913 - val_loss: 64.7965\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.3415 - val_loss: 61.5203\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.4683 - val_loss: 70.0749\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0009 - val_loss: 65.0565\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4913 - val_loss: 103.9252\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2183 - val_loss: 63.5236\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2764 - val_loss: 62.8731\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4159 - val_loss: 64.2155\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8173 - val_loss: 62.7220\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2391 - val_loss: 62.3201\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4951 - val_loss: 62.9365\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6119 - val_loss: 67.4213\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.5104 - val_loss: 63.9494\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4892 - val_loss: 63.1090\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5793 - val_loss: 66.4863\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9468 - val_loss: 73.3872\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.6047 - val_loss: 64.0559\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.2846 - val_loss: 70.4834\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 117.2918 - val_loss: 67.6935\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.3924 - val_loss: 62.3634\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5438 - val_loss: 67.8875\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0158 - val_loss: 62.3482\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3760 - val_loss: 70.5628\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5452 - val_loss: 60.3361\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1437 - val_loss: 79.4095\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1588 - val_loss: 66.6803\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1196 - val_loss: 67.7302\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.9560 - val_loss: 68.2370\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9797 - val_loss: 63.9002\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.8596 - val_loss: 70.4595\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.8693 - val_loss: 63.9138\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3925 - val_loss: 68.0272\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.6114 - val_loss: 62.2281\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2790 - val_loss: 78.7810\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.4123 - val_loss: 70.4529\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4368 - val_loss: 65.6290\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.5233 - val_loss: 65.3932\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 73.4700 - val_loss: 61.9311\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.4060 - val_loss: 60.6957\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4270 - val_loss: 65.9662\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.6814 - val_loss: 66.5456\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.4971 - val_loss: 65.9621\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0678 - val_loss: 60.7962\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5878 - val_loss: 74.2439\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1030 - val_loss: 62.0559\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6366 - val_loss: 62.0727\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9457 - val_loss: 65.7772\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.4085 - val_loss: 74.0427\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2697 - val_loss: 67.1712\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.5072 - val_loss: 65.8813\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4792 - val_loss: 62.2405\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7853 - val_loss: 64.2842\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1905 - val_loss: 64.4358\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1708 - val_loss: 63.1506\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.6404 - val_loss: 67.8165\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.2286 - val_loss: 64.1993\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.7785 - val_loss: 72.6216\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.6044 - val_loss: 60.6685\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8306 - val_loss: 61.8573\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.8060 - val_loss: 62.7780\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4486 - val_loss: 61.7246\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8009 - val_loss: 63.6132\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4101 - val_loss: 61.6585\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.9786 - val_loss: 61.0157\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.9900 - val_loss: 75.8807\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.9960 - val_loss: 91.5431\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1254 - val_loss: 64.0665\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.7735 - val_loss: 65.3016\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.3610 - val_loss: 73.1746\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0633 - val_loss: 62.4667\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5532 - val_loss: 67.1817\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.7853 - val_loss: 69.8967\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.5320 - val_loss: 63.5441\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.7958 - val_loss: 68.9276\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8733 - val_loss: 64.0945\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8478 - val_loss: 61.9525\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7781 - val_loss: 61.0970\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.1105 - val_loss: 69.6772\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.7819 - val_loss: 75.4035\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.0789 - val_loss: 60.8637\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.8614 - val_loss: 63.0799\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6408 - val_loss: 59.0976\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4756 - val_loss: 59.6261\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4688 - val_loss: 76.1091\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7911 - val_loss: 66.2667\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.3307 - val_loss: 61.7082\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.2921 - val_loss: 71.6356\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.1346 - val_loss: 65.4858\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1960 - val_loss: 67.6212\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7216 - val_loss: 70.5065\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1101 - val_loss: 66.9415\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4947 - val_loss: 66.5976\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4754 - val_loss: 61.5663\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2358 - val_loss: 98.0343\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 81.9515 - val_loss: 62.4750\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4246 - val_loss: 62.9928\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4452 - val_loss: 66.7011\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.4921 - val_loss: 67.0975\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0875 - val_loss: 61.7053\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.5684 - val_loss: 69.9476\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8668 - val_loss: 68.3601\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1102 - val_loss: 66.5881\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2874 - val_loss: 63.1010\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2056 - val_loss: 63.3850\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.3022 - val_loss: 68.0044\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5373 - val_loss: 64.3502\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.3669 - val_loss: 69.9728\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6414 - val_loss: 63.3384\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7824 - val_loss: 67.6829\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1495 - val_loss: 61.0652\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9878 - val_loss: 75.6264\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2023 - val_loss: 70.7649\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9498 - val_loss: 75.6764\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4061 - val_loss: 76.4916\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0532 - val_loss: 70.4413\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 58.8108\n",
      "--- Starting trial: run-42\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 128, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 18ms/step - loss: 689.7081 - val_loss: 660.2599\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5858 - val_loss: 660.1177\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4436 - val_loss: 659.9578\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2771 - val_loss: 659.7603\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0828 - val_loss: 659.5370\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8575 - val_loss: 659.2795\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5988 - val_loss: 658.9869\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3045 - val_loss: 658.6623\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.9730 - val_loss: 658.2949\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6027 - val_loss: 657.8969\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1927 - val_loss: 657.4472\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7422 - val_loss: 656.9563\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.2507 - val_loss: 656.4136\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.7170 - val_loss: 655.8340\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1411 - val_loss: 655.2135\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.5223 - val_loss: 654.5403\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.8607 - val_loss: 653.8346\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.1556 - val_loss: 653.1003\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.4070 - val_loss: 652.2856\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.6146 - val_loss: 651.4419\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.7786 - val_loss: 650.5609\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.8985 - val_loss: 649.6380\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.9744 - val_loss: 648.6645\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.0062 - val_loss: 647.6623\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.9940 - val_loss: 646.5869\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.9376 - val_loss: 645.4952\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.8372 - val_loss: 644.3279\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.6927 - val_loss: 643.1310\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.5043 - val_loss: 641.8828\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 671.2717 - val_loss: 640.5958\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.9952 - val_loss: 639.2625\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.6749 - val_loss: 637.8913\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.3109 - val_loss: 636.5048\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.9030 - val_loss: 635.0842\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.4515 - val_loss: 633.5676\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.9565 - val_loss: 632.0278\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.4180 - val_loss: 630.4597\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.8362 - val_loss: 628.8349\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.2111 - val_loss: 627.1508\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.5428 - val_loss: 625.4180\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.8316 - val_loss: 623.6782\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.0773 - val_loss: 621.8740\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.2801 - val_loss: 619.9759\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.4403 - val_loss: 618.0933\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.5577 - val_loss: 616.1181\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.6328 - val_loss: 614.1976\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.6654 - val_loss: 612.1785\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.6557 - val_loss: 610.0886\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.6039 - val_loss: 607.9822\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.5101 - val_loss: 605.8141\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.3743 - val_loss: 603.5632\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.1967 - val_loss: 601.3226\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.9774 - val_loss: 599.0458\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.7167 - val_loss: 596.7424\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.4143 - val_loss: 594.4134\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.0708 - val_loss: 592.1094\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.6859 - val_loss: 589.7041\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.2601 - val_loss: 587.1780\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.7933 - val_loss: 584.6657\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.2855 - val_loss: 582.1011\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 611.7371 - val_loss: 579.5729\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 609.1481 - val_loss: 576.9770\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.5186 - val_loss: 574.2873\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.8487 - val_loss: 571.5469\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.1385 - val_loss: 568.8125\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.3884 - val_loss: 566.0026\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.5981 - val_loss: 563.1823\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.7679 - val_loss: 560.2973\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.8981 - val_loss: 557.3530\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.9885 - val_loss: 554.4167\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.0394 - val_loss: 551.4456\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.0510 - val_loss: 548.4425\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.0232 - val_loss: 545.4756\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 575.0578 - val_loss: 554.7528\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.8666 - val_loss: 555.6208\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.7256 - val_loss: 552.9262\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.5433 - val_loss: 549.1968\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.3210 - val_loss: 545.2224\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 559.0598 - val_loss: 541.4187\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.7598 - val_loss: 537.5421\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.4214 - val_loss: 533.5915\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 549.0447 - val_loss: 529.5736\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.6298 - val_loss: 526.1169\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.2570 - val_loss: 534.0015\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 538.7038 - val_loss: 533.4435\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.1795 - val_loss: 530.1573\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.6146 - val_loss: 525.8100\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 528.0110 - val_loss: 520.9048\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 524.3694 - val_loss: 516.4794\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.6902 - val_loss: 511.9580\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 516.9736 - val_loss: 508.5743\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.2197 - val_loss: 504.0810\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.4289 - val_loss: 500.3444\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.6010 - val_loss: 496.3476\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.7364 - val_loss: 491.9682\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.8349 - val_loss: 487.7000\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.8968 - val_loss: 483.8585\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.9221 - val_loss: 480.2532\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.9109 - val_loss: 476.1376\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.8634 - val_loss: 471.4963\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.7798 - val_loss: 467.0589\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.6599 - val_loss: 462.9834\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.5042 - val_loss: 458.9243\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.3474 - val_loss: 461.3050\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.1046 - val_loss: 458.8367\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.8461 - val_loss: 454.7191\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.5490 - val_loss: 450.1140\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.2150 - val_loss: 444.5169\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.8451 - val_loss: 439.3613\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.4395 - val_loss: 434.4210\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.9987 - val_loss: 429.4479\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.6473 - val_loss: 428.3295\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 426.0258 - val_loss: 426.6624\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.9094 - val_loss: 433.2870\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.9465 - val_loss: 437.0415\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.3931 - val_loss: 435.1458\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.8192 - val_loss: 430.8483\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.4553 - val_loss: 426.1535\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.6463 - val_loss: 415.5980\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.0138 - val_loss: 406.1416\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.3481 - val_loss: 404.1531\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.9196 - val_loss: 401.6682\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.3505 - val_loss: 397.2025\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.0672 - val_loss: 390.0992\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.1802 - val_loss: 383.7847\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.2332 - val_loss: 377.4540\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 360.4372 - val_loss: 370.6730\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 355.2879 - val_loss: 364.4706\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.5753 - val_loss: 358.0106\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 345.2350 - val_loss: 351.6308\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 340.2227 - val_loss: 346.5778\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 335.7466 - val_loss: 342.3062\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.5252 - val_loss: 337.0320\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 326.2291 - val_loss: 331.3123\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 319.7556 - val_loss: 325.9898\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.8001 - val_loss: 320.4901\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.6000 - val_loss: 314.5054\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 304.5960 - val_loss: 308.6862\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 306.3321 - val_loss: 303.9069\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295.9235 - val_loss: 298.1844\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 290.0802 - val_loss: 295.6433\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.4803 - val_loss: 289.7595\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.3475 - val_loss: 281.5944\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 274.9144 - val_loss: 277.3713\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.8313 - val_loss: 270.4890\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.2898 - val_loss: 266.1966\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.9733 - val_loss: 258.5841\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.6259 - val_loss: 251.0929\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.5423 - val_loss: 248.2737\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.1311 - val_loss: 242.5117\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.8604 - val_loss: 235.3640\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.3455 - val_loss: 230.6555\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232.0655 - val_loss: 225.0826\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 223.4275 - val_loss: 221.3655\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 223.5604 - val_loss: 217.6734\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.0185 - val_loss: 213.5684\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.3111 - val_loss: 210.2722\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203.1151 - val_loss: 203.4419\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 197.2605 - val_loss: 193.4889\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.0599 - val_loss: 188.7763\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 197.7832 - val_loss: 182.9454\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.9140 - val_loss: 183.1114\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.7814 - val_loss: 182.5829\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 178.0419 - val_loss: 177.6760\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 166.4852 - val_loss: 170.2109\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 171.7921 - val_loss: 164.1712\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169.9005 - val_loss: 163.9303\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.8341 - val_loss: 159.0402\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 147.1531 - val_loss: 154.3987\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.4199 - val_loss: 152.0932\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 147.8903 - val_loss: 145.7966\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 139.6156 - val_loss: 138.9062\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.1255 - val_loss: 130.6021\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.8033 - val_loss: 126.3755\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.2728 - val_loss: 123.7481\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.4011 - val_loss: 121.3430\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.0030 - val_loss: 117.3099\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.9482 - val_loss: 117.2496\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.6583 - val_loss: 115.1973\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.7582 - val_loss: 114.3826\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.2756 - val_loss: 111.3932\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.0762 - val_loss: 107.7418\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5388 - val_loss: 105.8542\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4720 - val_loss: 100.9263\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3079 - val_loss: 96.6718\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4876 - val_loss: 93.6010\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8822 - val_loss: 90.8277\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.3975 - val_loss: 92.5340\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.6254 - val_loss: 88.4901\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4940 - val_loss: 86.2524\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7641 - val_loss: 89.3405\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9965 - val_loss: 87.1717\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4996 - val_loss: 90.9555\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.8736 - val_loss: 83.6686\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.9181 - val_loss: 83.4920\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.7305 - val_loss: 81.5388\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4764 - val_loss: 83.4015\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2748 - val_loss: 79.4067\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5702 - val_loss: 79.3051\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0062 - val_loss: 86.5617\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.1837 - val_loss: 77.6429\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 81.9609 - val_loss: 75.8674\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.1805 - val_loss: 70.5345\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2744 - val_loss: 69.2258\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.5923 - val_loss: 70.3358\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9048 - val_loss: 79.3115\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4815 - val_loss: 75.5257\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.1757 - val_loss: 66.9927\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6538 - val_loss: 68.0767\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.5312 - val_loss: 65.9890\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.0083 - val_loss: 66.9368\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3245 - val_loss: 68.9134\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9294 - val_loss: 76.3672\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6729 - val_loss: 81.8232\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.0127 - val_loss: 84.2416\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1553 - val_loss: 86.9396\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.4340 - val_loss: 84.3119\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.9665 - val_loss: 72.6667\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4361 - val_loss: 69.5624\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2827 - val_loss: 73.2806\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.7547 - val_loss: 75.0084\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8553 - val_loss: 72.7506\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 84.2256 - val_loss: 71.9642\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6196 - val_loss: 70.5033\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.3937 - val_loss: 68.4764\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1878 - val_loss: 68.9455\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.7795 - val_loss: 71.2215\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5400 - val_loss: 72.3928\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1352 - val_loss: 69.6854\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1935 - val_loss: 65.7185\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2440 - val_loss: 64.2191\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3233 - val_loss: 63.9650\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.3283 - val_loss: 68.8484\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.1231 - val_loss: 69.9765\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2623 - val_loss: 69.3043\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5488 - val_loss: 64.2612\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3964 - val_loss: 65.4628\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9815 - val_loss: 64.9037\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7540 - val_loss: 64.0909\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5751 - val_loss: 62.4552\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7993 - val_loss: 65.2330\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.5249 - val_loss: 66.1465\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6390 - val_loss: 64.1491\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.5025 - val_loss: 64.7387\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7810 - val_loss: 65.4867\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.1816 - val_loss: 65.8108\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4716 - val_loss: 63.5414\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.4329 - val_loss: 64.0494\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2347 - val_loss: 68.9161\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.5009 - val_loss: 71.8165\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 55.8858\n",
      "--- Starting trial: run-43\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 128, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 14ms/step - loss: 689.6597 - val_loss: 660.1768\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4244 - val_loss: 659.9409\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1839 - val_loss: 659.6976\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9338 - val_loss: 659.4340\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6700 - val_loss: 659.1539\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3879 - val_loss: 658.8679\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.0822 - val_loss: 658.5315\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7470 - val_loss: 658.1693\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3761 - val_loss: 657.7750\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9619 - val_loss: 657.3375\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4960 - val_loss: 656.8433\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.9685 - val_loss: 656.2883\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3682 - val_loss: 655.6280\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.6817 - val_loss: 654.8705\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.8936 - val_loss: 654.0061\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.9860 - val_loss: 653.0179\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.9378 - val_loss: 651.8787\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.7245 - val_loss: 650.5427\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.3173 - val_loss: 648.9914\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.6824 - val_loss: 647.1853\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.7803 - val_loss: 645.1030\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.5647 - val_loss: 642.6874\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.9815 - val_loss: 639.8724\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.9671 - val_loss: 636.5671\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 664.4468 - val_loss: 632.6780\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.3333 - val_loss: 628.1640\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.5243 - val_loss: 622.8782\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.8994 - val_loss: 616.6911\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.3180 - val_loss: 609.4064\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.6149 - val_loss: 600.8889\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.5964 - val_loss: 590.9720\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.0355 - val_loss: 579.3672\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.6660 - val_loss: 565.7010\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.2249 - val_loss: 550.6490\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.3529 - val_loss: 532.3425\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.7468 - val_loss: 512.3968\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 529.9813 - val_loss: 490.1705\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.1979 - val_loss: 465.6559\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 472.3448 - val_loss: 435.2379\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.5746 - val_loss: 409.1637\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.1999 - val_loss: 378.0905\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.5684 - val_loss: 340.1302\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 327.9128 - val_loss: 313.0833\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 299.0459 - val_loss: 273.5774\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 262.8728 - val_loss: 255.5941\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.1438 - val_loss: 229.1914\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.3183 - val_loss: 255.1365\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.4051 - val_loss: 290.4507\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 154.6753 - val_loss: 275.0208\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.1066 - val_loss: 342.3802\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2724 - val_loss: 388.2610\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.3891 - val_loss: 341.9737\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6559 - val_loss: 311.4395\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.9516 - val_loss: 393.2507\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.8934 - val_loss: 262.6788\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1773 - val_loss: 314.0317\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9582 - val_loss: 236.7050\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.7697 - val_loss: 253.8222\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9318 - val_loss: 203.7533\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2144 - val_loss: 223.7653\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.0368 - val_loss: 215.0704\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5658 - val_loss: 231.9014\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3563 - val_loss: 264.9425\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6182 - val_loss: 262.5146\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3775 - val_loss: 183.0970\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6576 - val_loss: 168.3689\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7329 - val_loss: 143.4377\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2576 - val_loss: 132.0650\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.6553 - val_loss: 137.3321\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7950 - val_loss: 135.8612\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6203 - val_loss: 198.0329\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0344 - val_loss: 131.9952\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.6022 - val_loss: 168.2426\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3186 - val_loss: 167.9224\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 108.0506 - val_loss: 138.6343\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 70.3122 - val_loss: 105.3966\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7511 - val_loss: 148.1895\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6912 - val_loss: 149.4081\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.0171 - val_loss: 136.7913\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.8450 - val_loss: 114.2264\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1240 - val_loss: 129.7919\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3957 - val_loss: 113.0411\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8330 - val_loss: 108.2112\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9091 - val_loss: 76.7617\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0294 - val_loss: 127.3847\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3367 - val_loss: 98.2318\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4279 - val_loss: 89.3921\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2379 - val_loss: 78.3616\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4849 - val_loss: 98.2027\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6574 - val_loss: 82.4746\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8754 - val_loss: 100.7575\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4310 - val_loss: 86.3867\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.2468 - val_loss: 89.0685\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0528 - val_loss: 108.4747\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.5491 - val_loss: 65.1130\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2252 - val_loss: 74.5691\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6423 - val_loss: 80.5794\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.0697 - val_loss: 76.0798\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7033 - val_loss: 73.8924\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9401 - val_loss: 93.9012\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 70.2350 - val_loss: 76.8555\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.3431 - val_loss: 92.2432\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8445 - val_loss: 72.5423\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0299 - val_loss: 88.8896\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0962 - val_loss: 79.9412\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4126 - val_loss: 82.1158\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3708 - val_loss: 70.3367\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8847 - val_loss: 70.8863\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1939 - val_loss: 73.2673\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4645 - val_loss: 72.1885\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6043 - val_loss: 67.0084\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.7478 - val_loss: 70.2273\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2190 - val_loss: 78.4506\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.8791 - val_loss: 70.0448\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3588 - val_loss: 74.2239\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.6240 - val_loss: 78.0411\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3264 - val_loss: 77.2655\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0615 - val_loss: 103.9384\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8037 - val_loss: 88.8276\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.5727 - val_loss: 70.9756\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1920 - val_loss: 74.7824\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.9319 - val_loss: 71.2531\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7202 - val_loss: 90.5375\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4238 - val_loss: 77.5393\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7639 - val_loss: 84.8268\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.5486 - val_loss: 87.6377\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.5807 - val_loss: 76.2347\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0919 - val_loss: 76.5265\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.7839 - val_loss: 70.7114\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0274 - val_loss: 68.2738\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 94.0085 - val_loss: 68.0408\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.5114 - val_loss: 67.1483\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2222 - val_loss: 71.4754\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1711 - val_loss: 68.0395\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9176 - val_loss: 67.5157\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6201 - val_loss: 73.6747\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6757 - val_loss: 71.6942\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2116 - val_loss: 74.4420\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.7838 - val_loss: 75.1719\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.9742 - val_loss: 92.3713\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8112 - val_loss: 73.2309\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6228 - val_loss: 85.0433\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7325 - val_loss: 72.6296\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1537 - val_loss: 69.5706\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7908 - val_loss: 75.4027\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5199 - val_loss: 62.2258\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.6818 - val_loss: 62.2771\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7046 - val_loss: 72.4591\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.0419 - val_loss: 69.4583\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8269 - val_loss: 68.4591\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.0350 - val_loss: 73.2608\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6517 - val_loss: 72.7908\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1300 - val_loss: 66.1150\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2136 - val_loss: 62.8759\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0480 - val_loss: 61.2083\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.9085 - val_loss: 61.1381\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.0360 - val_loss: 65.7668\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.5806 - val_loss: 62.7228\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2390 - val_loss: 85.5091\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2099 - val_loss: 75.9215\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.7937 - val_loss: 70.6765\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5144 - val_loss: 68.2407\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9575 - val_loss: 63.3974\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3989 - val_loss: 63.7606\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 81.5684 - val_loss: 82.0493\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9424 - val_loss: 73.6885\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7329 - val_loss: 68.6394\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2235 - val_loss: 64.9184\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3863 - val_loss: 63.2182\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3918 - val_loss: 64.9038\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7813 - val_loss: 65.7086\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3981 - val_loss: 67.1127\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3094 - val_loss: 71.3001\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.2277 - val_loss: 74.6194\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5127 - val_loss: 66.1302\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3488 - val_loss: 63.0824\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7977 - val_loss: 66.2878\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7825 - val_loss: 69.2625\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3099 - val_loss: 74.5994\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8262 - val_loss: 67.4659\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6474 - val_loss: 69.8511\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9121 - val_loss: 62.2052\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9799 - val_loss: 73.1944\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5179 - val_loss: 68.8221\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5819 - val_loss: 68.7234\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0639 - val_loss: 82.1294\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.6115 - val_loss: 75.1487\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0626 - val_loss: 65.3234\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3285 - val_loss: 67.6739\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1549 - val_loss: 67.9467\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1178 - val_loss: 65.3732\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3381 - val_loss: 65.2377\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.8275 - val_loss: 61.3949\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 114.4124 - val_loss: 62.0470\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5601 - val_loss: 68.9522\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 67.9679 - val_loss: 70.7869\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8922 - val_loss: 80.8303\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 86.7681 - val_loss: 79.7655\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9030 - val_loss: 84.1360\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0987 - val_loss: 72.4616\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7167 - val_loss: 65.0992\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.8038 - val_loss: 65.7577\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4781 - val_loss: 72.1172\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7270 - val_loss: 63.2480\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8429 - val_loss: 62.9000\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9358 - val_loss: 64.1023\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.6834 - val_loss: 65.9042\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.5977 - val_loss: 63.3507\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1110 - val_loss: 75.6178\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2939 - val_loss: 62.4181\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0136 - val_loss: 67.9844\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4838 - val_loss: 70.6542\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9056 - val_loss: 71.0625\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.2287 - val_loss: 63.1133\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1815 - val_loss: 62.7204\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2806 - val_loss: 66.5974\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2566 - val_loss: 64.3954\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2580 - val_loss: 63.3835\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.8803 - val_loss: 68.1696\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2217 - val_loss: 72.4864\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3249 - val_loss: 71.0570\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0168 - val_loss: 72.6951\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1861 - val_loss: 70.5862\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.4560 - val_loss: 68.2049\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.1592 - val_loss: 72.6837\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2958 - val_loss: 77.1369\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4530 - val_loss: 71.1188\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2713 - val_loss: 74.8089\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.7354 - val_loss: 68.6539\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.0630 - val_loss: 74.3079\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 82.1789 - val_loss: 67.7043\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.6580 - val_loss: 65.1879\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.9497 - val_loss: 65.4953\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2066 - val_loss: 71.6883\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.8885 - val_loss: 67.1685\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.5945 - val_loss: 63.1676\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1270 - val_loss: 62.0922\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.4772 - val_loss: 66.1615\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9049 - val_loss: 64.1339\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4896 - val_loss: 69.9990\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.3273 - val_loss: 64.3875\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8286 - val_loss: 71.0853\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5049 - val_loss: 66.0908\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.0848 - val_loss: 65.1401\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4691 - val_loss: 65.7961\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4687 - val_loss: 64.5611\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8268 - val_loss: 65.2443\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.1221 - val_loss: 62.9032\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.0008 - val_loss: 62.7660\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.5205 - val_loss: 67.4315\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 46.4031\n",
      "--- Starting trial: run-44\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 128, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 16ms/step - loss: 689.7045 - val_loss: 660.7448\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5730 - val_loss: 660.5547\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4217 - val_loss: 660.3462\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2460 - val_loss: 660.1112\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.0429 - val_loss: 659.8329\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.8090 - val_loss: 659.5118\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5418 - val_loss: 659.1642\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2394 - val_loss: 658.7648\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8999 - val_loss: 658.3223\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5222 - val_loss: 657.8456\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1052 - val_loss: 657.3154\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6479 - val_loss: 656.7401\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1497 - val_loss: 656.1414\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6101 - val_loss: 655.5011\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0283 - val_loss: 654.8127\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.4041 - val_loss: 654.0740\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.7371 - val_loss: 653.2783\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.0270 - val_loss: 652.4784\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.2739 - val_loss: 651.6212\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.4771 - val_loss: 650.7224\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.6366 - val_loss: 649.7520\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.7526 - val_loss: 648.7619\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.8246 - val_loss: 647.7566\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.8528 - val_loss: 646.7271\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.8372 - val_loss: 645.6201\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.7775 - val_loss: 644.5314\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6740 - val_loss: 643.3492\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.5265 - val_loss: 642.1230\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.3352 - val_loss: 640.8644\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.1000 - val_loss: 639.5036\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.8210 - val_loss: 638.1525\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.4984 - val_loss: 636.7769\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.1319 - val_loss: 635.2891\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.7218 - val_loss: 633.8437\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.2682 - val_loss: 632.3183\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.7712 - val_loss: 630.7256\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.2309 - val_loss: 629.1688\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.6471 - val_loss: 627.6055\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.0203 - val_loss: 626.0039\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 656.3503 - val_loss: 624.4440\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.6374 - val_loss: 622.7625\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.8816 - val_loss: 621.0112\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.0829 - val_loss: 619.2961\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.2416 - val_loss: 617.5278\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.3578 - val_loss: 615.7396\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.4315 - val_loss: 613.8917\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.4628 - val_loss: 611.9200\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.4520 - val_loss: 609.8860\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.3990 - val_loss: 607.7532\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.3039 - val_loss: 605.6548\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.1671 - val_loss: 603.5460\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.9885 - val_loss: 601.4026\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.7681 - val_loss: 599.2985\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.5063 - val_loss: 597.2353\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.2030 - val_loss: 595.1430\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.8585 - val_loss: 592.8386\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.4727 - val_loss: 590.3634\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.0460 - val_loss: 587.7960\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.5783 - val_loss: 585.3073\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.0698 - val_loss: 582.7861\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.5206 - val_loss: 580.2888\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.9307 - val_loss: 577.7264\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.3004 - val_loss: 575.1303\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.6298 - val_loss: 572.5672\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.9189 - val_loss: 569.6870\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.1679 - val_loss: 566.7466\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 595.3770 - val_loss: 563.5224\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.5461 - val_loss: 560.5840\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.6755 - val_loss: 557.7599\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.7652 - val_loss: 554.8024\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.8155 - val_loss: 551.8416\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 580.8263 - val_loss: 549.0606\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.7979 - val_loss: 546.2368\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.7302 - val_loss: 543.1324\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.6235 - val_loss: 540.1511\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.4778 - val_loss: 537.1570\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.5639 - val_loss: 535.2794\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.0823 - val_loss: 540.7676\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.8281 - val_loss: 541.8757\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.5309 - val_loss: 539.8914\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.1931 - val_loss: 536.7151\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.8409 - val_loss: 532.1052\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.4145 - val_loss: 529.2611\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.9678 - val_loss: 525.8261\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.4789 - val_loss: 521.8401\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.9504 - val_loss: 517.4668\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.3835 - val_loss: 513.0665\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.7957 - val_loss: 510.1472\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 524.1622 - val_loss: 514.3236\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.5106 - val_loss: 513.5002\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 516.8049 - val_loss: 509.9770\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.0548 - val_loss: 505.6277\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.2646 - val_loss: 501.0041\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.4362 - val_loss: 496.2324\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.6238 - val_loss: 494.9750\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.6845 - val_loss: 492.9711\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.8353 - val_loss: 488.9207\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 489.7954 - val_loss: 484.9016\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.7891 - val_loss: 480.7581\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.7424 - val_loss: 476.0593\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.6577 - val_loss: 471.7487\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.5360 - val_loss: 467.0015\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 469.3781 - val_loss: 462.6089\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 465.2300 - val_loss: 459.0011\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 461.0645 - val_loss: 451.8884\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.8516 - val_loss: 450.5024\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.6586 - val_loss: 453.6380\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.2359 - val_loss: 463.2407\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.8939 - val_loss: 463.6073\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.9175 - val_loss: 460.2378\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.6956 - val_loss: 453.5709\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.6897 - val_loss: 437.4886\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 426.2705 - val_loss: 427.0044\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.8906 - val_loss: 422.7741\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.3984 - val_loss: 423.0304\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 412.6543 - val_loss: 420.3130\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.0191 - val_loss: 415.3007\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.7663 - val_loss: 405.6061\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.0494 - val_loss: 398.6341\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 394.0139 - val_loss: 387.0382\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 390.6374 - val_loss: 383.3418\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.7381 - val_loss: 380.6764\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 380.3718 - val_loss: 378.0422\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.8829 - val_loss: 374.4997\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.4181 - val_loss: 377.7317\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 370.6968 - val_loss: 380.1367\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 362.1003 - val_loss: 378.3333\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.8184 - val_loss: 376.6351\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 352.8387 - val_loss: 378.7929\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347.0269 - val_loss: 374.1198\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 342.2259 - val_loss: 367.0077\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.9259 - val_loss: 365.3158\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.0831 - val_loss: 368.4973\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 330.0272 - val_loss: 365.0153\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 327.7332 - val_loss: 357.1681\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 318.2134 - val_loss: 347.6026\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 313.4479 - val_loss: 338.8612\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 308.3526 - val_loss: 335.7343\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 306.6257 - val_loss: 334.7695\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.1144 - val_loss: 331.6598\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.9142 - val_loss: 327.1257\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.4006 - val_loss: 324.9354\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 286.4248 - val_loss: 321.6722\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.4667 - val_loss: 314.9728\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 275.5015 - val_loss: 309.1127\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.3534 - val_loss: 301.9211\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.7268 - val_loss: 295.2433\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.5841 - val_loss: 291.3750\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.4776 - val_loss: 288.5036\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 252.7793 - val_loss: 281.9104\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.0647 - val_loss: 272.3581\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 242.9429 - val_loss: 265.0735\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.2781 - val_loss: 260.0332\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 232.7118 - val_loss: 257.4857\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 231.4003 - val_loss: 251.3321\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.1302 - val_loss: 241.7339\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.9705 - val_loss: 230.2522\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.9324 - val_loss: 225.8104\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 217.3968 - val_loss: 221.2647\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 203.9387 - val_loss: 221.8674\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 205.1200 - val_loss: 220.4559\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 196.0355 - val_loss: 216.4181\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 201.2775 - val_loss: 210.1138\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.6534 - val_loss: 205.2181\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.9618 - val_loss: 201.4718\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.5085 - val_loss: 199.4940\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169.3552 - val_loss: 196.3290\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 179.2282 - val_loss: 189.3775\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 176.0969 - val_loss: 185.2556\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.5387 - val_loss: 184.0571\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.7637 - val_loss: 179.5625\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.6310 - val_loss: 172.7494\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 161.1500 - val_loss: 164.5724\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.0106 - val_loss: 158.7594\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.9337 - val_loss: 154.9131\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.9749 - val_loss: 151.5037\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 146.7686 - val_loss: 149.6376\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.8380 - val_loss: 148.1074\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.0438 - val_loss: 147.4602\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.9724 - val_loss: 147.6026\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.7602 - val_loss: 147.0988\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.4419 - val_loss: 146.3755\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.3670 - val_loss: 141.5166\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.4959 - val_loss: 133.8610\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115.6048 - val_loss: 127.3477\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 106.6271 - val_loss: 120.1236\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.3175 - val_loss: 118.9012\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.9424 - val_loss: 116.3308\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.5379 - val_loss: 114.8838\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1060 - val_loss: 113.8962\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8085 - val_loss: 109.4808\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5149 - val_loss: 111.1861\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1023 - val_loss: 110.6313\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.0954 - val_loss: 113.8990\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4363 - val_loss: 106.2792\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.9590 - val_loss: 101.6516\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1792 - val_loss: 103.3359\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8018 - val_loss: 97.6157\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0472 - val_loss: 90.0198\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1347 - val_loss: 96.5386\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6889 - val_loss: 106.0860\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2910 - val_loss: 96.8112\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1085 - val_loss: 85.8680\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0338 - val_loss: 83.8147\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4188 - val_loss: 90.5670\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4254 - val_loss: 96.1897\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.2998 - val_loss: 88.0594\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.2812 - val_loss: 78.2617\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.5746 - val_loss: 72.4339\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7415 - val_loss: 71.7726\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.4344 - val_loss: 75.9547\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.5679 - val_loss: 81.5448\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.7978 - val_loss: 80.0886\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.1807 - val_loss: 73.3296\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0695 - val_loss: 70.7616\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6804 - val_loss: 73.4116\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4088 - val_loss: 73.7730\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7729 - val_loss: 64.7054\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4418 - val_loss: 58.8873\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7989 - val_loss: 58.0094\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8506 - val_loss: 58.3423\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1135 - val_loss: 62.2127\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.8311 - val_loss: 60.9591\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.7697 - val_loss: 64.2745\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1529 - val_loss: 67.2896\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.9565 - val_loss: 63.7128\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0012 - val_loss: 60.0274\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2578 - val_loss: 58.0464\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6616 - val_loss: 57.5045\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1524 - val_loss: 58.7086\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.2367 - val_loss: 61.1368\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2163 - val_loss: 62.6614\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1143 - val_loss: 61.9459\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4134 - val_loss: 65.6670\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5945 - val_loss: 69.2115\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2159 - val_loss: 69.5955\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.5659 - val_loss: 62.6761\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3683 - val_loss: 60.5382\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.9660 - val_loss: 60.4185\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2729 - val_loss: 63.7730\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.7637 - val_loss: 64.4127\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1410 - val_loss: 65.2331\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1633 - val_loss: 65.4855\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0107 - val_loss: 65.7553\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3584 - val_loss: 62.0875\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0128 - val_loss: 61.4350\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2295 - val_loss: 62.5292\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.4351 - val_loss: 62.6981\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5561 - val_loss: 65.9173\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5173 - val_loss: 62.4096\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 27.8721\n",
      "--- Starting trial: run-45\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 128, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6647 - val_loss: 660.1425\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4419 - val_loss: 659.9489\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2142 - val_loss: 659.7469\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.9779 - val_loss: 659.5366\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7290 - val_loss: 659.3083\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4631 - val_loss: 659.0538\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1755 - val_loss: 658.7804\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8609 - val_loss: 658.4637\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5134 - val_loss: 658.1205\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1262 - val_loss: 657.7280\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 686.6913 - val_loss: 657.2845\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1998 - val_loss: 656.7863\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6415 - val_loss: 656.2123\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0038 - val_loss: 655.5534\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.2729 - val_loss: 654.7843\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.4319 - val_loss: 653.8895\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.4617 - val_loss: 652.8661\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.3397 - val_loss: 651.6756\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.0394 - val_loss: 650.3088\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.5298 - val_loss: 648.6881\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.7745 - val_loss: 646.8049\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.7311 - val_loss: 644.5951\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.3495 - val_loss: 642.0278\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.5715 - val_loss: 639.0228\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.3286 - val_loss: 635.5003\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.5399 - val_loss: 631.3898\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.1119 - val_loss: 626.5701\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 652.9339 - val_loss: 620.9260\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 646.8762 - val_loss: 614.3085\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.7874 - val_loss: 606.5938\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.4891 - val_loss: 597.5278\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.7726 - val_loss: 586.8851\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.3932 - val_loss: 574.4698\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 597.0640 - val_loss: 559.9174\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.5879 - val_loss: 543.7125\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.3194 - val_loss: 524.1381\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 542.4490 - val_loss: 503.7484\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 517.9580 - val_loss: 480.5491\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 490.6848 - val_loss: 457.9831\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 458.5696 - val_loss: 422.5430\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 426.8955 - val_loss: 411.2816\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.5439 - val_loss: 371.3059\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 353.3652 - val_loss: 347.9730\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.8572 - val_loss: 322.5232\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.4306 - val_loss: 319.2922\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.0387 - val_loss: 294.0796\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.4228 - val_loss: 284.2769\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.1701 - val_loss: 278.0215\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 193.4380 - val_loss: 225.7677\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 157.2038 - val_loss: 217.6549\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.9318 - val_loss: 238.0675\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.3138 - val_loss: 224.9957\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.2416 - val_loss: 253.4950\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.5748 - val_loss: 195.9734\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.0452 - val_loss: 230.9297\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.6114 - val_loss: 175.5728\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0980 - val_loss: 254.2787\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0145 - val_loss: 181.2001\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2175 - val_loss: 225.3664\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7036 - val_loss: 179.3238\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0631 - val_loss: 174.0654\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3142 - val_loss: 197.6822\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4226 - val_loss: 181.2680\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7334 - val_loss: 154.2357\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.5191 - val_loss: 116.5228\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6124 - val_loss: 124.7336\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 70.2798 - val_loss: 151.0830\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0067 - val_loss: 165.0968\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6751 - val_loss: 124.6283\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7813 - val_loss: 131.1886\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7392 - val_loss: 161.8612\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2675 - val_loss: 142.4579\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0832 - val_loss: 127.6729\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.3131 - val_loss: 114.7990\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 99.1257 - val_loss: 118.0297\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.6411 - val_loss: 98.9146\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3209 - val_loss: 83.5661\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9557 - val_loss: 94.9108\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5318 - val_loss: 81.6233\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2991 - val_loss: 72.7401\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2892 - val_loss: 87.4633\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.7935 - val_loss: 75.5886\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7476 - val_loss: 98.8914\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.3208 - val_loss: 75.9952\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4278 - val_loss: 88.5854\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 80.0362 - val_loss: 114.4457\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.4348 - val_loss: 99.0122\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0802 - val_loss: 95.9174\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7115 - val_loss: 91.8404\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5853 - val_loss: 98.2430\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5618 - val_loss: 93.9750\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1447 - val_loss: 74.8618\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 67.1992 - val_loss: 84.3037\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.2163 - val_loss: 77.4359\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.9336 - val_loss: 76.9967\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.9801 - val_loss: 85.7058\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 63.0287 - val_loss: 95.5260\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.2737 - val_loss: 83.2860\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.3088 - val_loss: 81.1558\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.7937 - val_loss: 73.7782\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4204 - val_loss: 66.1589\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.4494 - val_loss: 71.5081\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.7821 - val_loss: 68.6167\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 93.6403 - val_loss: 65.0392\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 78.0726 - val_loss: 71.4309\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7524 - val_loss: 73.0154\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2691 - val_loss: 72.0029\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5079 - val_loss: 82.3145\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6576 - val_loss: 68.6555\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.5793 - val_loss: 71.2521\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.2510 - val_loss: 70.0664\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3248 - val_loss: 64.4703\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4546 - val_loss: 62.7326\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0726 - val_loss: 68.8386\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.1247 - val_loss: 70.5452\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.0960 - val_loss: 68.2910\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9480 - val_loss: 67.9268\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7654 - val_loss: 72.8942\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9604 - val_loss: 65.6943\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.7986 - val_loss: 63.0546\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.6526 - val_loss: 61.9770\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6702 - val_loss: 73.9507\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8088 - val_loss: 65.9041\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 79.7738 - val_loss: 63.4717\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.5184 - val_loss: 66.5398\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.7298 - val_loss: 68.2986\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9323 - val_loss: 65.8936\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7184 - val_loss: 75.5133\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.7654 - val_loss: 76.7538\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8864 - val_loss: 72.2175\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 65.9645 - val_loss: 66.7824\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.9993 - val_loss: 60.4912\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 76.2309 - val_loss: 62.2769\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3176 - val_loss: 59.0854\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1612 - val_loss: 65.2740\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.9996 - val_loss: 64.4939\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.3996 - val_loss: 69.9647\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5180 - val_loss: 64.5229\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5750 - val_loss: 65.1376\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4173 - val_loss: 65.1424\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8705 - val_loss: 64.6220\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.3940 - val_loss: 60.3485\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7367 - val_loss: 63.8104\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.1253 - val_loss: 65.1706\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8046 - val_loss: 63.4777\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3550 - val_loss: 67.0058\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1413 - val_loss: 61.6739\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.5737 - val_loss: 63.2489\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.9646 - val_loss: 72.0621\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4049 - val_loss: 61.5121\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9505 - val_loss: 67.6841\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0468 - val_loss: 64.9730\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5910 - val_loss: 69.0299\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.1876 - val_loss: 67.8191\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.3652 - val_loss: 66.2095\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3221 - val_loss: 59.6206\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.4179 - val_loss: 60.6208\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7136 - val_loss: 63.7520\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8000 - val_loss: 65.7461\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8397 - val_loss: 63.0023\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.3767 - val_loss: 62.9029\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.9302 - val_loss: 63.1512\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.2514 - val_loss: 83.3700\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 147.5062 - val_loss: 73.6412\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.4957 - val_loss: 68.4954\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.9850 - val_loss: 70.5616\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.5562 - val_loss: 66.0329\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0810 - val_loss: 62.1899\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 84.6085 - val_loss: 63.9037\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2610 - val_loss: 70.5008\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.7881 - val_loss: 63.1587\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0615 - val_loss: 84.7507\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3527 - val_loss: 64.1838\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1932 - val_loss: 67.3995\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4010 - val_loss: 58.3963\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4107 - val_loss: 62.1931\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4313 - val_loss: 62.5077\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.1501 - val_loss: 60.2731\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9406 - val_loss: 62.0735\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0993 - val_loss: 62.2701\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1362 - val_loss: 63.7404\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7411 - val_loss: 65.3517\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7776 - val_loss: 59.8728\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8821 - val_loss: 65.0415\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0262 - val_loss: 62.1276\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.4394 - val_loss: 69.2066\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.1609 - val_loss: 57.5440\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.9401 - val_loss: 63.5156\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5416 - val_loss: 67.6487\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.0993 - val_loss: 57.7005\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6148 - val_loss: 57.8124\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3315 - val_loss: 59.3390\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.4948 - val_loss: 60.0782\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.9651 - val_loss: 61.9117\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.7830 - val_loss: 57.4231\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1353 - val_loss: 60.0381\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0645 - val_loss: 66.2300\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0789 - val_loss: 64.7799\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.7602 - val_loss: 63.7842\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2369 - val_loss: 64.3492\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5788 - val_loss: 65.8756\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.2916 - val_loss: 61.4517\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3539 - val_loss: 63.5007\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.4521 - val_loss: 57.6787\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.4079 - val_loss: 63.6528\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.4290 - val_loss: 58.1167\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5053 - val_loss: 60.4391\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.8563 - val_loss: 59.0496\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2095 - val_loss: 62.9841\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.8831 - val_loss: 58.5950\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.4541 - val_loss: 60.2264\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.5062 - val_loss: 61.5019\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.4355 - val_loss: 60.5919\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.5539 - val_loss: 62.2832\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.5046 - val_loss: 68.2493\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4503 - val_loss: 68.5520\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.8936 - val_loss: 62.7077\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.1348 - val_loss: 59.7872\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4239 - val_loss: 59.3675\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0656 - val_loss: 61.7897\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.9363 - val_loss: 62.9258\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9626 - val_loss: 56.8055\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.4479 - val_loss: 59.4493\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.5139 - val_loss: 60.8194\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.3522 - val_loss: 67.2158\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.7124 - val_loss: 64.3352\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0014 - val_loss: 57.7458\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.6986 - val_loss: 61.3290\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2048 - val_loss: 67.8524\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0871 - val_loss: 57.0054\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.1431 - val_loss: 61.0538\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4908 - val_loss: 61.1684\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.2543 - val_loss: 60.8503\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4644 - val_loss: 61.2079\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.9058 - val_loss: 59.8617\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3517 - val_loss: 65.2585\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3559 - val_loss: 61.1392\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1655 - val_loss: 70.8097\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5446 - val_loss: 63.9848\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.8538 - val_loss: 63.1867\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.4885 - val_loss: 70.0219\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4088 - val_loss: 62.5915\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.4962 - val_loss: 63.3638\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.7442 - val_loss: 66.5532\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9077 - val_loss: 60.4980\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4303 - val_loss: 68.5732\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7146 - val_loss: 59.9186\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4326 - val_loss: 57.3844\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.2876 - val_loss: 59.5528\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.2170 - val_loss: 66.3953\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 33.6256\n",
      "--- Starting trial: run-46\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 128, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 16ms/step - loss: 689.7037 - val_loss: 659.7930\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5703 - val_loss: 659.6474\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4170 - val_loss: 659.4821\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.2396 - val_loss: 659.2825\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.0347 - val_loss: 659.0565\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7991 - val_loss: 658.7978\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.5303 - val_loss: 658.4943\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2264 - val_loss: 658.1619\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 687.8857 - val_loss: 657.7847\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5070 - val_loss: 657.3706\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0890 - val_loss: 656.9193\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6309 - val_loss: 656.4271\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1321 - val_loss: 655.9033\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.5918 - val_loss: 655.3179\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0096 - val_loss: 654.7162\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3851 - val_loss: 654.0573\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 683.7180 - val_loss: 653.3380\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.0078 - val_loss: 652.5914\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.2545 - val_loss: 651.8203\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.4576 - val_loss: 650.9911\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.6174 - val_loss: 650.1214\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.7335 - val_loss: 649.2239\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.8058 - val_loss: 648.2633\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.8342 - val_loss: 647.2847\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.8189 - val_loss: 646.2140\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.7595 - val_loss: 645.1517\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.6564 - val_loss: 643.9913\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.5094 - val_loss: 642.8184\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.3186 - val_loss: 641.5990\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.0838 - val_loss: 640.3113\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.8053 - val_loss: 639.0204\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.4832 - val_loss: 637.6917\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.1172 - val_loss: 636.3452\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.7078 - val_loss: 634.9899\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.2549 - val_loss: 633.5549\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.7584 - val_loss: 632.0085\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.2186 - val_loss: 630.4555\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659.6354 - val_loss: 628.8665\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.0092 - val_loss: 627.2692\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 656.3399 - val_loss: 625.6450\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 654.6274 - val_loss: 623.8678\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.8723 - val_loss: 622.0255\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.0743 - val_loss: 620.1548\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.2336 - val_loss: 618.2608\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 647.3503 - val_loss: 616.3383\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.4247 - val_loss: 614.4486\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.4567 - val_loss: 612.4712\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.4464 - val_loss: 610.4362\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 639.3940 - val_loss: 608.3554\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.2997 - val_loss: 606.2442\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 635.1635 - val_loss: 604.1507\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.9855 - val_loss: 601.9377\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.7657 - val_loss: 599.6907\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.5045 - val_loss: 597.5291\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.2018 - val_loss: 595.2034\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.8579 - val_loss: 592.8311\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.4728 - val_loss: 590.3604\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.0466 - val_loss: 587.8706\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.5795 - val_loss: 585.3558\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.0715 - val_loss: 582.8109\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.5228 - val_loss: 580.2883\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.9337 - val_loss: 577.7115\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.3039 - val_loss: 575.1595\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.6338 - val_loss: 572.5343\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.9235 - val_loss: 569.8119\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.1731 - val_loss: 567.0551\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.3827 - val_loss: 564.2737\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.5524 - val_loss: 561.4525\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 589.6823 - val_loss: 558.4999\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.7726 - val_loss: 555.7585\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.8234 - val_loss: 552.7029\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.8347 - val_loss: 549.7338\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.8068 - val_loss: 546.8557\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.7396 - val_loss: 543.7354\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.7300 - val_loss: 542.9496\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 568.5009 - val_loss: 541.8945\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 565.3232 - val_loss: 539.3531\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.1029 - val_loss: 536.5096\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 558.8423 - val_loss: 533.3246\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.5426 - val_loss: 529.8346\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.2420 - val_loss: 530.6494\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.8430 - val_loss: 529.8227\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.4333 - val_loss: 527.0154\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 541.9822 - val_loss: 523.6040\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.4918 - val_loss: 520.3851\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 534.9630 - val_loss: 516.7079\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 531.6122 - val_loss: 516.2286\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 527.8046 - val_loss: 515.0059\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 524.1693 - val_loss: 512.2433\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.4923 - val_loss: 508.9595\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 516.7764 - val_loss: 504.9396\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 513.0224 - val_loss: 501.0392\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.2312 - val_loss: 497.5135\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 505.4027 - val_loss: 493.5256\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 501.5375 - val_loss: 489.1189\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.6353 - val_loss: 484.8930\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 493.6966 - val_loss: 481.1171\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 489.7213 - val_loss: 476.7613\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.7096 - val_loss: 473.0728\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 481.6615 - val_loss: 469.0161\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 477.5771 - val_loss: 464.8879\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 473.4567 - val_loss: 461.0155\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.3002 - val_loss: 456.5224\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 465.2926 - val_loss: 456.5428\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 460.9164 - val_loss: 453.1791\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.6615 - val_loss: 449.0613\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 452.5366 - val_loss: 445.9718\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.0457 - val_loss: 443.4518\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 443.6842 - val_loss: 439.5607\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 439.2815 - val_loss: 435.0159\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 434.9008 - val_loss: 428.9695\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.3806 - val_loss: 423.8667\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.8731 - val_loss: 418.7078\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 421.3448 - val_loss: 415.6605\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.9834 - val_loss: 412.5828\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.2422 - val_loss: 409.2337\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 407.6920 - val_loss: 404.3937\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.1501 - val_loss: 398.9803\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 398.2339 - val_loss: 394.0651\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 393.6035 - val_loss: 388.3859\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 388.8587 - val_loss: 382.5534\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.3226 - val_loss: 376.6575\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 379.8082 - val_loss: 371.2966\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.2117 - val_loss: 365.4299\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 371.9166 - val_loss: 361.9939\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 365.7650 - val_loss: 357.5647\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.0468 - val_loss: 352.5868\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.7043 - val_loss: 346.6836\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 353.2468 - val_loss: 342.7107\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347.1922 - val_loss: 337.9294\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 345.0276 - val_loss: 332.0808\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 337.4332 - val_loss: 326.7802\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 334.6320 - val_loss: 322.2324\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 328.9808 - val_loss: 316.6926\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.6001 - val_loss: 311.8826\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 319.2793 - val_loss: 306.9825\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 313.0103 - val_loss: 301.7437\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.7174 - val_loss: 296.5217\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 306.9028 - val_loss: 290.9449\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 299.8578 - val_loss: 286.3523\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.2505 - val_loss: 280.5813\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.1781 - val_loss: 277.0508\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 285.3810 - val_loss: 272.6533\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.7359 - val_loss: 267.8652\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.5541 - val_loss: 262.8246\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 276.8135 - val_loss: 258.5731\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 268.5901 - val_loss: 252.8718\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 263.0917 - val_loss: 249.4286\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.3294 - val_loss: 245.1414\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 251.5823 - val_loss: 241.1457\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 247.0356 - val_loss: 236.8355\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241.3160 - val_loss: 232.4437\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.3309 - val_loss: 227.3401\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.8054 - val_loss: 224.0016\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.7504 - val_loss: 219.9834\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 222.9464 - val_loss: 215.9337\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 222.6232 - val_loss: 212.4100\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.7281 - val_loss: 208.4146\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 212.8041 - val_loss: 204.3191\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.8254 - val_loss: 200.0885\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.1677 - val_loss: 196.4405\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.6073 - val_loss: 192.5081\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.1806 - val_loss: 188.1378\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.9757 - val_loss: 185.1241\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.7579 - val_loss: 182.3641\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.5371 - val_loss: 178.9455\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.2010 - val_loss: 175.3708\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 169.1892 - val_loss: 171.3791\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.4643 - val_loss: 167.2606\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.8811 - val_loss: 163.8245\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 162.5478 - val_loss: 161.8570\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.3034 - val_loss: 160.9851\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.8235 - val_loss: 160.9794\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 154.3828 - val_loss: 156.1132\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 152.6494 - val_loss: 153.0467\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 155.0063 - val_loss: 149.6133\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.9713 - val_loss: 145.7818\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.3078 - val_loss: 145.1605\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.5829 - val_loss: 146.1520\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.4409 - val_loss: 140.0739\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.2072 - val_loss: 139.1476\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.3281 - val_loss: 138.3609\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.0634 - val_loss: 139.0962\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.2382 - val_loss: 131.9688\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.4207 - val_loss: 119.9591\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.6730 - val_loss: 116.7217\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 148.4178 - val_loss: 118.3234\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.5165 - val_loss: 119.9055\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.7250 - val_loss: 128.0961\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 123.0580 - val_loss: 128.1041\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 115.7667 - val_loss: 117.9772\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0381 - val_loss: 107.1071\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7742 - val_loss: 108.6007\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.6270 - val_loss: 125.4530\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2071 - val_loss: 117.2197\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.5579 - val_loss: 109.7183\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2999 - val_loss: 110.6229\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2531 - val_loss: 104.2329\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7384 - val_loss: 110.5089\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6434 - val_loss: 114.3466\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.7047 - val_loss: 104.2405\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.6789 - val_loss: 96.4616\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5683 - val_loss: 98.0700\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.8670 - val_loss: 102.8139\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7234 - val_loss: 97.2549\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2020 - val_loss: 89.6239\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0463 - val_loss: 85.7958\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9499 - val_loss: 87.1331\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6621 - val_loss: 83.2859\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 124.5789 - val_loss: 82.8045\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.7102 - val_loss: 76.5904\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4073 - val_loss: 73.3034\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.6811 - val_loss: 72.1853\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4196 - val_loss: 73.4319\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.6489 - val_loss: 75.6447\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.4551 - val_loss: 81.2807\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.1975 - val_loss: 83.6374\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9458 - val_loss: 85.8634\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2612 - val_loss: 77.1328\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0907 - val_loss: 71.0549\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.5944 - val_loss: 68.7420\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.3859 - val_loss: 68.4084\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.8857 - val_loss: 69.4950\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3578 - val_loss: 71.7251\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0093 - val_loss: 74.3856\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1790 - val_loss: 70.5920\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8693 - val_loss: 68.4035\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3591 - val_loss: 65.7216\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3913 - val_loss: 65.3542\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6147 - val_loss: 66.0236\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8709 - val_loss: 68.4403\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3260 - val_loss: 69.0190\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4143 - val_loss: 67.7987\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.3578 - val_loss: 67.0915\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0771 - val_loss: 66.1087\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3440 - val_loss: 65.4393\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.7310 - val_loss: 65.0483\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7078 - val_loss: 64.6248\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1679 - val_loss: 64.6846\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.0684 - val_loss: 64.8681\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0029 - val_loss: 66.1251\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8417 - val_loss: 64.9123\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 101.9145 - val_loss: 64.6559\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4851 - val_loss: 64.5909\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1894 - val_loss: 64.7247\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7875 - val_loss: 69.2189\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2738 - val_loss: 69.3192\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6397 - val_loss: 65.5944\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6756 - val_loss: 64.9374\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.3261 - val_loss: 64.5763\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51.6120\n",
      "--- Starting trial: run-47\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 128, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 17ms/step - loss: 689.6568 - val_loss: 661.0036\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4140 - val_loss: 660.7307\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1655 - val_loss: 660.4550\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9073 - val_loss: 660.1755\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.6345 - val_loss: 659.8840\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.3425 - val_loss: 659.5709\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0257 - val_loss: 659.2282\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6782 - val_loss: 658.8610\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2931 - val_loss: 658.4539\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.8626 - val_loss: 658.0038\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.3779 - val_loss: 657.4888\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.8286 - val_loss: 656.8999\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.2029 - val_loss: 656.2302\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.4868 - val_loss: 655.4662\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.6642 - val_loss: 654.5901\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.7164 - val_loss: 653.5677\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.6210 - val_loss: 652.3915\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.3525 - val_loss: 651.0298\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.8806 - val_loss: 649.4465\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.1699 - val_loss: 647.6021\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.1791 - val_loss: 645.4521\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.8595 - val_loss: 642.9424\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.1544 - val_loss: 639.9861\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 666.9971 - val_loss: 636.5651\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.3091 - val_loss: 632.5444\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 658.9992 - val_loss: 627.8654\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.9598 - val_loss: 622.3657\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.0648 - val_loss: 615.9028\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.1667 - val_loss: 608.3454\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 633.0922 - val_loss: 599.5329\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 623.6382 - val_loss: 589.2346\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 612.5668 - val_loss: 577.0975\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.5986 - val_loss: 562.9272\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 584.4063 - val_loss: 546.2656\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.6061 - val_loss: 527.1368\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.2015 - val_loss: 506.9766\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 522.9250 - val_loss: 486.0193\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.0203 - val_loss: 462.1185\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.0583 - val_loss: 435.1227\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 438.5237 - val_loss: 404.3318\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 402.6216 - val_loss: 370.9811\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 369.7393 - val_loss: 337.4394\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.4773 - val_loss: 304.2983\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 309.1339 - val_loss: 272.6012\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 285.0312 - val_loss: 246.7919\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.9548 - val_loss: 219.6371\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 227.6251 - val_loss: 186.1701\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 202.0566 - val_loss: 164.5509\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.4855 - val_loss: 151.8385\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 153.2004 - val_loss: 139.1296\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 134.0954 - val_loss: 135.3356\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.4268 - val_loss: 123.7593\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.7879 - val_loss: 119.5286\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.8176 - val_loss: 110.8834\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 126.9562 - val_loss: 110.6758\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9453 - val_loss: 96.7042\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.7717 - val_loss: 99.1448\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5747 - val_loss: 95.2072\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3164 - val_loss: 94.3555\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.1923 - val_loss: 94.4615\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 95.0647 - val_loss: 98.5070\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.3555 - val_loss: 85.5378\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.3792 - val_loss: 98.1898\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.4497 - val_loss: 91.5315\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.7289 - val_loss: 92.5279\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6472 - val_loss: 85.4857\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.3607 - val_loss: 91.6626\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1685 - val_loss: 94.5156\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.3933 - val_loss: 81.3190\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6472 - val_loss: 93.0830\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1930 - val_loss: 74.6051\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6634 - val_loss: 85.3497\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7371 - val_loss: 82.8725\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.9280 - val_loss: 81.0770\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7216 - val_loss: 81.9165\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.4680 - val_loss: 74.0244\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3643 - val_loss: 71.8749\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9272 - val_loss: 73.7673\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4124 - val_loss: 70.4834\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3272 - val_loss: 84.5558\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0383 - val_loss: 84.4838\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1505 - val_loss: 67.0525\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.8630 - val_loss: 66.9169\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4225 - val_loss: 73.7384\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8107 - val_loss: 75.3475\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.3639 - val_loss: 74.1870\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0557 - val_loss: 77.1431\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7664 - val_loss: 64.8954\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2149 - val_loss: 74.2664\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2572 - val_loss: 71.2857\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8465 - val_loss: 71.0617\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 107.4477 - val_loss: 69.1461\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1269 - val_loss: 72.0470\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1291 - val_loss: 71.0948\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5879 - val_loss: 69.1972\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3320 - val_loss: 78.5546\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8175 - val_loss: 69.5362\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7966 - val_loss: 64.5752\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4768 - val_loss: 67.0196\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2485 - val_loss: 69.0373\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4541 - val_loss: 69.5378\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2926 - val_loss: 68.3549\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1942 - val_loss: 66.8755\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2906 - val_loss: 72.1507\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2597 - val_loss: 64.5164\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5769 - val_loss: 70.2570\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5533 - val_loss: 64.4434\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.5583 - val_loss: 65.4231\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.9718 - val_loss: 70.9399\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.1707 - val_loss: 71.1054\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2606 - val_loss: 65.1016\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0671 - val_loss: 67.6969\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2247 - val_loss: 69.1719\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.0114 - val_loss: 82.4948\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3202 - val_loss: 77.2763\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5424 - val_loss: 70.2693\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7450 - val_loss: 67.1689\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2402 - val_loss: 70.9888\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1130 - val_loss: 67.2841\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6797 - val_loss: 65.4916\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4083 - val_loss: 69.3360\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.2713 - val_loss: 70.4174\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1266 - val_loss: 77.2514\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9139 - val_loss: 66.1247\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7912 - val_loss: 69.3663\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.3178 - val_loss: 64.9773\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.9658 - val_loss: 67.0164\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.7259 - val_loss: 66.7735\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0770 - val_loss: 74.0139\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5501 - val_loss: 63.1999\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2853 - val_loss: 71.5123\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5829 - val_loss: 65.0057\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4865 - val_loss: 68.1958\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.5820 - val_loss: 69.8311\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0591 - val_loss: 68.5887\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5854 - val_loss: 66.4336\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3522 - val_loss: 68.9366\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0597 - val_loss: 67.9343\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0749 - val_loss: 65.8069\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2597 - val_loss: 65.0835\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1291 - val_loss: 80.9489\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.9060 - val_loss: 63.9251\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.4650 - val_loss: 66.5394\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 76.3216 - val_loss: 62.1381\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 75.8397 - val_loss: 63.1382\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1773 - val_loss: 72.2509\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.7232 - val_loss: 71.4634\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7275 - val_loss: 62.8451\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3191 - val_loss: 67.9278\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.9725 - val_loss: 65.3422\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6240 - val_loss: 65.2574\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3833 - val_loss: 63.1395\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0067 - val_loss: 66.2123\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6687 - val_loss: 63.2888\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7850 - val_loss: 76.5972\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4713 - val_loss: 72.2801\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5597 - val_loss: 62.9099\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.9146 - val_loss: 68.8181\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.2836 - val_loss: 63.7931\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.1243 - val_loss: 64.2876\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.6105 - val_loss: 63.3424\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.0155 - val_loss: 64.7730\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.8207 - val_loss: 64.0010\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 78.4724 - val_loss: 65.8759\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3084 - val_loss: 64.5966\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1764 - val_loss: 78.7707\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.5797 - val_loss: 64.6364\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0096 - val_loss: 65.6009\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7549 - val_loss: 64.2198\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2855 - val_loss: 70.7757\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6321 - val_loss: 73.0070\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.6855 - val_loss: 65.2023\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.9246 - val_loss: 66.9157\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7955 - val_loss: 64.0100\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3165 - val_loss: 67.6371\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1046 - val_loss: 63.7152\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9163 - val_loss: 67.8760\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6678 - val_loss: 72.1021\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.6923 - val_loss: 65.8913\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.3929 - val_loss: 66.9289\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4346 - val_loss: 69.8272\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3310 - val_loss: 66.7763\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.6482 - val_loss: 71.8840\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.4116 - val_loss: 68.6521\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3537 - val_loss: 67.1978\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9251 - val_loss: 63.9850\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.8804 - val_loss: 69.8420\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8050 - val_loss: 68.5903\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8822 - val_loss: 77.0426\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.0986 - val_loss: 62.9544\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.1570 - val_loss: 63.4859\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.4757 - val_loss: 69.8120\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.6792 - val_loss: 62.8909\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2844 - val_loss: 65.2159\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2200 - val_loss: 62.2164\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4621 - val_loss: 67.7739\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.6421 - val_loss: 66.7315\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 94.0571 - val_loss: 62.8500\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7438 - val_loss: 63.7788\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7433 - val_loss: 63.3052\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.7464 - val_loss: 64.4482\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8897 - val_loss: 63.8311\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8189 - val_loss: 63.0827\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0009 - val_loss: 66.4312\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9569 - val_loss: 65.7450\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2070 - val_loss: 62.7416\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2056 - val_loss: 89.9204\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.6352 - val_loss: 61.2663\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.5950 - val_loss: 69.3145\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.5307 - val_loss: 74.9726\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5830 - val_loss: 61.4419\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6773 - val_loss: 68.3853\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1244 - val_loss: 68.4367\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 72.9693 - val_loss: 71.0608\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7620 - val_loss: 59.9651\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7726 - val_loss: 62.6468\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.2168 - val_loss: 65.0414\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8230 - val_loss: 60.9001\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 87.5381 - val_loss: 71.1369\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8408 - val_loss: 67.5964\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.9362 - val_loss: 62.9440\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.4728 - val_loss: 61.7816\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5151 - val_loss: 63.2604\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8620 - val_loss: 75.3404\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4579 - val_loss: 65.0582\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.5664 - val_loss: 70.8815\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 85.8646 - val_loss: 69.9801\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.5638 - val_loss: 61.4417\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3678 - val_loss: 65.1827\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7699 - val_loss: 64.5105\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2390 - val_loss: 63.0505\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.7727 - val_loss: 72.4325\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8792 - val_loss: 61.3072\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.4957 - val_loss: 61.4647\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.9785 - val_loss: 61.9910\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3165 - val_loss: 66.7481\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.6748 - val_loss: 62.5502\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3930 - val_loss: 62.0838\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7283 - val_loss: 67.2142\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5721 - val_loss: 63.0106\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.9787 - val_loss: 62.5179\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.3972 - val_loss: 69.6746\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3376 - val_loss: 68.4226\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0369 - val_loss: 62.5791\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.7604 - val_loss: 65.6212\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3054 - val_loss: 67.8499\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0304 - val_loss: 64.9690\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.6322 - val_loss: 62.2428\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6024 - val_loss: 66.0370\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.0602 - val_loss: 64.2993\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 40.1996\n",
      "--- Starting trial: run-48\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 256, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6835 - val_loss: 660.2310\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4893 - val_loss: 660.0166\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2549 - val_loss: 659.7584\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9723 - val_loss: 659.4421\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6337 - val_loss: 659.0686\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2329 - val_loss: 658.6388\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7644 - val_loss: 658.1234\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2244 - val_loss: 657.5400\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.6088 - val_loss: 656.8821\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9153 - val_loss: 656.1425\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1415 - val_loss: 655.3054\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.2855 - val_loss: 654.4075\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3459 - val_loss: 653.4091\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 682.3215 - val_loss: 652.3422\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.2112 - val_loss: 651.1825\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.0143 - val_loss: 649.9285\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.7302 - val_loss: 648.5680\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.3582 - val_loss: 647.1364\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.8982 - val_loss: 645.6271\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 674.3494 - val_loss: 644.0196\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.7122 - val_loss: 642.3572\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.9859 - val_loss: 640.5767\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.1706 - val_loss: 638.7116\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.2663 - val_loss: 636.7500\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.2729 - val_loss: 634.6773\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.1905 - val_loss: 632.5395\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.0189 - val_loss: 630.2858\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.7585 - val_loss: 627.9761\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.4094 - val_loss: 625.5688\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.9714 - val_loss: 623.0844\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.4451 - val_loss: 620.5001\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.8302 - val_loss: 617.8026\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.1270 - val_loss: 615.0334\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.3360 - val_loss: 612.1576\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.4571 - val_loss: 609.2291\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.4904 - val_loss: 606.2102\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.4362 - val_loss: 603.0853\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 631.2949 - val_loss: 599.9005\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.0667 - val_loss: 596.6262\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.7515 - val_loss: 593.2475\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.3499 - val_loss: 589.7261\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.8620 - val_loss: 586.1742\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.2878 - val_loss: 582.5189\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.6281 - val_loss: 578.7958\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.8826 - val_loss: 575.0305\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 603.0518 - val_loss: 571.0927\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.1359 - val_loss: 567.1447\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.1351 - val_loss: 563.0759\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.0497 - val_loss: 559.0094\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 586.8801 - val_loss: 554.8877\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 582.6263 - val_loss: 550.7278\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.2886 - val_loss: 546.5148\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.8841 - val_loss: 575.2508\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 569.3852 - val_loss: 577.9056\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.8028 - val_loss: 571.8749\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.1342 - val_loss: 565.0299\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.3813 - val_loss: 558.2231\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.5457 - val_loss: 550.5813\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.6276 - val_loss: 544.1553\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.6274 - val_loss: 538.0038\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.5463 - val_loss: 538.6837\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.4234 - val_loss: 563.6545\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.2233 - val_loss: 561.9199\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.9161 - val_loss: 553.6592\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.5172 - val_loss: 544.8516\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.0334 - val_loss: 534.2989\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.4673 - val_loss: 525.0212\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.8206 - val_loss: 516.3849\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.0937 - val_loss: 508.1930\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.2874 - val_loss: 502.2566\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.4019 - val_loss: 496.2141\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.4375 - val_loss: 489.3396\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.4862 - val_loss: 494.3770\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.3030 - val_loss: 492.6435\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 456.1136 - val_loss: 486.9309\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.8397 - val_loss: 478.5081\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.4852 - val_loss: 469.6612\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.0522 - val_loss: 460.5702\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.5413 - val_loss: 453.2119\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 423.9532 - val_loss: 445.1958\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.2882 - val_loss: 437.3884\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.9002 - val_loss: 428.9208\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.7808 - val_loss: 423.4243\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 396.9430 - val_loss: 417.2315\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.9957 - val_loss: 408.9810\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.9583 - val_loss: 400.7472\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.8395 - val_loss: 392.8082\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 368.6428 - val_loss: 384.6029\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.9516 - val_loss: 377.4406\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.1443 - val_loss: 374.0223\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 346.8547 - val_loss: 365.5713\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.5115 - val_loss: 357.6741\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.5441 - val_loss: 354.2998\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.4742 - val_loss: 351.1945\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.7126 - val_loss: 341.1096\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 309.6939 - val_loss: 332.6689\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.0816 - val_loss: 324.8738\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295.4872 - val_loss: 315.2672\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.6483 - val_loss: 308.6823\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.2449 - val_loss: 308.4377\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 272.6754 - val_loss: 301.7536\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 264.5100 - val_loss: 292.6751\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.4280 - val_loss: 279.9793\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.4737 - val_loss: 267.8531\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 245.1268 - val_loss: 256.7183\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.0078 - val_loss: 251.3407\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 226.5679 - val_loss: 251.8258\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219.1899 - val_loss: 246.0339\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.8513 - val_loss: 237.5662\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 201.4847 - val_loss: 229.8869\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 196.0077 - val_loss: 218.6432\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.2286 - val_loss: 204.8107\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.5928 - val_loss: 200.9716\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.4955 - val_loss: 195.8712\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 165.1185 - val_loss: 189.6023\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 153.5941 - val_loss: 177.3891\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.5603 - val_loss: 164.5507\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.2860 - val_loss: 154.8755\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.0244 - val_loss: 146.3180\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 126.4204 - val_loss: 135.0525\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116.0729 - val_loss: 122.1028\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.0652 - val_loss: 115.7634\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.9260 - val_loss: 116.7965\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.9933 - val_loss: 106.7770\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8072 - val_loss: 104.6950\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8736 - val_loss: 110.0170\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4999 - val_loss: 103.0882\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.2881 - val_loss: 98.6832\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.4674 - val_loss: 101.3148\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9067 - val_loss: 107.2309\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.2792 - val_loss: 100.1844\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3853 - val_loss: 97.7363\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9101 - val_loss: 96.5647\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.4388 - val_loss: 102.1802\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0787 - val_loss: 103.8858\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.2737 - val_loss: 116.4680\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0385 - val_loss: 129.9150\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1207 - val_loss: 111.7392\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8388 - val_loss: 82.9652\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2528 - val_loss: 82.3438\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.1745 - val_loss: 120.2671\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3963 - val_loss: 140.5662\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3360 - val_loss: 113.3447\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.1634 - val_loss: 81.4624\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6089 - val_loss: 72.6924\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0800 - val_loss: 81.4547\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7215 - val_loss: 89.8639\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5782 - val_loss: 87.7010\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7754 - val_loss: 91.0375\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.7623 - val_loss: 81.0565\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6140 - val_loss: 69.1082\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6165 - val_loss: 67.1285\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8759 - val_loss: 78.2778\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3355 - val_loss: 76.0872\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 72.6393 - val_loss: 73.4226\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0614 - val_loss: 70.9810\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7226 - val_loss: 67.9882\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.4950 - val_loss: 67.2888\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4813 - val_loss: 69.5761\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.0869 - val_loss: 67.9392\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9277 - val_loss: 64.2092\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1555 - val_loss: 65.6536\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4787 - val_loss: 64.9631\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.4694 - val_loss: 66.4966\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5911 - val_loss: 73.8497\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6113 - val_loss: 74.4202\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.9115 - val_loss: 74.9448\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0021 - val_loss: 73.6861\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.6277 - val_loss: 70.8204\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9714 - val_loss: 68.2873\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9340 - val_loss: 69.8442\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.2066 - val_loss: 70.2142\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.6237 - val_loss: 64.0986\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.5894 - val_loss: 63.8799\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5895 - val_loss: 67.0685\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6247 - val_loss: 71.6919\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7834 - val_loss: 80.9537\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52.4647 - val_loss: 72.0487\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0775 - val_loss: 65.8228\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.8292 - val_loss: 67.0613\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.1969 - val_loss: 72.0752\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.6608 - val_loss: 67.6987\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5857 - val_loss: 65.5516\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.0449 - val_loss: 64.9067\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1393 - val_loss: 66.3529\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0885 - val_loss: 73.1474\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5219 - val_loss: 70.1496\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.4037 - val_loss: 64.8615\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 125.6273 - val_loss: 63.4880\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.2035 - val_loss: 65.1822\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1294 - val_loss: 73.7760\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9467 - val_loss: 69.7959\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4062 - val_loss: 63.8900\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8788 - val_loss: 63.3811\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.1898 - val_loss: 64.9095\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.7394 - val_loss: 70.4588\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8044 - val_loss: 74.6772\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7185 - val_loss: 74.1839\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.8399 - val_loss: 69.3379\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.0956 - val_loss: 66.8665\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.1430 - val_loss: 67.1972\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.4348 - val_loss: 69.6721\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7731 - val_loss: 71.6207\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3151 - val_loss: 74.2507\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1742 - val_loss: 73.2533\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7687 - val_loss: 69.5681\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.1234 - val_loss: 68.1385\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.9818 - val_loss: 68.2684\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5277 - val_loss: 66.7566\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.2552 - val_loss: 65.7014\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.3243 - val_loss: 64.9928\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7453 - val_loss: 63.9727\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4248 - val_loss: 62.8393\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.0788 - val_loss: 62.3677\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.9991 - val_loss: 62.6552\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5731 - val_loss: 62.1399\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6985 - val_loss: 62.3981\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9195 - val_loss: 62.4006\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6011 - val_loss: 63.1941\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.2707 - val_loss: 66.3894\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 96.2518 - val_loss: 66.5529\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.3846 - val_loss: 61.8813\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1799 - val_loss: 62.1629\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8481 - val_loss: 61.7742\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8980 - val_loss: 61.7527\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5139 - val_loss: 61.5084\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3994 - val_loss: 62.5195\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0163 - val_loss: 63.5458\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.7132 - val_loss: 64.6360\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7560 - val_loss: 64.2626\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9028 - val_loss: 67.4069\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8818 - val_loss: 65.4119\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.0979 - val_loss: 63.6857\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3157 - val_loss: 63.5829\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4725 - val_loss: 64.4428\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.0200 - val_loss: 63.6238\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.9410 - val_loss: 64.6124\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0907 - val_loss: 67.6219\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9017 - val_loss: 65.5707\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0578 - val_loss: 61.8867\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.4450 - val_loss: 66.5886\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.9114 - val_loss: 62.0952\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.4227 - val_loss: 63.5195\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.2138 - val_loss: 69.5548\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 111.7041 - val_loss: 69.4820\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2100 - val_loss: 70.5906\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.2633 - val_loss: 78.6523\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2667 - val_loss: 80.0103\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52.8208 - val_loss: 69.1178\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3038 - val_loss: 65.3904\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 52.3065\n",
      "--- Starting trial: run-49\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 256, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6590 - val_loss: 660.2476\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4218 - val_loss: 660.0056\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.1790 - val_loss: 659.7626\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9267 - val_loss: 659.5025\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6605 - val_loss: 659.2261\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3757 - val_loss: 658.9320\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0669 - val_loss: 658.6127\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.7285 - val_loss: 658.2576\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3537 - val_loss: 657.8682\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9352 - val_loss: 657.4212\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4642 - val_loss: 656.9175\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9308 - val_loss: 656.3521\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.3236 - val_loss: 655.7085\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.6291 - val_loss: 654.9655\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 683.8317 - val_loss: 654.1095\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.9132 - val_loss: 653.1147\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.8524 - val_loss: 651.9669\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.6242 - val_loss: 650.6475\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.1995 - val_loss: 649.1031\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.5441 - val_loss: 647.3089\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.6181 - val_loss: 645.2194\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.3745 - val_loss: 642.7817\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.7585 - val_loss: 639.9352\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.7053 - val_loss: 636.6273\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.1398 - val_loss: 632.7461\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 659.9735 - val_loss: 628.1948\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.1022 - val_loss: 622.8972\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 649.4045 - val_loss: 616.6862\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 642.7376 - val_loss: 609.4160\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.9343 - val_loss: 600.8720\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 625.7983 - val_loss: 590.8851\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 615.0997 - val_loss: 579.2001\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.5687 - val_loss: 565.5181\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.8891 - val_loss: 549.4461\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 570.7507 - val_loss: 533.0986\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 550.7051 - val_loss: 511.5230\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 527.2811 - val_loss: 489.3444\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 500.0102 - val_loss: 462.6690\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 467.7538 - val_loss: 431.6923\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.6541 - val_loss: 402.8114\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 389.9623 - val_loss: 385.0293\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.1797 - val_loss: 340.6208\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 289.3026 - val_loss: 291.0872\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 244.4236 - val_loss: 284.0898\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 213.2186 - val_loss: 277.9747\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.0526 - val_loss: 238.3384\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.0752 - val_loss: 509.1328\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.7213 - val_loss: 449.4716\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2639 - val_loss: 336.3851\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5845 - val_loss: 555.0012\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.1309 - val_loss: 386.1423\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0935 - val_loss: 453.6745\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4640 - val_loss: 229.4057\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.5494 - val_loss: 305.5853\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6043 - val_loss: 308.2551\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7471 - val_loss: 263.4602\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5312 - val_loss: 290.4646\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1363 - val_loss: 199.1188\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1769 - val_loss: 168.5299\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.1803 - val_loss: 196.8806\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7981 - val_loss: 203.6954\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6684 - val_loss: 194.0125\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0891 - val_loss: 92.1957\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.4023 - val_loss: 138.7295\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0700 - val_loss: 122.6365\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9349 - val_loss: 145.9169\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.0547 - val_loss: 156.1433\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8602 - val_loss: 128.4111\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1042 - val_loss: 167.1832\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.4298 - val_loss: 178.6064\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6677 - val_loss: 157.0307\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1087 - val_loss: 112.2786\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.7313 - val_loss: 96.1077\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0477 - val_loss: 160.0248\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2408 - val_loss: 125.3273\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7702 - val_loss: 88.9170\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 85.4105 - val_loss: 149.3192\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.9078 - val_loss: 118.1943\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0252 - val_loss: 105.3516\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5305 - val_loss: 77.6887\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5941 - val_loss: 95.0133\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9414 - val_loss: 95.1023\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6661 - val_loss: 76.8527\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.5155 - val_loss: 91.0323\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.8083 - val_loss: 74.6944\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8730 - val_loss: 75.5643\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2339 - val_loss: 79.9740\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3820 - val_loss: 75.6699\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5903 - val_loss: 83.0198\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.5798 - val_loss: 81.4859\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.8142 - val_loss: 87.1853\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.7213 - val_loss: 74.3494\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.8514 - val_loss: 76.9239\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1241 - val_loss: 81.2990\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1967 - val_loss: 94.3102\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.0518 - val_loss: 99.5110\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3328 - val_loss: 94.8191\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3708 - val_loss: 76.1208\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.2557 - val_loss: 82.0705\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7373 - val_loss: 77.2814\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.7596 - val_loss: 90.0400\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3686 - val_loss: 78.1467\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9641 - val_loss: 79.5560\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8175 - val_loss: 98.1165\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1784 - val_loss: 73.8540\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4327 - val_loss: 81.0171\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 103.2383 - val_loss: 105.3271\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.5353 - val_loss: 98.8923\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5449 - val_loss: 85.9477\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0963 - val_loss: 75.0430\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1561 - val_loss: 69.1846\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0852 - val_loss: 72.5087\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0681 - val_loss: 65.5914\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8878 - val_loss: 67.1346\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.3430 - val_loss: 73.4415\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0242 - val_loss: 77.4292\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3528 - val_loss: 67.3119\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.8764 - val_loss: 67.1406\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.7108 - val_loss: 92.7262\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4007 - val_loss: 68.2284\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3395 - val_loss: 69.2554\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9125 - val_loss: 78.5770\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.1622 - val_loss: 92.2589\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.9985 - val_loss: 75.2411\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6257 - val_loss: 73.0256\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3799 - val_loss: 70.5784\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.1442 - val_loss: 77.5254\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4960 - val_loss: 85.6558\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.8141 - val_loss: 99.6734\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6005 - val_loss: 82.7978\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.9335 - val_loss: 73.9462\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6723 - val_loss: 70.1732\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.6285 - val_loss: 72.7641\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5223 - val_loss: 67.3704\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0672 - val_loss: 79.0239\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.1771 - val_loss: 68.1723\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8082 - val_loss: 69.2110\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6403 - val_loss: 74.1789\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.1016 - val_loss: 72.9588\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2611 - val_loss: 69.0262\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6921 - val_loss: 65.8721\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.2557 - val_loss: 77.3534\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.2165 - val_loss: 75.4222\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9706 - val_loss: 70.6700\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 60.8774 - val_loss: 68.2226\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.4202 - val_loss: 65.8366\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.4877 - val_loss: 64.2666\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.2380 - val_loss: 68.3035\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1383 - val_loss: 65.2605\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4952 - val_loss: 74.7183\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.7343 - val_loss: 76.3876\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.2729 - val_loss: 79.0572\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.9352 - val_loss: 81.6996\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6781 - val_loss: 77.4428\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4324 - val_loss: 71.4823\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2654 - val_loss: 71.8245\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.1080 - val_loss: 79.0503\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9588 - val_loss: 85.8952\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0453 - val_loss: 77.0511\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4220 - val_loss: 70.3512\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1286 - val_loss: 85.3343\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4680 - val_loss: 67.3621\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3819 - val_loss: 61.6701\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.9637 - val_loss: 70.2228\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1531 - val_loss: 70.5674\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9317 - val_loss: 73.2550\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.7287 - val_loss: 67.6782\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.2507 - val_loss: 69.8313\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6036 - val_loss: 68.0696\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8955 - val_loss: 68.8507\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.2670 - val_loss: 82.2934\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.0966 - val_loss: 71.5940\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0712 - val_loss: 68.4986\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.4312 - val_loss: 65.5768\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 123.3316 - val_loss: 63.7703\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.3998 - val_loss: 66.3780\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1293 - val_loss: 66.2466\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4608 - val_loss: 66.5237\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.4782 - val_loss: 61.9390\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.4984 - val_loss: 100.7454\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.1853 - val_loss: 67.7412\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 75.3019 - val_loss: 69.4025\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.3609 - val_loss: 70.4006\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.6517 - val_loss: 74.6290\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2593 - val_loss: 75.2360\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2873 - val_loss: 64.4701\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5586 - val_loss: 67.2270\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.8168 - val_loss: 67.6936\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5254 - val_loss: 67.5026\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9925 - val_loss: 64.2568\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8944 - val_loss: 65.1164\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.4404 - val_loss: 70.9167\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.9711 - val_loss: 66.5667\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6480 - val_loss: 64.5946\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.4657 - val_loss: 62.6744\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.5473 - val_loss: 77.9879\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1555 - val_loss: 72.0021\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6870 - val_loss: 67.0630\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7435 - val_loss: 67.5050\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1925 - val_loss: 65.8009\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.0146 - val_loss: 71.5234\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8841 - val_loss: 72.2785\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4830 - val_loss: 70.3221\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.1820 - val_loss: 64.4302\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1005 - val_loss: 68.3171\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3568 - val_loss: 71.3430\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0122 - val_loss: 74.4901\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.5907 - val_loss: 71.3394\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3385 - val_loss: 63.5602\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2267 - val_loss: 65.3282\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9933 - val_loss: 75.1868\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3295 - val_loss: 70.9488\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.3527 - val_loss: 66.7726\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8540 - val_loss: 63.3199\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.1948 - val_loss: 71.3564\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3340 - val_loss: 62.0619\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2884 - val_loss: 70.1860\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5236 - val_loss: 69.9203\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 73.3828 - val_loss: 66.2656\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.0290 - val_loss: 63.1928\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5267 - val_loss: 63.0709\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5312 - val_loss: 66.0707\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1974 - val_loss: 63.0375\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.8529 - val_loss: 64.7224\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.5790 - val_loss: 63.7372\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5977 - val_loss: 69.5483\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.8102 - val_loss: 68.2505\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7833 - val_loss: 65.3098\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8497 - val_loss: 63.9062\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1314 - val_loss: 67.3154\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3697 - val_loss: 83.5016\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3751 - val_loss: 80.5585\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2101 - val_loss: 73.4394\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2890 - val_loss: 75.9866\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.8560 - val_loss: 67.9856\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6766 - val_loss: 65.9119\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0241 - val_loss: 63.9505\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3991 - val_loss: 64.7568\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6412 - val_loss: 68.0480\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.0405 - val_loss: 65.9000\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9102 - val_loss: 70.6752\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.0619 - val_loss: 77.1139\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.5854 - val_loss: 70.6447\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8401 - val_loss: 64.4458\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2462 - val_loss: 64.2555\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0789 - val_loss: 74.0527\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4528 - val_loss: 63.0114\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4305 - val_loss: 65.6493\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7274 - val_loss: 73.4954\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1348 - val_loss: 77.0767\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 59.1883\n",
      "--- Starting trial: run-50\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 256, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 16ms/step - loss: 689.6852 - val_loss: 660.3373\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.4952 - val_loss: 660.0922\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2651 - val_loss: 659.7999\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9866 - val_loss: 659.4587\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6521 - val_loss: 659.0641\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2551 - val_loss: 658.5972\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7903 - val_loss: 658.0623\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2534 - val_loss: 657.4617\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.6409 - val_loss: 656.7825\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.9501 - val_loss: 656.0186\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1786 - val_loss: 655.1694\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3247 - val_loss: 654.2470\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3870 - val_loss: 653.2671\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.3644 - val_loss: 652.1891\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 681.2555 - val_loss: 651.0216\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.0598 - val_loss: 649.7496\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.7767 - val_loss: 648.4167\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.4056 - val_loss: 646.9851\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.9462 - val_loss: 645.4653\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 674.3983 - val_loss: 643.8857\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.7614 - val_loss: 642.2015\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.0355 - val_loss: 640.4412\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.2206 - val_loss: 638.5711\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.3165 - val_loss: 636.6122\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.3232 - val_loss: 634.5771\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.2407 - val_loss: 632.4700\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.0694 - val_loss: 630.3142\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.8089 - val_loss: 627.9854\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.4595 - val_loss: 625.5875\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.0215 - val_loss: 623.0809\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 651.4949 - val_loss: 620.5209\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.8798 - val_loss: 617.8454\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.1763 - val_loss: 615.0744\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.3849 - val_loss: 612.1071\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.5056 - val_loss: 609.0328\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.5385 - val_loss: 606.0157\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.4841 - val_loss: 602.8443\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.3423 - val_loss: 599.7119\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.1136 - val_loss: 596.6049\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.7981 - val_loss: 593.4080\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.3959 - val_loss: 589.8394\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.9075 - val_loss: 586.2029\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.3330 - val_loss: 582.3909\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.6727 - val_loss: 578.5190\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.9266 - val_loss: 574.5812\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.0953 - val_loss: 570.5722\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.1789 - val_loss: 566.6402\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 595.1776 - val_loss: 562.4718\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.1386 - val_loss: 562.5046\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.9405 - val_loss: 562.7834\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.6938 - val_loss: 560.1102\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.3585 - val_loss: 556.1722\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.9374 - val_loss: 551.5967\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.4321 - val_loss: 546.7850\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.8434 - val_loss: 541.7427\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.1717 - val_loss: 536.5865\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.4174 - val_loss: 531.7095\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.5806 - val_loss: 526.6287\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.7220 - val_loss: 527.3589\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.6837 - val_loss: 526.8900\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.6091 - val_loss: 522.5078\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.4482 - val_loss: 517.0330\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.2042 - val_loss: 511.2124\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.8784 - val_loss: 505.4763\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.4718 - val_loss: 499.9972\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.9846 - val_loss: 494.1983\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.4171 - val_loss: 488.8271\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.7699 - val_loss: 483.2219\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.1124 - val_loss: 473.2751\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.2589 - val_loss: 463.9396\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 480.6596 - val_loss: 455.2433\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 474.5685 - val_loss: 447.4991\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 468.4625 - val_loss: 445.7457\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.3973 - val_loss: 444.0395\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.3298 - val_loss: 428.3581\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.9755 - val_loss: 413.7499\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.6345 - val_loss: 406.4848\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.4955 - val_loss: 433.0816\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.8968 - val_loss: 460.7692\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.2271 - val_loss: 466.9013\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.5805 - val_loss: 461.4868\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 410.8845 - val_loss: 445.0574\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.0763 - val_loss: 403.6962\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.3772 - val_loss: 381.1803\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 391.4321 - val_loss: 362.5019\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.7873 - val_loss: 378.5789\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.9522 - val_loss: 405.0120\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 369.8284 - val_loss: 427.5280\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 362.7089 - val_loss: 425.0590\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 355.8329 - val_loss: 414.0974\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 348.0365 - val_loss: 400.3211\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.8643 - val_loss: 373.4005\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 333.5155 - val_loss: 351.5597\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.9256 - val_loss: 336.9134\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 318.4021 - val_loss: 332.2460\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.4980 - val_loss: 331.1605\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.8088 - val_loss: 326.8656\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295.1108 - val_loss: 326.0800\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 288.0313 - val_loss: 332.6818\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 282.3658 - val_loss: 322.0072\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.7922 - val_loss: 296.4503\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 269.3202 - val_loss: 276.9317\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 257.0728 - val_loss: 280.8049\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.4927 - val_loss: 275.0265\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241.5558 - val_loss: 276.8714\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 232.6009 - val_loss: 278.3571\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 224.9283 - val_loss: 258.6591\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 216.0880 - val_loss: 242.6285\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 208.5744 - val_loss: 235.3876\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.6065 - val_loss: 231.6835\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 190.8344 - val_loss: 229.9935\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.2719 - val_loss: 218.8140\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 185.2547 - val_loss: 192.1720\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.0961 - val_loss: 187.8646\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 170.3507 - val_loss: 178.8272\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 153.1545 - val_loss: 173.6637\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.3072 - val_loss: 170.4832\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 138.9760 - val_loss: 157.1114\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.2705 - val_loss: 159.8622\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.1985 - val_loss: 163.6502\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.7174 - val_loss: 167.3450\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.2530 - val_loss: 157.7002\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.0221 - val_loss: 156.9701\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.5677 - val_loss: 148.8157\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0266 - val_loss: 137.7159\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.7357 - val_loss: 136.2765\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.6000 - val_loss: 129.6818\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.8699 - val_loss: 112.5990\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3795 - val_loss: 106.4276\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.7850 - val_loss: 110.1736\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2828 - val_loss: 114.0932\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2741 - val_loss: 112.4978\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9100 - val_loss: 105.4071\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.5434 - val_loss: 98.9784\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5430 - val_loss: 90.2461\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0409 - val_loss: 90.2963\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9478 - val_loss: 87.0688\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0131 - val_loss: 82.8299\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.5169 - val_loss: 83.7535\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0451 - val_loss: 74.9315\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.6311 - val_loss: 73.2991\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4594 - val_loss: 67.5761\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2198 - val_loss: 66.0216\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.8223 - val_loss: 65.5354\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.6744 - val_loss: 64.3902\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2340 - val_loss: 62.4720\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.8250 - val_loss: 60.7617\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3058 - val_loss: 60.9865\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2736 - val_loss: 58.5862\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.2174 - val_loss: 60.7877\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 83.5396 - val_loss: 63.1134\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0542 - val_loss: 63.4695\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.2048 - val_loss: 63.5767\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.6076 - val_loss: 60.7432\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0774 - val_loss: 59.3250\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.7738 - val_loss: 63.7071\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7042 - val_loss: 71.7873\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.1173 - val_loss: 62.9459\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7499 - val_loss: 62.4940\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.8730 - val_loss: 61.8966\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.7317 - val_loss: 62.7763\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.5325 - val_loss: 59.5984\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9356 - val_loss: 57.2273\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5704 - val_loss: 61.9170\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.1180 - val_loss: 67.7601\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.4164 - val_loss: 66.2996\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9390 - val_loss: 62.2537\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1421 - val_loss: 62.7990\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1399 - val_loss: 64.7076\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9200 - val_loss: 69.2714\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.1641 - val_loss: 59.8129\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0067 - val_loss: 57.8773\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0308 - val_loss: 60.8822\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.0358 - val_loss: 71.7425\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.9681 - val_loss: 73.8339\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4237 - val_loss: 65.7230\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.2258 - val_loss: 62.9601\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3998 - val_loss: 63.3214\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50.7264 - val_loss: 64.5432\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.0233 - val_loss: 65.2765\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64.9370 - val_loss: 61.5217\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 83.1723 - val_loss: 63.4716\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.6432 - val_loss: 63.6055\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 101.5816 - val_loss: 65.1918\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6688 - val_loss: 61.7009\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6847 - val_loss: 59.8643\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.5161 - val_loss: 59.8080\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.6363 - val_loss: 60.1925\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.3158 - val_loss: 62.6100\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.5094 - val_loss: 64.9387\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.6871 - val_loss: 63.9058\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5993 - val_loss: 65.2383\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.2297 - val_loss: 69.7576\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1601 - val_loss: 73.8367\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7590 - val_loss: 77.0101\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.9592 - val_loss: 71.5563\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2653 - val_loss: 68.3170\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4052 - val_loss: 66.3902\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8034 - val_loss: 60.6544\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1504 - val_loss: 59.7316\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9646 - val_loss: 61.0780\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3237 - val_loss: 58.8548\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9192 - val_loss: 59.7088\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.5046 - val_loss: 61.4170\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2834 - val_loss: 60.1608\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8958 - val_loss: 58.5172\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.0088 - val_loss: 58.6147\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.9126 - val_loss: 62.2383\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0476 - val_loss: 59.5576\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.1061 - val_loss: 57.6969\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4574 - val_loss: 61.7297\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.8603 - val_loss: 67.6965\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.7025 - val_loss: 70.5769\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 111.1861 - val_loss: 69.7819\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.5288 - val_loss: 64.1046\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 46.0111 - val_loss: 65.0581\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.8347 - val_loss: 65.4971\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47.5441 - val_loss: 62.4418\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7124 - val_loss: 58.2934\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7649 - val_loss: 61.1030\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.9120 - val_loss: 62.8039\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0762 - val_loss: 64.1980\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.9129 - val_loss: 59.6795\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1155 - val_loss: 59.4053\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7623 - val_loss: 60.1526\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.4705 - val_loss: 59.0927\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6557 - val_loss: 57.0274\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6071 - val_loss: 56.4187\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4209 - val_loss: 58.1183\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.0486 - val_loss: 65.3884\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.5417 - val_loss: 63.2127\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.7636 - val_loss: 64.4724\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3078 - val_loss: 65.6888\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.2788 - val_loss: 65.9829\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6998 - val_loss: 62.8507\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0805 - val_loss: 60.7134\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.4461 - val_loss: 60.2678\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.5343 - val_loss: 59.3203\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7514 - val_loss: 60.6853\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5418 - val_loss: 60.6113\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.1956 - val_loss: 62.6316\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8865 - val_loss: 61.7788\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.5279 - val_loss: 60.1321\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.7210 - val_loss: 60.1858\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 51.8687 - val_loss: 57.4216\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 51.2567 - val_loss: 59.0041\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52.9533 - val_loss: 57.1723\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 48.2990 - val_loss: 58.4201\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4612 - val_loss: 58.1107\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.5216 - val_loss: 60.6416\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 34.4930\n",
      "--- Starting trial: run-51\n",
      "{'activation': 'relu', 'dropout': 0.1, 'num_units': 256, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6628 - val_loss: 660.3298\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4354 - val_loss: 660.0509\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2028 - val_loss: 659.7684\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 688.9614 - val_loss: 659.4763\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.7068 - val_loss: 659.1678\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4348 - val_loss: 658.8355\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1404 - val_loss: 658.4703\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8181 - val_loss: 658.0740\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.4618 - val_loss: 657.6399\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.0643 - val_loss: 657.1649\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6178 - val_loss: 656.6254\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.1129 - val_loss: 656.0251\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.5386 - val_loss: 655.3359\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.8825 - val_loss: 654.5445\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.1301 - val_loss: 653.6442\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.2640 - val_loss: 652.6132\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.2645 - val_loss: 651.4196\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.1081 - val_loss: 650.0572\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 679.7675 - val_loss: 648.5020\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.2108 - val_loss: 646.6904\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.4003 - val_loss: 644.5773\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.2919 - val_loss: 642.1390\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.8345 - val_loss: 639.2964\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 668.9675 - val_loss: 636.0281\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.6201 - val_loss: 632.2079\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.7093 - val_loss: 627.7603\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.1378 - val_loss: 622.5886\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.7914 - val_loss: 616.5361\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.5367 - val_loss: 609.5119\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 638.2165 - val_loss: 601.3080\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 629.6471 - val_loss: 591.6877\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 619.6128 - val_loss: 580.4466\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 607.8607 - val_loss: 567.3223\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.0943 - val_loss: 551.9537\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.9661 - val_loss: 534.1752\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 559.2111 - val_loss: 516.5822\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 537.5673 - val_loss: 499.6848\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 511.8079 - val_loss: 473.4442\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 481.9324 - val_loss: 445.0450\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 447.9055 - val_loss: 424.1860\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.6700 - val_loss: 406.5197\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 367.1461 - val_loss: 370.6538\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 324.7318 - val_loss: 318.3877\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 274.6621 - val_loss: 281.4612\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.3945 - val_loss: 257.8784\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.4659 - val_loss: 234.2801\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 161.4361 - val_loss: 250.7442\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 142.2895 - val_loss: 302.3698\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.2743 - val_loss: 206.8825\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.4501 - val_loss: 288.7679\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6889 - val_loss: 329.0601\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8970 - val_loss: 330.1698\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1878 - val_loss: 321.8439\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.5868 - val_loss: 219.1012\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3605 - val_loss: 273.6234\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9942 - val_loss: 219.1096\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.5458 - val_loss: 221.6160\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2355 - val_loss: 214.2494\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.5402 - val_loss: 185.5238\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4862 - val_loss: 189.7155\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4090 - val_loss: 140.7862\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7335 - val_loss: 126.9224\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.6001 - val_loss: 132.1793\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2442 - val_loss: 133.3421\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0024 - val_loss: 129.8329\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9843 - val_loss: 150.0677\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.9490 - val_loss: 130.7764\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8462 - val_loss: 137.0348\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9292 - val_loss: 130.8164\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0142 - val_loss: 103.3241\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.0614 - val_loss: 122.2438\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.3552 - val_loss: 84.2521\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58.5767 - val_loss: 146.8182\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.8571 - val_loss: 101.7257\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5282 - val_loss: 77.8244\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4518 - val_loss: 84.2480\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5308 - val_loss: 94.2965\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5337 - val_loss: 86.1034\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.7804 - val_loss: 96.8833\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4731 - val_loss: 89.9352\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.9908 - val_loss: 104.4819\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1481 - val_loss: 90.7613\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9032 - val_loss: 91.4464\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.8238 - val_loss: 95.4628\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6196 - val_loss: 92.4063\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4480 - val_loss: 98.2915\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6585 - val_loss: 81.8171\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.8829 - val_loss: 77.0886\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.4876 - val_loss: 74.6586\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1488 - val_loss: 76.5372\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3123 - val_loss: 80.5317\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.4507 - val_loss: 75.3732\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4601 - val_loss: 77.0563\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.0502 - val_loss: 78.5321\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.6386 - val_loss: 71.3894\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3310 - val_loss: 73.6290\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4981 - val_loss: 63.0671\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5083 - val_loss: 70.1244\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6382 - val_loss: 63.0260\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.0921 - val_loss: 74.0414\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5529 - val_loss: 86.4371\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.0304 - val_loss: 73.0641\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.3246 - val_loss: 85.5064\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1140 - val_loss: 75.0109\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4401 - val_loss: 79.4148\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0624 - val_loss: 66.8174\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.2313 - val_loss: 73.6708\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3048 - val_loss: 70.2573\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 88.9824 - val_loss: 73.4951\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3941 - val_loss: 72.6304\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5479 - val_loss: 74.4770\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.5655 - val_loss: 76.6914\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.5375 - val_loss: 65.4289\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9949 - val_loss: 73.0948\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8783 - val_loss: 74.4646\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3535 - val_loss: 69.5495\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.9481 - val_loss: 67.7961\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7877 - val_loss: 74.1038\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4743 - val_loss: 63.4932\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6227 - val_loss: 59.4714\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.8238 - val_loss: 67.4931\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7535 - val_loss: 75.3611\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4668 - val_loss: 71.5417\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.0803 - val_loss: 70.7683\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4375 - val_loss: 71.0303\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1600 - val_loss: 57.5132\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5170 - val_loss: 65.1829\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.0103 - val_loss: 72.8288\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.2163 - val_loss: 83.4770\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.9456 - val_loss: 67.6638\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.4345 - val_loss: 71.5739\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2247 - val_loss: 61.0648\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.2460 - val_loss: 57.9705\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6055 - val_loss: 65.2374\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.6990 - val_loss: 57.4177\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.8738 - val_loss: 64.1919\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.0345 - val_loss: 58.2239\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.1863 - val_loss: 56.9914\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7144 - val_loss: 58.8339\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5396 - val_loss: 73.5684\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8228 - val_loss: 57.2152\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.3212 - val_loss: 77.4268\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6313 - val_loss: 71.6422\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.7149 - val_loss: 72.0139\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2523 - val_loss: 75.2134\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2448 - val_loss: 80.5415\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9538 - val_loss: 65.9439\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.8983 - val_loss: 81.0352\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.7940 - val_loss: 77.2012\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1549 - val_loss: 66.7876\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.4023 - val_loss: 69.5148\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2568 - val_loss: 67.2006\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4205 - val_loss: 64.1241\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.0058 - val_loss: 58.9909\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.6900 - val_loss: 59.7111\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7147 - val_loss: 70.7462\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.3119 - val_loss: 59.1640\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2586 - val_loss: 72.4614\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4844 - val_loss: 75.3750\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0126 - val_loss: 68.5437\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.8502 - val_loss: 60.3532\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.2326 - val_loss: 57.8901\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8997 - val_loss: 70.0560\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2855 - val_loss: 63.9615\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2948 - val_loss: 57.5826\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.2292 - val_loss: 59.1702\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.9899 - val_loss: 65.3102\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6300 - val_loss: 65.9434\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.5218 - val_loss: 61.2245\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9342 - val_loss: 61.0926\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8247 - val_loss: 60.7876\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8822 - val_loss: 57.1773\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4998 - val_loss: 59.2354\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2034 - val_loss: 57.8507\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.1558 - val_loss: 63.2116\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9251 - val_loss: 72.0499\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6888 - val_loss: 68.2958\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0504 - val_loss: 63.7323\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.4542 - val_loss: 65.3199\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1950 - val_loss: 74.3884\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3331 - val_loss: 61.4493\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.0477 - val_loss: 62.9537\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.5829 - val_loss: 61.2878\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4665 - val_loss: 66.0723\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 49.4570 - val_loss: 62.4472\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 54.7797 - val_loss: 68.9658\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1074 - val_loss: 68.9870\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8095 - val_loss: 61.6194\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9507 - val_loss: 67.4252\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7854 - val_loss: 64.0610\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9795 - val_loss: 76.3631\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.8760 - val_loss: 62.4487\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.6652 - val_loss: 61.5177\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.0717 - val_loss: 72.7178\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.7901 - val_loss: 58.1110\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0018 - val_loss: 71.9506\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.3665 - val_loss: 59.8452\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1406 - val_loss: 56.0210\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.7014 - val_loss: 70.1640\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.8561 - val_loss: 58.5033\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5706 - val_loss: 60.5050\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7570 - val_loss: 68.3348\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.3864 - val_loss: 57.7137\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4998 - val_loss: 57.5744\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50.1024 - val_loss: 60.9876\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.0498 - val_loss: 67.7243\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2554 - val_loss: 58.7155\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0962 - val_loss: 67.7429\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3115 - val_loss: 60.6954\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4608 - val_loss: 60.4459\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.3513 - val_loss: 62.3029\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0075 - val_loss: 64.5024\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5290 - val_loss: 66.0798\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.4093 - val_loss: 61.6316\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2285 - val_loss: 62.9646\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.2051 - val_loss: 58.2764\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6475 - val_loss: 57.1466\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1806 - val_loss: 64.6022\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.9546 - val_loss: 65.8747\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9974 - val_loss: 63.5414\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1700 - val_loss: 65.7151\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.7340 - val_loss: 61.7361\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.2337 - val_loss: 58.0834\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4483 - val_loss: 65.4521\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2780 - val_loss: 70.4773\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0366 - val_loss: 63.5315\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.2799 - val_loss: 60.4865\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.3154 - val_loss: 68.7108\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6024 - val_loss: 58.1572\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.4843 - val_loss: 62.9434\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2177 - val_loss: 57.8018\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2756 - val_loss: 60.1906\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3135 - val_loss: 59.1407\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.6587 - val_loss: 63.0126\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.7818 - val_loss: 60.5296\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4507 - val_loss: 58.7375\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.4055 - val_loss: 68.6719\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.9044 - val_loss: 61.3981\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.6401 - val_loss: 65.7216\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1486 - val_loss: 64.3991\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.9904 - val_loss: 58.5340\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4734 - val_loss: 68.9790\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9686 - val_loss: 58.1570\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6932 - val_loss: 61.4722\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.5790 - val_loss: 63.9381\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.4908 - val_loss: 59.8465\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.3333 - val_loss: 60.8448\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.8269 - val_loss: 75.5041\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8831 - val_loss: 65.6765\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3383 - val_loss: 64.9266\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 43.1353\n",
      "--- Starting trial: run-52\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 256, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 17ms/step - loss: 689.6846 - val_loss: 659.6068\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.4929 - val_loss: 659.4008\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2613 - val_loss: 659.1514\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.9811 - val_loss: 658.8486\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 688.6451 - val_loss: 658.4890\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.2470 - val_loss: 658.0618\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7812 - val_loss: 657.5598\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2437 - val_loss: 656.9891\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6308 - val_loss: 656.3502\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9398 - val_loss: 655.6254\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.1683 - val_loss: 654.8238\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3146 - val_loss: 653.9332\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3773 - val_loss: 652.9553\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 682.3549 - val_loss: 651.8984\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.2466 - val_loss: 650.7501\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.0516 - val_loss: 649.5368\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.7692 - val_loss: 648.2172\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 677.3990 - val_loss: 646.8151\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.9406 - val_loss: 645.2978\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.3934 - val_loss: 643.7166\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.7576 - val_loss: 642.0354\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.0327 - val_loss: 640.2822\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.2188 - val_loss: 638.4390\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 667.3156 - val_loss: 636.4692\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.3234 - val_loss: 634.4325\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.2421 - val_loss: 632.3202\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.0717 - val_loss: 630.0944\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.8123 - val_loss: 627.8166\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.4641 - val_loss: 625.4401\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.0271 - val_loss: 622.9422\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.5015 - val_loss: 620.3789\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.8874 - val_loss: 617.6697\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 646.1852 - val_loss: 614.9278\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.3947 - val_loss: 612.0770\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.5165 - val_loss: 609.1810\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.5504 - val_loss: 606.1599\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.4971 - val_loss: 603.0208\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.3563 - val_loss: 599.8021\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.1286 - val_loss: 596.5515\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.8140 - val_loss: 593.1798\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.4128 - val_loss: 589.7444\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 617.9254 - val_loss: 586.2404\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.3519 - val_loss: 582.6307\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.6925 - val_loss: 578.9977\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.9474 - val_loss: 575.2030\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.1171 - val_loss: 571.4221\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 599.2016 - val_loss: 567.4498\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.2012 - val_loss: 563.3233\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.1162 - val_loss: 559.0881\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.9468 - val_loss: 554.8391\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.6934 - val_loss: 550.5963\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.3560 - val_loss: 546.1628\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.0393 - val_loss: 552.9078\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.4518 - val_loss: 554.4868\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.8715 - val_loss: 551.6937\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.2037 - val_loss: 547.7924\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.4515 - val_loss: 543.1474\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.6161 - val_loss: 538.1874\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 545.6983 - val_loss: 533.0316\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.6985 - val_loss: 528.0726\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.6169 - val_loss: 522.7646\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.4542 - val_loss: 518.0359\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.2101 - val_loss: 512.4548\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 519.8853 - val_loss: 507.0391\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 514.4798 - val_loss: 502.2365\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.9940 - val_loss: 496.9710\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 503.4280 - val_loss: 491.4799\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.7821 - val_loss: 485.6362\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 492.0966 - val_loss: 494.1942\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 486.2771 - val_loss: 492.7729\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 480.4017 - val_loss: 486.3176\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.4419 - val_loss: 479.5063\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.4012 - val_loss: 472.3629\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.2810 - val_loss: 465.0715\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.0823 - val_loss: 458.5734\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.8053 - val_loss: 451.2965\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.4506 - val_loss: 444.8525\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.0183 - val_loss: 438.3279\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 432.5606 - val_loss: 430.2033\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.1868 - val_loss: 423.0024\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.0468 - val_loss: 419.2177\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.2203 - val_loss: 413.8953\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 404.5749 - val_loss: 406.4844\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 397.6756 - val_loss: 400.9578\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 390.7768 - val_loss: 393.7290\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.7604 - val_loss: 387.5675\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 377.4341 - val_loss: 381.2934\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 369.7184 - val_loss: 374.5093\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 362.2876 - val_loss: 366.7083\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 356.1648 - val_loss: 357.9607\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347.6726 - val_loss: 350.4937\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.2453 - val_loss: 343.3083\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 332.9365 - val_loss: 335.1087\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.4922 - val_loss: 326.8692\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.7515 - val_loss: 320.2006\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 310.5442 - val_loss: 312.4519\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.2756 - val_loss: 303.4738\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.6676 - val_loss: 294.0697\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 289.2517 - val_loss: 284.8311\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.9933 - val_loss: 275.3423\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.0608 - val_loss: 267.8582\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 263.2608 - val_loss: 260.2156\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 258.9398 - val_loss: 254.4361\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 247.8643 - val_loss: 247.8277\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.3526 - val_loss: 240.5943\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 237.9513 - val_loss: 234.8992\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 225.3659 - val_loss: 228.0064\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 217.0726 - val_loss: 223.6223\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.8815 - val_loss: 219.3082\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 207.5064 - val_loss: 207.7926\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.3591 - val_loss: 201.6677\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 185.8691 - val_loss: 198.8401\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.4989 - val_loss: 191.1018\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.7769 - val_loss: 180.2601\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.3079 - val_loss: 174.3973\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 160.6294 - val_loss: 180.8522\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 154.5675 - val_loss: 170.1507\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 159.0118 - val_loss: 164.2730\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.2940 - val_loss: 165.0857\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.4337 - val_loss: 145.3941\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.8956 - val_loss: 132.0400\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 147.1995 - val_loss: 130.7911\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 133.5804 - val_loss: 137.4133\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.6159 - val_loss: 140.9327\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.3303 - val_loss: 132.5307\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.2791 - val_loss: 130.7246\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6728 - val_loss: 130.4353\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.2471 - val_loss: 100.8473\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3285 - val_loss: 98.6159\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.8102 - val_loss: 113.8611\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.4633 - val_loss: 119.6093\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.1829 - val_loss: 108.2274\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.7392 - val_loss: 96.7992\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.9828 - val_loss: 96.3014\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4988 - val_loss: 92.1046\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6918 - val_loss: 89.4044\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6918 - val_loss: 89.3573\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1341 - val_loss: 84.7911\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7853 - val_loss: 85.0136\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.8572 - val_loss: 77.6979\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.3839 - val_loss: 79.2771\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5798 - val_loss: 77.2798\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.1854 - val_loss: 72.3920\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5652 - val_loss: 73.2653\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0543 - val_loss: 69.3553\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.9490 - val_loss: 68.6636\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2278 - val_loss: 79.1830\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4701 - val_loss: 70.4810\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7010 - val_loss: 64.6231\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4630 - val_loss: 64.0004\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.8980 - val_loss: 66.7509\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.9860 - val_loss: 79.0554\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.0898 - val_loss: 78.8886\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.4256 - val_loss: 70.0687\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 70.5718 - val_loss: 65.8236\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.8451 - val_loss: 65.4236\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5773 - val_loss: 68.9081\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.3976 - val_loss: 67.2081\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8176 - val_loss: 69.0247\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.1776 - val_loss: 68.5939\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.3812 - val_loss: 68.1585\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3693 - val_loss: 64.5065\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2416 - val_loss: 63.9676\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3637 - val_loss: 65.2005\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1477 - val_loss: 63.9833\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.2933 - val_loss: 62.5525\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.3401 - val_loss: 66.8719\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.8431 - val_loss: 62.9231\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.6738 - val_loss: 62.9076\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3324 - val_loss: 62.6528\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.7866 - val_loss: 67.6785\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7896 - val_loss: 67.4635\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2481 - val_loss: 64.4353\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.2521 - val_loss: 63.8325\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.2814 - val_loss: 63.1115\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0767 - val_loss: 63.5978\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7385 - val_loss: 66.9686\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9094 - val_loss: 63.2053\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2611 - val_loss: 65.5276\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.5686 - val_loss: 64.1563\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5290 - val_loss: 63.8840\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6763 - val_loss: 63.0813\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.3756 - val_loss: 65.0510\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6879 - val_loss: 66.9851\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.2306 - val_loss: 64.3851\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.7551 - val_loss: 65.2821\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.2876 - val_loss: 63.8040\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.0650 - val_loss: 64.4944\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.7681 - val_loss: 64.4209\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.5703 - val_loss: 67.7091\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1097 - val_loss: 63.0481\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 70.2884 - val_loss: 64.1165\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.3048 - val_loss: 63.5797\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.2877 - val_loss: 64.7612\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6559 - val_loss: 64.0556\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 52.1750 - val_loss: 63.7070\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.9379 - val_loss: 62.0775\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8452 - val_loss: 64.8111\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.8919 - val_loss: 63.8157\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.1044 - val_loss: 63.7465\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.4599 - val_loss: 72.7843\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.4306 - val_loss: 72.3954\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9039 - val_loss: 63.6325\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 51.4574 - val_loss: 63.1208\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.3433 - val_loss: 63.7182\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0854 - val_loss: 63.0306\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4560 - val_loss: 62.9518\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.9666 - val_loss: 61.9285\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.4402 - val_loss: 62.0893\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1642 - val_loss: 62.2251\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9993 - val_loss: 63.2122\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 58.2718 - val_loss: 63.9306\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.0788 - val_loss: 62.1747\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.4617 - val_loss: 62.7632\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6501 - val_loss: 61.0046\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4261 - val_loss: 62.0711\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 91.9081 - val_loss: 63.3613\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6103 - val_loss: 62.0104\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1949 - val_loss: 62.6759\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.9653 - val_loss: 62.4135\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1704 - val_loss: 65.5568\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 65.1997 - val_loss: 66.0224\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3664 - val_loss: 62.8655\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.1151 - val_loss: 62.3065\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.1705 - val_loss: 63.7889\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.5804 - val_loss: 67.1059\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4476 - val_loss: 62.1251\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6673 - val_loss: 62.2580\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.8446 - val_loss: 61.0307\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.7558 - val_loss: 61.4498\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.9094 - val_loss: 61.8063\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3264 - val_loss: 62.7212\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4255 - val_loss: 62.5388\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.1619 - val_loss: 62.7948\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1367 - val_loss: 63.8585\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8573 - val_loss: 63.5188\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.1655 - val_loss: 62.7210\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0017 - val_loss: 61.2824\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9737 - val_loss: 63.1362\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4983 - val_loss: 65.0663\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8686 - val_loss: 64.0321\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.6297 - val_loss: 61.7539\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.0564 - val_loss: 62.5693\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5881 - val_loss: 62.9791\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.5219 - val_loss: 62.1664\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6567 - val_loss: 61.3539\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.5888 - val_loss: 62.0138\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.4966 - val_loss: 67.7076\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 50.0889 - val_loss: 61.8137\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.7846 - val_loss: 61.6810\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 49.8555\n",
      "--- Starting trial: run-53\n",
      "{'activation': 'sigmoid', 'dropout': 0.1, 'num_units': 256, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6559 - val_loss: 661.0222\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4109 - val_loss: 660.7584\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.1602 - val_loss: 660.4913\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.8994 - val_loss: 660.2196\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.6241 - val_loss: 659.9354\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.3293 - val_loss: 659.6300\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.0092 - val_loss: 659.3024\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6581 - val_loss: 658.9365\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2687 - val_loss: 658.5345\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.8336 - val_loss: 658.0865\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.3433 - val_loss: 657.5767\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.7877 - val_loss: 657.0017\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.1546 - val_loss: 656.3425\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.4299 - val_loss: 655.5800\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.5973 - val_loss: 654.7064\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.6376 - val_loss: 653.7032\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.5284 - val_loss: 652.5298\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 680.2438 - val_loss: 651.1660\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.7530 - val_loss: 649.5796\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.0201 - val_loss: 647.7404\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.0035 - val_loss: 645.5805\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.6534 - val_loss: 643.0614\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 669.9128 - val_loss: 640.1111\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 666.7136 - val_loss: 636.6735\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 662.9767 - val_loss: 632.6131\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.6094 - val_loss: 627.8801\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.5027 - val_loss: 622.3255\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 647.5288 - val_loss: 615.8179\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.5381 - val_loss: 608.1848\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 632.3551 - val_loss: 599.2686\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 622.7739 - val_loss: 588.7811\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.5533 - val_loss: 576.4835\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.4102 - val_loss: 562.0518\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.0129 - val_loss: 545.2123\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.3804 - val_loss: 526.7739\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 544.8038 - val_loss: 506.0789\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 520.8621 - val_loss: 483.1384\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.9271 - val_loss: 457.8293\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.3989 - val_loss: 427.2372\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 425.5046 - val_loss: 392.0513\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 384.2585 - val_loss: 353.0911\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 341.9008 - val_loss: 313.0627\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 298.7084 - val_loss: 273.6988\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.5764 - val_loss: 225.1549\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.5867 - val_loss: 191.6949\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 158.5477 - val_loss: 164.6422\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.0745 - val_loss: 145.8386\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.4810 - val_loss: 138.3346\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.6691 - val_loss: 116.4930\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.9808 - val_loss: 113.8684\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 105.0640 - val_loss: 114.3130\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4688 - val_loss: 104.7112\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3591 - val_loss: 89.6038\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.0358 - val_loss: 87.3667\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.9806 - val_loss: 103.4576\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.1292 - val_loss: 88.9085\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.4785 - val_loss: 95.5239\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0396 - val_loss: 109.9461\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.8250 - val_loss: 92.2485\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.6228 - val_loss: 92.1187\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0678 - val_loss: 90.0594\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5679 - val_loss: 90.9449\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8477 - val_loss: 91.4042\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.5910 - val_loss: 88.0242\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1468 - val_loss: 92.0907\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 116.7868 - val_loss: 84.6192\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6968 - val_loss: 87.7479\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.4183 - val_loss: 81.8989\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2765 - val_loss: 87.4013\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3918 - val_loss: 77.9207\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.9280 - val_loss: 101.6848\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4501 - val_loss: 81.2895\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.2347 - val_loss: 79.7750\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.3645 - val_loss: 85.1431\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.6539 - val_loss: 84.4141\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1098 - val_loss: 84.7970\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.9899 - val_loss: 70.3374\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0515 - val_loss: 170.8459\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7448 - val_loss: 73.8190\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.6141 - val_loss: 80.2986\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.7742 - val_loss: 71.7503\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.5874 - val_loss: 77.8787\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.4228 - val_loss: 73.6775\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.7262 - val_loss: 65.2369\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6943 - val_loss: 72.7830\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3886 - val_loss: 95.3801\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 82.3445 - val_loss: 68.4231\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2160 - val_loss: 65.4662\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1902 - val_loss: 66.0684\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.9056 - val_loss: 74.1745\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7080 - val_loss: 75.6964\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.0964 - val_loss: 72.1870\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9740 - val_loss: 66.4337\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3202 - val_loss: 79.9466\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8813 - val_loss: 67.0322\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.9608 - val_loss: 78.4040\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.7703 - val_loss: 72.9079\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.4345 - val_loss: 67.7707\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.4267 - val_loss: 63.4704\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7131 - val_loss: 64.1827\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.3479 - val_loss: 70.6736\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0429 - val_loss: 62.8138\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.0493 - val_loss: 69.3916\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.0464 - val_loss: 69.0433\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4463 - val_loss: 69.4600\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.7707 - val_loss: 76.6299\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.9402 - val_loss: 69.9229\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3463 - val_loss: 70.1633\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2931 - val_loss: 65.3858\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5213 - val_loss: 63.7543\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4229 - val_loss: 70.3302\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0897 - val_loss: 63.9625\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.5627 - val_loss: 81.4940\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.6203 - val_loss: 74.8956\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2696 - val_loss: 70.8221\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.2807 - val_loss: 68.6319\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.2698 - val_loss: 64.4703\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 103.1432 - val_loss: 63.0767\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.9617 - val_loss: 68.8576\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7405 - val_loss: 63.5070\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.9922 - val_loss: 71.9463\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.3084 - val_loss: 65.5570\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 74.7454 - val_loss: 62.3660\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.1450 - val_loss: 69.6585\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.6420 - val_loss: 65.1659\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.0929 - val_loss: 68.7095\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.0707 - val_loss: 64.1389\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.1283 - val_loss: 64.8539\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7293 - val_loss: 64.9471\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3033 - val_loss: 63.3529\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.6705 - val_loss: 64.5780\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8928 - val_loss: 62.9353\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1836 - val_loss: 62.4130\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0506 - val_loss: 66.5707\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4705 - val_loss: 67.6149\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8111 - val_loss: 64.2168\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.2466 - val_loss: 63.4556\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2180 - val_loss: 64.5729\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1152 - val_loss: 70.6732\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.0450 - val_loss: 62.5550\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4129 - val_loss: 64.3343\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3677 - val_loss: 67.5768\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3991 - val_loss: 66.3027\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1971 - val_loss: 69.0532\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.9200 - val_loss: 69.3697\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2984 - val_loss: 64.6232\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.7898 - val_loss: 69.1867\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3452 - val_loss: 66.9689\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.8833 - val_loss: 62.4688\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.0251 - val_loss: 64.9024\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.9513 - val_loss: 64.9768\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2980 - val_loss: 64.7971\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.0651 - val_loss: 62.8041\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.2967 - val_loss: 64.8022\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7043 - val_loss: 60.5847\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.9702 - val_loss: 64.9513\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.0841 - val_loss: 61.8087\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.4747 - val_loss: 68.6150\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.2959 - val_loss: 67.8351\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5298 - val_loss: 61.6241\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6919 - val_loss: 68.3882\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2868 - val_loss: 60.2893\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6641 - val_loss: 62.2809\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.5405 - val_loss: 61.7148\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.5591 - val_loss: 62.5216\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.6323 - val_loss: 62.6006\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.4971 - val_loss: 68.8123\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.4880 - val_loss: 70.9729\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7680 - val_loss: 61.8800\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3737 - val_loss: 60.7422\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9950 - val_loss: 86.4325\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2867 - val_loss: 62.8396\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7240 - val_loss: 64.6391\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.1709 - val_loss: 71.3471\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.0104 - val_loss: 65.1015\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 70.6522 - val_loss: 69.0976\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4835 - val_loss: 64.3670\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.2410 - val_loss: 62.0249\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4579 - val_loss: 61.4571\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3247 - val_loss: 62.7067\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9274 - val_loss: 63.5634\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.5164 - val_loss: 62.7887\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.7453 - val_loss: 72.6090\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.7105 - val_loss: 67.2850\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5168 - val_loss: 66.2591\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1096 - val_loss: 61.3332\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9060 - val_loss: 63.6770\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9028 - val_loss: 64.6860\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.2901 - val_loss: 64.2160\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.0273 - val_loss: 63.4812\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.3795 - val_loss: 62.1007\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.9138 - val_loss: 62.7886\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 77.3318 - val_loss: 61.1814\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.8405 - val_loss: 62.3292\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 62.5241 - val_loss: 62.2269\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.8899 - val_loss: 77.5990\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.3475 - val_loss: 64.8437\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1660 - val_loss: 66.7421\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.0675 - val_loss: 68.7234\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5021 - val_loss: 63.4184\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.5745 - val_loss: 63.5732\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.9937 - val_loss: 67.5011\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.9746 - val_loss: 70.0700\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.8596 - val_loss: 70.9368\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.3068 - val_loss: 63.1690\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4321 - val_loss: 62.4879\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1149 - val_loss: 62.4318\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2576 - val_loss: 60.9321\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2648 - val_loss: 64.9537\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.0836 - val_loss: 77.5378\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.3582 - val_loss: 63.7101\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.0433 - val_loss: 68.6772\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 61.7360 - val_loss: 59.5365\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3010 - val_loss: 63.3844\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.7486 - val_loss: 61.1328\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2272 - val_loss: 69.6427\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2296 - val_loss: 61.8943\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.7723 - val_loss: 63.3658\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.2567 - val_loss: 66.9448\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2650 - val_loss: 61.9391\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.8846 - val_loss: 64.6277\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.3744 - val_loss: 60.6400\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.7721 - val_loss: 65.0264\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0599 - val_loss: 64.3646\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7919 - val_loss: 63.6960\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4075 - val_loss: 66.4380\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.0919 - val_loss: 61.9886\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.2851 - val_loss: 66.3424\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.0719 - val_loss: 63.3424\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.9518 - val_loss: 65.9766\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.9323 - val_loss: 67.2897\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.2230 - val_loss: 61.9735\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 72.8891 - val_loss: 61.1097\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8790 - val_loss: 62.9649\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.3508 - val_loss: 62.9338\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.1447 - val_loss: 64.2688\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.2493 - val_loss: 60.7113\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.5012 - val_loss: 69.0657\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8684 - val_loss: 71.0423\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5143 - val_loss: 71.5153\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9807 - val_loss: 67.9751\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8727 - val_loss: 63.6058\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6609 - val_loss: 64.1712\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1239 - val_loss: 62.1736\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5182 - val_loss: 65.3930\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.5704 - val_loss: 62.0818\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6683 - val_loss: 63.3292\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6503 - val_loss: 64.0100\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1134 - val_loss: 61.5921\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.2531 - val_loss: 65.2204\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 59.9131\n",
      "--- Starting trial: run-54\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 256, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6828 - val_loss: 660.2914\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.4866 - val_loss: 660.0660\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2504 - val_loss: 659.7999\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9658 - val_loss: 659.4901\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6255 - val_loss: 659.1152\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2231 - val_loss: 658.6813\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7532 - val_loss: 658.1789\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2117 - val_loss: 657.5855\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 686.5951 - val_loss: 656.9307\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9006 - val_loss: 656.2056\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1259 - val_loss: 655.4011\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.2692 - val_loss: 654.4971\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3289 - val_loss: 653.5265\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.3040 - val_loss: 652.4501\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.1932 - val_loss: 651.2924\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.9960 - val_loss: 650.0391\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.7116 - val_loss: 648.7028\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 677.3394 - val_loss: 647.3025\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 675.8792 - val_loss: 645.7706\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 674.3305 - val_loss: 644.1638\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.6931 - val_loss: 642.4735\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.9669 - val_loss: 640.7126\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.1518 - val_loss: 638.8662\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.2474 - val_loss: 636.8976\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.2542 - val_loss: 634.8718\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 663.1719 - val_loss: 632.7556\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.0007 - val_loss: 630.4859\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.7405 - val_loss: 628.1529\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.3915 - val_loss: 625.7584\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 653.9539 - val_loss: 623.2471\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.4277 - val_loss: 620.6509\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 648.8132 - val_loss: 617.9550\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.1104 - val_loss: 615.2038\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.3196 - val_loss: 612.3832\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 640.4410 - val_loss: 609.4594\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.4746 - val_loss: 606.4093\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.4209 - val_loss: 603.2979\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.2800 - val_loss: 600.0846\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.0520 - val_loss: 596.8411\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 624.7372 - val_loss: 593.5081\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 621.3359 - val_loss: 590.0719\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.8483 - val_loss: 586.4886\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.2747 - val_loss: 582.8612\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.6152 - val_loss: 579.2144\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.8701 - val_loss: 575.3821\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.0397 - val_loss: 571.5284\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.1242 - val_loss: 567.6009\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.1237 - val_loss: 563.6713\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.0388 - val_loss: 559.5517\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.8694 - val_loss: 555.3541\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.6160 - val_loss: 550.9943\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.4210 - val_loss: 557.8158\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 573.8722 - val_loss: 578.6182\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.3795 - val_loss: 577.4378\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.7966 - val_loss: 570.6871\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.1279 - val_loss: 563.4505\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.3754 - val_loss: 556.7200\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.5399 - val_loss: 549.8335\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 545.6222 - val_loss: 543.6993\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 540.6224 - val_loss: 537.3309\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.5411 - val_loss: 531.3513\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.3784 - val_loss: 525.1605\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.1345 - val_loss: 518.7878\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.8098 - val_loss: 512.7907\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.4044 - val_loss: 507.2581\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 508.9187 - val_loss: 501.7131\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 503.3529 - val_loss: 495.7910\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.7072 - val_loss: 490.2097\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 491.9819 - val_loss: 484.4802\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.1771 - val_loss: 478.1568\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.2932 - val_loss: 472.4354\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.3304 - val_loss: 466.8440\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.3456 - val_loss: 478.6402\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.3647 - val_loss: 486.8106\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.0527 - val_loss: 494.9075\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.8321 - val_loss: 488.6640\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.5001 - val_loss: 477.6516\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 437.0764 - val_loss: 467.6172\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.5695 - val_loss: 456.5615\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.0966 - val_loss: 453.2317\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 417.3409 - val_loss: 448.8193\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 410.6106 - val_loss: 439.8009\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.7969 - val_loss: 430.0364\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 396.9040 - val_loss: 420.7446\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 389.9340 - val_loss: 411.9526\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 382.8877 - val_loss: 402.7130\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.7657 - val_loss: 393.8636\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368.5683 - val_loss: 384.6648\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.2960 - val_loss: 376.5069\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 354.0190 - val_loss: 369.0451\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 346.5799 - val_loss: 361.0453\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.3861 - val_loss: 355.5399\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 331.9670 - val_loss: 352.6129\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 324.1078 - val_loss: 347.2374\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 316.7407 - val_loss: 340.7672\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 309.8445 - val_loss: 329.1941\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 301.1581 - val_loss: 317.4757\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.4103 - val_loss: 309.6643\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.5427 - val_loss: 314.4166\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 278.6925 - val_loss: 309.1479\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 271.5287 - val_loss: 307.6414\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 262.3279 - val_loss: 298.0360\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.5146 - val_loss: 289.1909\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 246.6006 - val_loss: 278.5312\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 238.9532 - val_loss: 263.6765\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 230.6556 - val_loss: 250.4432\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 222.1520 - val_loss: 253.9774\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 213.0759 - val_loss: 249.2957\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.0199 - val_loss: 243.7794\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 196.5755 - val_loss: 231.8542\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 200.6429 - val_loss: 220.9395\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.9509 - val_loss: 206.4413\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 173.1825 - val_loss: 198.4083\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 164.7706 - val_loss: 189.9276\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 158.0931 - val_loss: 178.4820\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.2866 - val_loss: 169.5340\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.1740 - val_loss: 161.3812\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 146.6457 - val_loss: 154.8215\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 134.1758 - val_loss: 152.8988\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 132.7169 - val_loss: 146.9859\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.9909 - val_loss: 137.5555\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.0828 - val_loss: 129.3934\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 149.4544 - val_loss: 127.1745\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.7257 - val_loss: 115.9107\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.3078 - val_loss: 112.2870\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.0114 - val_loss: 115.4675\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1357 - val_loss: 121.0484\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.8744 - val_loss: 108.0888\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.5645 - val_loss: 96.0232\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4178 - val_loss: 105.6429\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1057 - val_loss: 105.0950\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.5653 - val_loss: 91.9189\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.6568 - val_loss: 93.4074\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9663 - val_loss: 88.6933\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6242 - val_loss: 88.7259\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9993 - val_loss: 92.2170\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4694 - val_loss: 89.2187\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7001 - val_loss: 79.0002\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 85.1740 - val_loss: 86.6856\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.9130 - val_loss: 80.8315\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1647 - val_loss: 71.3015\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7851 - val_loss: 77.3831\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.5648 - val_loss: 75.9235\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.1702 - val_loss: 77.0889\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 103.9957 - val_loss: 76.5227\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.9370 - val_loss: 75.7838\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 88.0315 - val_loss: 72.8225\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6660 - val_loss: 73.3473\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1427 - val_loss: 78.4104\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.5670 - val_loss: 78.7246\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.0443 - val_loss: 78.8648\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.8524 - val_loss: 71.3951\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.5995 - val_loss: 69.8661\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 84.5365 - val_loss: 72.5806\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.3754 - val_loss: 77.2620\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 102.1869 - val_loss: 86.9622\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.4967 - val_loss: 92.0751\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7234 - val_loss: 83.8420\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.3296 - val_loss: 86.1835\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2283 - val_loss: 86.3402\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.8730 - val_loss: 90.3061\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.4954 - val_loss: 92.2321\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.2720 - val_loss: 79.0880\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9995 - val_loss: 72.6049\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2534 - val_loss: 69.2437\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.6856 - val_loss: 73.3701\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3218 - val_loss: 74.1691\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.4677 - val_loss: 71.9653\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9508 - val_loss: 70.0209\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.4235 - val_loss: 69.0326\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.8554 - val_loss: 68.7639\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6676 - val_loss: 68.3417\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2998 - val_loss: 70.2226\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 111.3216 - val_loss: 78.0203\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.3371 - val_loss: 77.5577\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.0220 - val_loss: 71.7764\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.5425 - val_loss: 69.6396\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 135.2842 - val_loss: 69.7326\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5762 - val_loss: 67.0699\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8268 - val_loss: 65.1848\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6744 - val_loss: 65.9989\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.9261 - val_loss: 63.0175\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.3937 - val_loss: 62.6379\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1452 - val_loss: 65.5575\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.5337 - val_loss: 65.5940\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.5869 - val_loss: 63.3806\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6642 - val_loss: 70.3175\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6717 - val_loss: 79.8983\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0190 - val_loss: 81.8072\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2819 - val_loss: 74.7319\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7098 - val_loss: 70.2021\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.4245 - val_loss: 70.7631\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.0440 - val_loss: 70.6599\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5376 - val_loss: 70.1087\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.7518 - val_loss: 69.9128\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3684 - val_loss: 70.0408\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.4336 - val_loss: 68.6201\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7508 - val_loss: 70.3866\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.1191 - val_loss: 66.1148\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.3528 - val_loss: 66.0114\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8832 - val_loss: 70.2021\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4485 - val_loss: 80.4795\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4926 - val_loss: 81.0782\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 69.8981 - val_loss: 69.0026\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.0589 - val_loss: 64.3950\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.0408 - val_loss: 65.3380\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.2725 - val_loss: 64.8713\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.5864 - val_loss: 64.5852\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3330 - val_loss: 65.2937\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1686 - val_loss: 64.6277\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9793 - val_loss: 63.8110\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0872 - val_loss: 64.0333\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.8615 - val_loss: 67.4093\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.5317 - val_loss: 73.4005\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.5942 - val_loss: 69.8415\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1891 - val_loss: 66.8994\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1956 - val_loss: 67.0874\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.1413 - val_loss: 64.7940\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6830 - val_loss: 67.0144\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7401 - val_loss: 65.4468\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.4187 - val_loss: 64.4479\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2020 - val_loss: 65.2103\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.2520 - val_loss: 64.1399\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.1447 - val_loss: 65.1707\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7034 - val_loss: 67.5770\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.2359 - val_loss: 65.8475\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.2928 - val_loss: 63.4942\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.6779 - val_loss: 62.5318\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9171 - val_loss: 62.3709\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2294 - val_loss: 63.9642\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.6950 - val_loss: 64.5739\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.6356 - val_loss: 66.9344\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2724 - val_loss: 63.1704\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.9993 - val_loss: 62.8478\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3682 - val_loss: 66.2206\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9610 - val_loss: 69.0931\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.1427 - val_loss: 69.1736\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.8403 - val_loss: 67.1500\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.4318 - val_loss: 67.6671\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.8217 - val_loss: 64.3103\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.2926 - val_loss: 63.0340\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2641 - val_loss: 64.3129\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4981 - val_loss: 62.9975\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0776 - val_loss: 62.6999\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.4458 - val_loss: 61.3154\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3551 - val_loss: 62.8162\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.5411 - val_loss: 64.0782\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8595 - val_loss: 63.7359\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.4171 - val_loss: 65.1911\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0451 - val_loss: 63.1137\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 44.3620\n",
      "--- Starting trial: run-55\n",
      "{'activation': 'linear', 'dropout': 0.2, 'num_units': 256, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6533 - val_loss: 660.0412\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4014 - val_loss: 659.7818\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.1434 - val_loss: 659.5142\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.8752 - val_loss: 659.2299\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.5917 - val_loss: 658.9264\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 688.2878 - val_loss: 658.6059\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.9579 - val_loss: 658.2435\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.5954 - val_loss: 657.8339\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.1932 - val_loss: 657.3974\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.7433 - val_loss: 656.8925\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.2359 - val_loss: 656.3266\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.6605 - val_loss: 655.6725\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.0043 - val_loss: 654.9357\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.2528 - val_loss: 654.0898\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3888 - val_loss: 653.1200\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.3925 - val_loss: 651.9850\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.2405 - val_loss: 650.6936\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.9055 - val_loss: 649.2029\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.3560 - val_loss: 647.4770\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.5543 - val_loss: 645.4589\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.4568 - val_loss: 643.0925\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.0123 - val_loss: 640.3337\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.1606 - val_loss: 637.1608\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.8315 - val_loss: 633.4568\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 661.9423 - val_loss: 629.0779\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 657.3962 - val_loss: 624.0219\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 652.0800 - val_loss: 618.0883\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 645.8606 - val_loss: 611.1049\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 638.5819 - val_loss: 602.9889\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.0612 - val_loss: 593.5335\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.0840 - val_loss: 582.4519\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 608.3992 - val_loss: 569.4690\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.7118 - val_loss: 554.3162\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.7578 - val_loss: 543.9147\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.4092 - val_loss: 523.3531\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 538.4811 - val_loss: 499.8000\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 512.9561 - val_loss: 475.0778\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 483.1985 - val_loss: 448.1862\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 448.4192 - val_loss: 412.4489\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 411.0180 - val_loss: 381.9962\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368.6381 - val_loss: 368.7107\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 320.4199 - val_loss: 316.8397\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 270.1353 - val_loss: 270.8061\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 223.9042 - val_loss: 257.7742\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.9693 - val_loss: 248.3568\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 145.5926 - val_loss: 394.6860\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0629 - val_loss: 365.9882\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3720 - val_loss: 397.8926\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3106 - val_loss: 465.4502\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1942 - val_loss: 304.0063\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1932 - val_loss: 355.5760\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.2675 - val_loss: 379.1245\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7252 - val_loss: 319.2864\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.8514 - val_loss: 320.2129\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7754 - val_loss: 301.9872\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5935 - val_loss: 259.4441\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5680 - val_loss: 199.0851\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.9084 - val_loss: 221.5272\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5814 - val_loss: 219.7209\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3763 - val_loss: 228.2104\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.3783 - val_loss: 192.9275\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.6749 - val_loss: 213.0865\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2479 - val_loss: 195.0052\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.9860 - val_loss: 131.9348\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.0938 - val_loss: 191.2110\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2989 - val_loss: 125.1721\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.0060 - val_loss: 169.6369\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3672 - val_loss: 113.3500\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6171 - val_loss: 132.7075\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.3385 - val_loss: 146.3195\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.1726 - val_loss: 128.1095\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9458 - val_loss: 124.3065\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.5694 - val_loss: 141.8848\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5131 - val_loss: 131.1006\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.0091 - val_loss: 110.1844\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.5956 - val_loss: 115.7847\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.9665 - val_loss: 124.0229\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.5527 - val_loss: 139.6188\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2546 - val_loss: 96.5677\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8841 - val_loss: 91.6100\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.2689 - val_loss: 67.5389\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3296 - val_loss: 91.4598\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 94.1153 - val_loss: 76.7721\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1115 - val_loss: 117.6890\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.9146 - val_loss: 84.5586\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.7182 - val_loss: 89.2121\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.9632 - val_loss: 86.8024\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.1682 - val_loss: 76.7820\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3651 - val_loss: 100.6668\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6644 - val_loss: 84.7490\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7808 - val_loss: 99.5277\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.7860 - val_loss: 92.1341\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7076 - val_loss: 70.0562\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1737 - val_loss: 95.1571\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.1463 - val_loss: 90.2126\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2551 - val_loss: 91.1168\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.6614 - val_loss: 94.6200\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.5338 - val_loss: 80.4245\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0121 - val_loss: 67.1681\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.6269 - val_loss: 82.0479\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4654 - val_loss: 73.4203\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.6926 - val_loss: 83.5201\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.2408 - val_loss: 84.2612\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.2239 - val_loss: 133.1305\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7615 - val_loss: 89.2349\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3517 - val_loss: 92.2140\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3893 - val_loss: 87.0375\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.8269 - val_loss: 66.9847\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5515 - val_loss: 103.2398\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.8757 - val_loss: 82.9852\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.8410 - val_loss: 75.6551\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.7286 - val_loss: 66.1521\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.8086 - val_loss: 71.1780\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6059 - val_loss: 77.0475\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1332 - val_loss: 94.2312\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 92.4955 - val_loss: 90.7628\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2824 - val_loss: 76.5991\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1213 - val_loss: 72.5294\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0852 - val_loss: 69.1761\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6547 - val_loss: 64.8645\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5572 - val_loss: 75.3416\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5541 - val_loss: 75.2335\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.0902 - val_loss: 74.3624\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.7133 - val_loss: 64.7008\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 131.1439 - val_loss: 65.9373\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.6168 - val_loss: 64.6618\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1798 - val_loss: 64.8984\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0812 - val_loss: 68.5898\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.0287 - val_loss: 64.7272\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2822 - val_loss: 79.3302\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.8653 - val_loss: 87.0386\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7006 - val_loss: 82.9106\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9535 - val_loss: 65.7531\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7923 - val_loss: 75.4951\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1494 - val_loss: 82.9832\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.2610 - val_loss: 75.0180\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4842 - val_loss: 76.1400\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.1974 - val_loss: 71.5634\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5249 - val_loss: 67.8444\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.6293 - val_loss: 74.5012\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4281 - val_loss: 82.9939\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.5785 - val_loss: 79.7902\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5654 - val_loss: 77.7562\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1798 - val_loss: 76.0926\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1088 - val_loss: 64.9479\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.9184 - val_loss: 79.1141\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.1439 - val_loss: 81.3533\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6571 - val_loss: 102.5919\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.9912 - val_loss: 74.3265\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.9366 - val_loss: 77.7681\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 73.1415 - val_loss: 76.5276\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.7166 - val_loss: 78.7570\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.0495 - val_loss: 76.0315\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.6620 - val_loss: 84.0111\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.6096 - val_loss: 82.5479\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.4779 - val_loss: 73.6089\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3035 - val_loss: 78.5620\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2039 - val_loss: 66.9918\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.5483 - val_loss: 67.4855\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.3984 - val_loss: 75.4847\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.1319 - val_loss: 69.3631\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.0956 - val_loss: 71.1544\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.5499 - val_loss: 65.9996\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6961 - val_loss: 68.6629\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4073 - val_loss: 70.1401\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5132 - val_loss: 69.4412\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.3049 - val_loss: 76.8575\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 105.6035 - val_loss: 67.5755\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 90.6344 - val_loss: 69.7403\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.5552 - val_loss: 72.7844\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.2030 - val_loss: 68.6010\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 82.8706 - val_loss: 67.7413\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9815 - val_loss: 69.8943\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6170 - val_loss: 76.7434\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 78.8247 - val_loss: 71.0262\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.8208 - val_loss: 68.5441\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.4125 - val_loss: 65.4111\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2212 - val_loss: 68.0726\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.9370 - val_loss: 66.7613\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.6133 - val_loss: 67.2100\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.0805 - val_loss: 67.8451\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7049 - val_loss: 66.4075\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.2068 - val_loss: 63.6926\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 100.6718 - val_loss: 63.5627\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6752 - val_loss: 65.6842\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1307 - val_loss: 70.8515\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1081 - val_loss: 63.8994\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1644 - val_loss: 68.6688\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.7218 - val_loss: 68.1451\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6654 - val_loss: 69.4215\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2034 - val_loss: 71.9887\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.4558 - val_loss: 71.0241\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9193 - val_loss: 78.7204\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0517 - val_loss: 68.2545\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2059 - val_loss: 69.4850\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9322 - val_loss: 65.6640\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1304 - val_loss: 69.4215\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7506 - val_loss: 67.6575\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9536 - val_loss: 66.2151\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5777 - val_loss: 64.3811\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0178 - val_loss: 70.0288\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5289 - val_loss: 68.5242\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.2689 - val_loss: 66.0948\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 127.1782 - val_loss: 64.6238\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.4514 - val_loss: 68.2617\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.0709 - val_loss: 74.0832\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7910 - val_loss: 86.7116\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.7932 - val_loss: 82.7390\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2665 - val_loss: 72.9686\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7225 - val_loss: 79.2594\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1741 - val_loss: 68.0286\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5529 - val_loss: 67.2588\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0631 - val_loss: 74.5091\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.0462 - val_loss: 81.6490\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.2456 - val_loss: 81.1154\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.9356 - val_loss: 67.7931\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 64.8321 - val_loss: 70.4738\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6371 - val_loss: 65.3244\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.0855 - val_loss: 63.6657\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7603 - val_loss: 65.9501\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1480 - val_loss: 67.8135\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.5457 - val_loss: 64.4733\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9712 - val_loss: 63.5258\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.5386 - val_loss: 62.9136\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5891 - val_loss: 66.1010\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.9042 - val_loss: 62.4333\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.8898 - val_loss: 68.0378\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.6042 - val_loss: 64.5278\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.3430 - val_loss: 67.7867\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8985 - val_loss: 64.7262\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.9024 - val_loss: 63.6296\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4623 - val_loss: 67.5040\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.6741 - val_loss: 70.7826\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.2724 - val_loss: 66.7369\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5119 - val_loss: 72.2589\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.5753 - val_loss: 66.5059\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8176 - val_loss: 64.8838\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5775 - val_loss: 70.4599\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.5807 - val_loss: 65.1735\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9939 - val_loss: 69.0243\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0651 - val_loss: 64.1366\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.0036 - val_loss: 65.3209\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3432 - val_loss: 67.1933\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.8992 - val_loss: 75.7129\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.2897 - val_loss: 71.3092\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.8014 - val_loss: 67.3558\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.8059 - val_loss: 70.0180\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.4928 - val_loss: 75.1123\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5916 - val_loss: 67.2726\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3636 - val_loss: 77.6197\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 62.8053\n",
      "--- Starting trial: run-56\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 256, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 16ms/step - loss: 689.6870 - val_loss: 660.2260\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.5016 - val_loss: 660.0708\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.2760 - val_loss: 659.8672\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 689.0020 - val_loss: 659.6174\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6719 - val_loss: 659.3017\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2792 - val_loss: 658.9169\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.8187 - val_loss: 658.4492\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.2860 - val_loss: 657.9120\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6775 - val_loss: 657.3025\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.9906 - val_loss: 656.6023\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.2229 - val_loss: 655.8239\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3726 - val_loss: 654.9609\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.4382 - val_loss: 654.0128\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.4185 - val_loss: 652.9642\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.3127 - val_loss: 651.8257\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.1199 - val_loss: 650.6115\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 678.8394 - val_loss: 649.3081\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.4708 - val_loss: 647.9120\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 676.0137 - val_loss: 646.4253\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.4679 - val_loss: 644.8503\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.8331 - val_loss: 643.1865\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.1091 - val_loss: 641.4444\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.2958 - val_loss: 639.5960\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.3934 - val_loss: 637.7264\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.4016 - val_loss: 635.6890\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.3206 - val_loss: 633.5947\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.1505 - val_loss: 631.4571\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.8913 - val_loss: 629.1945\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.5432 - val_loss: 626.8395\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.1061 - val_loss: 624.3632\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.5804 - val_loss: 621.8256\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.9664 - val_loss: 619.2305\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.2637 - val_loss: 616.4539\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.4731 - val_loss: 613.6262\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 640.5945 - val_loss: 610.7770\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 637.6283 - val_loss: 607.7701\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.5745 - val_loss: 604.6658\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.4333 - val_loss: 601.4718\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.2052 - val_loss: 598.1633\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 624.8901 - val_loss: 594.7009\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.4885 - val_loss: 591.2696\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 618.0005 - val_loss: 587.8101\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.4265 - val_loss: 584.3880\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.7665 - val_loss: 580.8109\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.0209 - val_loss: 576.9954\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.1899 - val_loss: 573.1906\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.2739 - val_loss: 569.2870\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.2728 - val_loss: 565.2842\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.1873 - val_loss: 560.9833\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 587.0172 - val_loss: 556.7573\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 582.7632 - val_loss: 552.2985\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.4252 - val_loss: 548.1505\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.0036 - val_loss: 543.6594\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.4986 - val_loss: 538.9255\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.9105 - val_loss: 534.1642\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.2396 - val_loss: 529.2286\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.4861 - val_loss: 524.2361\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.8231 - val_loss: 529.7525\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.7507 - val_loss: 538.5534\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.7601 - val_loss: 537.0094\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.6821 - val_loss: 531.6725\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.5204 - val_loss: 525.5150\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.2766 - val_loss: 518.9709\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.9514 - val_loss: 512.3975\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.5582 - val_loss: 498.7507\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.0782 - val_loss: 489.8533\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.5343 - val_loss: 502.3786\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 497.9034 - val_loss: 501.9791\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.1855 - val_loss: 496.7552\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.3827 - val_loss: 489.9399\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 480.4984 - val_loss: 481.7717\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 474.6065 - val_loss: 469.8940\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.5157 - val_loss: 459.7067\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.4041 - val_loss: 452.1100\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.2077 - val_loss: 445.2443\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 449.9308 - val_loss: 438.7875\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 443.5748 - val_loss: 432.2563\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 437.2661 - val_loss: 434.1827\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 430.6558 - val_loss: 432.8318\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.2111 - val_loss: 435.3383\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.4339 - val_loss: 436.2595\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.7692 - val_loss: 429.2461\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 403.9181 - val_loss: 419.1956\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.3115 - val_loss: 400.4311\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 390.6725 - val_loss: 394.9778\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 383.6824 - val_loss: 386.1180\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 376.4070 - val_loss: 375.6590\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 371.0410 - val_loss: 366.5036\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 362.4924 - val_loss: 359.3825\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 355.5426 - val_loss: 365.2171\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 347.9970 - val_loss: 365.8315\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 340.5667 - val_loss: 359.4960\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 333.1470 - val_loss: 351.5958\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.5070 - val_loss: 343.7573\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 317.7345 - val_loss: 344.0806\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.6293 - val_loss: 341.7776\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 302.5970 - val_loss: 335.8214\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 294.9637 - val_loss: 323.7228\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.9130 - val_loss: 306.6585\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 280.1546 - val_loss: 304.6621\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 271.5387 - val_loss: 298.8579\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 263.0218 - val_loss: 291.7665\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 254.7259 - val_loss: 282.1477\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.8375 - val_loss: 277.7311\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 245.6822 - val_loss: 282.9778\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 231.2957 - val_loss: 277.5934\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 224.5250 - val_loss: 264.7157\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 222.4492 - val_loss: 217.9984\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 211.9424 - val_loss: 204.1855\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 203.9577 - val_loss: 205.6835\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 194.0087 - val_loss: 200.8439\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.0094 - val_loss: 195.4155\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.6448 - val_loss: 175.3701\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 174.1118 - val_loss: 177.6849\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 163.0340 - val_loss: 184.2051\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.1698 - val_loss: 171.2433\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 158.7024 - val_loss: 154.3015\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 156.9403 - val_loss: 148.1287\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 133.5499 - val_loss: 148.3415\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.8831 - val_loss: 151.0994\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 124.6836 - val_loss: 144.4919\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 120.1983 - val_loss: 139.2688\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.2214 - val_loss: 135.1045\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.9380 - val_loss: 135.4925\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.2274 - val_loss: 138.6159\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.0708 - val_loss: 130.1545\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.9300 - val_loss: 129.6972\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9663 - val_loss: 136.0138\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0775 - val_loss: 125.8075\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7543 - val_loss: 126.6567\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.4235 - val_loss: 122.6086\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7484 - val_loss: 123.4174\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.1259 - val_loss: 124.3715\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 100.4386 - val_loss: 107.7429\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8209 - val_loss: 106.6341\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.9667 - val_loss: 103.5842\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.5236 - val_loss: 99.7957\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 104.9102 - val_loss: 98.4179\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.9474 - val_loss: 94.7297\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 68.0532 - val_loss: 88.0325\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0046 - val_loss: 86.0397\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0687 - val_loss: 90.6801\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6750 - val_loss: 89.4403\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3671 - val_loss: 84.9464\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.2802 - val_loss: 82.8962\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1004 - val_loss: 79.6810\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7004 - val_loss: 79.1334\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4377 - val_loss: 76.6753\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7614 - val_loss: 78.1028\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.3748 - val_loss: 77.0631\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9160 - val_loss: 76.4833\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6664 - val_loss: 75.8854\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1394 - val_loss: 73.3018\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 46.1194 - val_loss: 69.8499\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2205 - val_loss: 67.5793\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 66.0543 - val_loss: 67.8714\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.4378 - val_loss: 69.4671\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.3973 - val_loss: 68.0829\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.8905 - val_loss: 69.7609\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0706 - val_loss: 67.9616\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2789 - val_loss: 65.6880\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.4255 - val_loss: 64.8393\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.6616 - val_loss: 63.3556\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9315 - val_loss: 61.1225\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9723 - val_loss: 59.5242\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.4409 - val_loss: 60.4875\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.0885 - val_loss: 60.4936\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1171 - val_loss: 58.5080\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.1557 - val_loss: 62.5889\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0566 - val_loss: 62.7526\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.8063 - val_loss: 58.6561\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6098 - val_loss: 59.1924\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.8477 - val_loss: 59.7629\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.9780 - val_loss: 64.9759\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1924 - val_loss: 68.1128\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5202 - val_loss: 64.3154\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8712 - val_loss: 62.1430\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 70.3611 - val_loss: 60.2393\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.3755 - val_loss: 60.6591\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7931 - val_loss: 62.9116\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7371 - val_loss: 64.4037\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.2073 - val_loss: 63.1361\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.4720 - val_loss: 59.8833\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.0708 - val_loss: 59.8342\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.4163 - val_loss: 61.2060\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.0665 - val_loss: 65.3148\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 67.4734 - val_loss: 63.6122\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 62.5797 - val_loss: 60.1754\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 49.2575 - val_loss: 58.7185\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 81.5859 - val_loss: 58.2710\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.6830 - val_loss: 60.0987\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7207 - val_loss: 60.5875\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.8806 - val_loss: 59.6687\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.4712 - val_loss: 58.4197\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.6719 - val_loss: 57.1128\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.3739 - val_loss: 59.1881\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1386 - val_loss: 60.1904\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6313 - val_loss: 59.0731\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 52.0158 - val_loss: 59.0247\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.0983 - val_loss: 57.3416\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.5543 - val_loss: 57.0985\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.9529 - val_loss: 58.6931\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 49.3686 - val_loss: 62.9424\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5309 - val_loss: 59.4838\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.7773 - val_loss: 57.4297\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7136 - val_loss: 58.5211\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8345 - val_loss: 57.8112\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.6713 - val_loss: 58.6034\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.4622 - val_loss: 66.9105\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8720 - val_loss: 68.1850\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.3871 - val_loss: 65.7834\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.3033 - val_loss: 61.7596\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 75.1751 - val_loss: 58.2853\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.6729 - val_loss: 58.3888\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.9895 - val_loss: 59.9060\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.2947 - val_loss: 62.1147\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.6531 - val_loss: 64.1144\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3614 - val_loss: 63.0802\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4744 - val_loss: 61.0509\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1038 - val_loss: 62.4816\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.5955 - val_loss: 64.0103\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.0053 - val_loss: 65.5635\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6619 - val_loss: 61.9762\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3936 - val_loss: 59.7184\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3599 - val_loss: 58.9681\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9276 - val_loss: 60.1948\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5074 - val_loss: 62.1268\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.9348 - val_loss: 61.9694\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.3538 - val_loss: 59.9155\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.7837 - val_loss: 59.2711\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.7692 - val_loss: 59.9390\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7553 - val_loss: 60.4557\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.6922 - val_loss: 60.7481\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.2779 - val_loss: 62.0291\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.7354 - val_loss: 64.4342\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1071 - val_loss: 64.2125\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7378 - val_loss: 65.3242\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.0289 - val_loss: 66.1539\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9333 - val_loss: 66.5073\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8370 - val_loss: 70.9905\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.2180 - val_loss: 71.2610\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.7053 - val_loss: 69.5905\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3501 - val_loss: 70.4174\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.1303 - val_loss: 63.6964\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7395 - val_loss: 61.7435\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.9409 - val_loss: 61.4363\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.6307 - val_loss: 61.5449\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1191 - val_loss: 60.9754\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.7095 - val_loss: 62.3191\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5375 - val_loss: 62.8662\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 30.2577\n",
      "--- Starting trial: run-57\n",
      "{'activation': 'relu', 'dropout': 0.2, 'num_units': 256, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6608 - val_loss: 660.1707\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4285 - val_loss: 659.9501\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.1908 - val_loss: 659.7259\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.9439 - val_loss: 659.4874\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.6835 - val_loss: 659.2278\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.4051 - val_loss: 658.9465\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.1035 - val_loss: 658.6368\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7732 - val_loss: 658.2969\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.4075 - val_loss: 657.9205\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.9994 - val_loss: 657.4995\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.5406 - val_loss: 657.0258\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.0214 - val_loss: 656.4888\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.4307 - val_loss: 655.8707\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.7554 - val_loss: 655.1577\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.9802 - val_loss: 654.3492\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.0879 - val_loss: 653.3984\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.0576 - val_loss: 652.2957\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.8651 - val_loss: 651.0236\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.4823 - val_loss: 649.5361\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.8760 - val_loss: 647.8190\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 676.0075 - val_loss: 645.7922\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.8314 - val_loss: 643.4592\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 671.2942 - val_loss: 640.7008\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 668.3337 - val_loss: 637.4944\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 664.8769 - val_loss: 633.7386\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 660.8376 - val_loss: 629.3450\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.1157 - val_loss: 624.1984\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 650.5929 - val_loss: 618.1813\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 644.1312 - val_loss: 611.1124\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 636.5684 - val_loss: 602.8783\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 627.7144 - val_loss: 593.2051\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.3466 - val_loss: 581.8737\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.2034 - val_loss: 568.6541\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 590.9785 - val_loss: 553.0850\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.3792 - val_loss: 538.2407\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 554.9507 - val_loss: 517.7676\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 532.4334 - val_loss: 498.8560\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 506.1009 - val_loss: 473.2776\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 475.9339 - val_loss: 446.1931\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 440.5999 - val_loss: 416.9069\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.5053 - val_loss: 374.4854\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 364.9559 - val_loss: 341.5398\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 322.9621 - val_loss: 299.8280\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 286.0942 - val_loss: 298.3910\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 251.0746 - val_loss: 279.9401\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 206.1986 - val_loss: 273.0415\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 183.3021 - val_loss: 236.9243\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 150.0033 - val_loss: 257.9227\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.6031 - val_loss: 277.6347\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 110.7189 - val_loss: 272.1038\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.1068 - val_loss: 281.9182\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.3179 - val_loss: 328.3498\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.3510 - val_loss: 309.5869\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.5600 - val_loss: 280.0584\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.2068 - val_loss: 248.7020\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 87.3826 - val_loss: 231.6184\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.3977 - val_loss: 211.9249\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3300 - val_loss: 231.7677\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9693 - val_loss: 200.8592\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.5554 - val_loss: 163.3251\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.9286 - val_loss: 127.8797\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1196 - val_loss: 165.0010\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.8012 - val_loss: 146.4296\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.7423 - val_loss: 132.1700\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5957 - val_loss: 133.7665\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2161 - val_loss: 129.3696\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6365 - val_loss: 110.0864\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4670 - val_loss: 145.5704\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0013 - val_loss: 132.9050\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.3015 - val_loss: 92.1259\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.3808 - val_loss: 108.5952\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.3309 - val_loss: 99.0204\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 94.4266 - val_loss: 94.7832\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.0714 - val_loss: 92.7839\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 109.8196 - val_loss: 91.4575\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5162 - val_loss: 88.3795\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0448 - val_loss: 79.5227\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.9345 - val_loss: 66.3279\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2701 - val_loss: 110.6800\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5496 - val_loss: 129.8799\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.4237 - val_loss: 102.1236\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 117.0490 - val_loss: 99.6085\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6427 - val_loss: 91.0325\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.6581 - val_loss: 80.3329\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.1092 - val_loss: 79.7302\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.4588 - val_loss: 78.4022\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.3915 - val_loss: 83.5956\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 84.8901 - val_loss: 90.1099\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 88.5146 - val_loss: 92.1371\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.3881 - val_loss: 83.4144\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6788 - val_loss: 92.9175\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6552 - val_loss: 68.6791\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.7783 - val_loss: 70.8992\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4041 - val_loss: 70.7169\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8624 - val_loss: 73.6960\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.5059 - val_loss: 77.0159\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.0928 - val_loss: 75.7597\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.5422 - val_loss: 88.9644\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.1082 - val_loss: 91.0272\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3350 - val_loss: 80.9945\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.3605 - val_loss: 80.9220\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7395 - val_loss: 83.1229\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1843 - val_loss: 89.3189\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7245 - val_loss: 89.7213\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.2468 - val_loss: 73.8100\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2755 - val_loss: 75.8381\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.2555 - val_loss: 82.6332\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.3347 - val_loss: 61.1264\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.8452 - val_loss: 66.0193\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.5594 - val_loss: 64.3390\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.6374 - val_loss: 72.0198\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7368 - val_loss: 75.2489\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.8558 - val_loss: 73.0450\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.7885 - val_loss: 76.7577\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.7860 - val_loss: 62.4972\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.0230 - val_loss: 68.0981\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.7051 - val_loss: 68.8411\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.8776 - val_loss: 66.7749\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.1209 - val_loss: 64.4217\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9632 - val_loss: 64.0427\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.5991 - val_loss: 66.5870\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0717 - val_loss: 64.0940\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4920 - val_loss: 72.6810\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.6116 - val_loss: 76.4326\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.1662 - val_loss: 73.1002\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1402 - val_loss: 80.3860\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.4445 - val_loss: 70.7700\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 91.6210 - val_loss: 66.0176\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 80.3895 - val_loss: 71.4421\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6338 - val_loss: 72.4540\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.2116 - val_loss: 73.6823\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3431 - val_loss: 66.0235\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.9646 - val_loss: 59.2521\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.2199 - val_loss: 61.6752\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.7416 - val_loss: 66.9635\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6032 - val_loss: 58.8849\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.6359 - val_loss: 73.1140\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2039 - val_loss: 59.2131\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.3339 - val_loss: 63.2672\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.1827 - val_loss: 58.6662\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.1261 - val_loss: 59.3013\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.4809 - val_loss: 59.0621\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5048 - val_loss: 59.9679\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.7132 - val_loss: 62.2821\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.2052 - val_loss: 60.0713\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1605 - val_loss: 63.9313\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.8203 - val_loss: 61.5445\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.1471 - val_loss: 61.9907\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.7719 - val_loss: 59.0230\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.7878 - val_loss: 60.1077\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.6797 - val_loss: 64.1498\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.8240 - val_loss: 66.2388\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.2687 - val_loss: 60.6148\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7352 - val_loss: 64.8479\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.2746 - val_loss: 61.0526\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.6292 - val_loss: 65.1489\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.5785 - val_loss: 64.5324\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.8755 - val_loss: 59.0038\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 126.1876 - val_loss: 66.1188\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.9614 - val_loss: 66.9295\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9079 - val_loss: 70.4261\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7505 - val_loss: 61.0157\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 53.4496 - val_loss: 63.4915\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.6151 - val_loss: 64.1956\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2990 - val_loss: 69.8966\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0177 - val_loss: 65.7057\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.2370 - val_loss: 70.8729\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9570 - val_loss: 64.9701\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2963 - val_loss: 63.5716\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.7293 - val_loss: 68.9917\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.6544 - val_loss: 63.2396\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.9719 - val_loss: 56.4673\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.9096 - val_loss: 62.3822\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.6720 - val_loss: 64.3673\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 143.6474 - val_loss: 69.3872\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.8533 - val_loss: 67.7758\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.3559 - val_loss: 64.1356\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.5198 - val_loss: 57.4902\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.9022 - val_loss: 64.5364\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.9586 - val_loss: 59.7348\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.1201 - val_loss: 58.7202\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.4657 - val_loss: 62.6204\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1022 - val_loss: 59.0126\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.1872 - val_loss: 59.4439\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 68.0292 - val_loss: 70.7384\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 88.2553 - val_loss: 60.9643\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3485 - val_loss: 58.3359\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.0808 - val_loss: 60.7558\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.9415 - val_loss: 61.8996\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.6066 - val_loss: 64.3083\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.5473 - val_loss: 68.5215\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.4490 - val_loss: 58.1042\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3733 - val_loss: 58.3875\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.7884 - val_loss: 59.5078\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.2826 - val_loss: 63.0344\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 138.7774 - val_loss: 67.1817\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.3219 - val_loss: 60.8929\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 57.1665 - val_loss: 58.7540\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4662 - val_loss: 58.4714\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.7465 - val_loss: 60.1013\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.1017 - val_loss: 62.2803\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.9499 - val_loss: 59.5584\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.8585 - val_loss: 64.4438\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8890 - val_loss: 59.0533\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6121 - val_loss: 58.9067\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.9236 - val_loss: 60.1498\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0416 - val_loss: 59.1843\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3452 - val_loss: 72.2845\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.7423 - val_loss: 62.4685\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.4033 - val_loss: 63.4355\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.5027 - val_loss: 61.7551\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.3838 - val_loss: 62.7125\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5353 - val_loss: 61.6023\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.9524 - val_loss: 60.3073\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.8871 - val_loss: 61.0239\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.5805 - val_loss: 60.5696\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.7720 - val_loss: 73.6117\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9429 - val_loss: 72.8573\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2178 - val_loss: 73.2140\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.8848 - val_loss: 59.4995\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0963 - val_loss: 60.5967\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.3138 - val_loss: 66.5367\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.1215 - val_loss: 69.4530\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.1994 - val_loss: 64.3617\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 73.4189 - val_loss: 64.8582\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7902 - val_loss: 60.7635\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.1469 - val_loss: 57.4133\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.6924 - val_loss: 61.2945\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5283 - val_loss: 67.4231\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.6302 - val_loss: 64.6189\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.1314 - val_loss: 72.6771\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.1738 - val_loss: 69.6372\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4983 - val_loss: 61.7251\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9487 - val_loss: 62.1914\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.2610 - val_loss: 62.3141\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4560 - val_loss: 61.5741\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.7829 - val_loss: 59.5620\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8994 - val_loss: 65.3708\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4653 - val_loss: 58.2799\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.7406 - val_loss: 58.8682\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.7459 - val_loss: 58.4195\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 49.1107 - val_loss: 70.0567\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.8054 - val_loss: 68.5229\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.4489 - val_loss: 62.8185\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.4969 - val_loss: 61.0809\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.9182 - val_loss: 63.8358\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7807 - val_loss: 66.2298\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.9497 - val_loss: 57.7051\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.5228 - val_loss: 61.9918\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2051 - val_loss: 57.5918\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 32.6085\n",
      "--- Starting trial: run-58\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 256, 'optimizer': 'adam'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 15ms/step - loss: 689.6856 - val_loss: 659.6799\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4965 - val_loss: 659.3765\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.2673 - val_loss: 659.0291\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9897 - val_loss: 658.6293\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.6562 - val_loss: 658.1735\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.2603 - val_loss: 657.6490\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.7964 - val_loss: 657.0530\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 687.2606 - val_loss: 656.4009\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.6492 - val_loss: 655.6719\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 685.9594 - val_loss: 654.8759\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.1890 - val_loss: 653.9876\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.3362 - val_loss: 653.0391\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.3995 - val_loss: 651.9990\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.3777 - val_loss: 650.8748\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 681.2698 - val_loss: 649.6863\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 680.0750 - val_loss: 648.4396\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 678.7926 - val_loss: 647.0988\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.4224 - val_loss: 645.6735\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.9637 - val_loss: 644.1538\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 674.4164 - val_loss: 642.5458\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 672.7803 - val_loss: 640.8584\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 671.0551 - val_loss: 639.1061\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 669.2407 - val_loss: 637.2869\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 667.3371 - val_loss: 635.3811\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 665.3443 - val_loss: 633.3340\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.2624 - val_loss: 631.1683\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 661.0914 - val_loss: 628.9979\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 658.8312 - val_loss: 626.7017\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 656.4824 - val_loss: 624.3514\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.0447 - val_loss: 621.9353\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 651.5183 - val_loss: 619.3665\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.9036 - val_loss: 616.8005\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 646.2004 - val_loss: 614.0608\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 643.4092 - val_loss: 611.2279\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 640.5303 - val_loss: 608.3645\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 637.5634 - val_loss: 605.4545\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 634.5092 - val_loss: 602.4086\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.3677 - val_loss: 599.2022\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.1391 - val_loss: 596.0452\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.8238 - val_loss: 592.7736\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.4219 - val_loss: 589.3186\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.9335 - val_loss: 585.9056\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 614.3592 - val_loss: 582.3130\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.6990 - val_loss: 578.6241\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 606.9532 - val_loss: 574.9922\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.1219 - val_loss: 571.1669\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 599.2056 - val_loss: 567.3122\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.2045 - val_loss: 563.2783\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 591.1187 - val_loss: 559.1831\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 586.9486 - val_loss: 555.1706\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 582.6943 - val_loss: 550.8694\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 578.3702 - val_loss: 551.0096\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.9516 - val_loss: 551.2055\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.4551 - val_loss: 548.5110\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.8701 - val_loss: 544.7717\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.2000 - val_loss: 540.0520\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.5835 - val_loss: 540.0620\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.6279 - val_loss: 541.8982\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.7205 - val_loss: 539.7037\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 540.7242 - val_loss: 534.6941\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 535.6433 - val_loss: 530.2012\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 530.4798 - val_loss: 524.5115\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 525.2347 - val_loss: 518.8140\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 519.9086 - val_loss: 513.1310\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 514.5016 - val_loss: 507.2117\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 509.0143 - val_loss: 502.0755\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 503.4470 - val_loss: 496.4840\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 497.7996 - val_loss: 490.9374\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 492.0857 - val_loss: 488.6898\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 486.2825 - val_loss: 486.6249\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 480.4072 - val_loss: 481.6095\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 474.4467 - val_loss: 475.3772\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 468.4050 - val_loss: 468.6799\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.7633 - val_loss: 463.8004\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 456.1201 - val_loss: 458.0045\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 449.8524 - val_loss: 451.5073\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 443.6059 - val_loss: 446.0976\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 437.1034 - val_loss: 439.5051\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 430.6028 - val_loss: 432.7923\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 424.0181 - val_loss: 425.3753\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 417.3537 - val_loss: 417.7829\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 410.6114 - val_loss: 411.2057\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 403.7948 - val_loss: 404.8897\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 397.2495 - val_loss: 399.4559\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 390.0080 - val_loss: 392.3963\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 382.9953 - val_loss: 384.1050\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 375.8861 - val_loss: 376.5721\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368.6925 - val_loss: 368.1873\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.4202 - val_loss: 360.2560\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.0715 - val_loss: 352.2181\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 346.7931 - val_loss: 343.8739\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 339.2944 - val_loss: 336.4902\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 331.6268 - val_loss: 328.4833\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 325.6832 - val_loss: 320.6293\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.7749 - val_loss: 312.1411\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 310.1665 - val_loss: 303.0828\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 302.9411 - val_loss: 294.5116\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 295.6678 - val_loss: 285.6731\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 287.8641 - val_loss: 277.7469\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 279.2452 - val_loss: 272.1829\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 272.1822 - val_loss: 264.3664\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 266.4580 - val_loss: 255.5205\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 259.0153 - val_loss: 247.1468\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249.6762 - val_loss: 238.4861\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.7079 - val_loss: 231.0058\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 235.4599 - val_loss: 224.9380\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 225.5939 - val_loss: 217.7014\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 219.0632 - val_loss: 209.6075\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 214.3900 - val_loss: 203.1369\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 220.6007 - val_loss: 195.6588\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 197.6916 - val_loss: 189.9212\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 195.0854 - val_loss: 186.5632\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.8812 - val_loss: 181.6539\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 184.3380 - val_loss: 174.7464\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 175.9053 - val_loss: 168.6201\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 162.3223 - val_loss: 159.9131\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 167.5968 - val_loss: 150.3018\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 154.0022 - val_loss: 151.4982\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 140.7310 - val_loss: 153.3663\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.8462 - val_loss: 148.7119\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 141.2509 - val_loss: 141.0018\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.3848 - val_loss: 120.6723\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 129.9080 - val_loss: 116.7739\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 156.5334 - val_loss: 123.8543\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 122.1614 - val_loss: 118.0548\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 130.2564 - val_loss: 116.6100\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.1965 - val_loss: 115.9860\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.0330 - val_loss: 118.6443\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 99.8106 - val_loss: 114.0204\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.7656 - val_loss: 107.2721\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6222 - val_loss: 111.7413\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.6864 - val_loss: 103.0175\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3269 - val_loss: 90.0378\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2586 - val_loss: 87.9338\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.3645 - val_loss: 89.3455\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 99.9924 - val_loss: 84.0460\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.6830 - val_loss: 82.7785\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2929 - val_loss: 82.4011\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5542 - val_loss: 90.0259\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.0860 - val_loss: 88.7224\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.8407 - val_loss: 80.3522\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8737 - val_loss: 76.2923\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6573 - val_loss: 70.1045\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5813 - val_loss: 67.8034\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.0590 - val_loss: 69.9706\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.5166 - val_loss: 69.2692\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 98.8155 - val_loss: 66.2705\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.1939 - val_loss: 66.3751\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 73.4856 - val_loss: 69.8093\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.2532 - val_loss: 76.6320\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9074 - val_loss: 69.3818\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.7735 - val_loss: 68.2702\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.2390 - val_loss: 68.5752\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.6636 - val_loss: 67.3766\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5999 - val_loss: 65.8104\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1539 - val_loss: 65.6503\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 72.3319 - val_loss: 66.1315\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1891 - val_loss: 66.3512\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 123.7353 - val_loss: 66.5046\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7600 - val_loss: 67.3760\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3689 - val_loss: 65.8730\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.5135 - val_loss: 66.5151\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.9425 - val_loss: 66.1684\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.1786 - val_loss: 64.5925\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.3480 - val_loss: 66.4995\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1464 - val_loss: 68.0729\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.4929 - val_loss: 67.9067\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 82.1679 - val_loss: 70.6664\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.0303 - val_loss: 67.0877\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.2518 - val_loss: 66.1207\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8861 - val_loss: 65.1621\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.0400 - val_loss: 64.6497\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.2305 - val_loss: 64.6741\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.2093 - val_loss: 64.5823\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.9598 - val_loss: 64.7581\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.2581 - val_loss: 64.6524\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4219 - val_loss: 64.5998\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8045 - val_loss: 65.7169\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0119 - val_loss: 64.7604\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.0877 - val_loss: 64.3210\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.5422 - val_loss: 63.8140\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.5861 - val_loss: 64.5455\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.1530 - val_loss: 64.0822\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.7500 - val_loss: 63.9670\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.0306 - val_loss: 66.8307\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3182 - val_loss: 65.6542\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.1081 - val_loss: 64.3752\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8657 - val_loss: 64.9267\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.5311 - val_loss: 64.3415\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.9597 - val_loss: 71.1914\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8493 - val_loss: 69.7925\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7100 - val_loss: 65.2966\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.0107 - val_loss: 63.8988\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.5910 - val_loss: 64.2065\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.3935 - val_loss: 64.3222\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9300 - val_loss: 67.6185\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6296 - val_loss: 64.9155\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 95.4593 - val_loss: 64.4797\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.7582 - val_loss: 65.3122\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8916 - val_loss: 62.8271\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.2894 - val_loss: 63.7751\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.1654 - val_loss: 63.9402\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 59.1975 - val_loss: 64.0890\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.7560 - val_loss: 65.6564\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 72.8581 - val_loss: 64.3470\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.1971 - val_loss: 63.9128\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3863 - val_loss: 63.9287\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.6767 - val_loss: 64.9418\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.2094 - val_loss: 66.7446\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.0144 - val_loss: 64.7397\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.5011 - val_loss: 64.2356\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.5165 - val_loss: 64.2996\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.8588 - val_loss: 63.9638\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.2867 - val_loss: 63.2060\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1407 - val_loss: 64.3580\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 60.7720 - val_loss: 62.2751\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 125.9548 - val_loss: 64.1869\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.2801 - val_loss: 62.5767\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.0395 - val_loss: 64.4753\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 56.0502 - val_loss: 64.0757\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.6977 - val_loss: 63.3870\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8161 - val_loss: 63.8041\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1718 - val_loss: 64.2118\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.4181 - val_loss: 65.1031\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.3792 - val_loss: 63.8322\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.8479 - val_loss: 63.2340\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.1570 - val_loss: 63.7165\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.6835 - val_loss: 64.4307\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.4963 - val_loss: 65.1379\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.2055 - val_loss: 64.2951\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1984 - val_loss: 64.2774\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.2045 - val_loss: 64.3723\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 58.5525 - val_loss: 66.3932\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 57.6791 - val_loss: 63.9934\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 96.9584 - val_loss: 62.8872\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.2169 - val_loss: 62.4651\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9606 - val_loss: 62.1149\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 104.6524 - val_loss: 62.1273\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 94.5513 - val_loss: 62.9145\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.0035 - val_loss: 62.5557\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.2881 - val_loss: 62.0215\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.4532 - val_loss: 62.3385\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3627 - val_loss: 63.3561\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3541 - val_loss: 63.9980\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.3598 - val_loss: 66.1646\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.6009 - val_loss: 65.4885\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8190 - val_loss: 65.0003\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.9857 - val_loss: 62.3280\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.2880 - val_loss: 65.7297\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 66.2830 - val_loss: 63.5610\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 51.9611\n",
      "--- Starting trial: run-59\n",
      "{'activation': 'sigmoid', 'dropout': 0.2, 'num_units': 256, 'optimizer': 'sgd'}\n",
      "Epoch 1/250\n",
      "8/8 [==============================] - 1s 17ms/step - loss: 689.6576 - val_loss: 661.5768\n",
      "Epoch 2/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 689.4169 - val_loss: 661.2859\n",
      "Epoch 3/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 689.1705 - val_loss: 660.9968\n",
      "Epoch 4/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.9146 - val_loss: 660.7018\n",
      "Epoch 5/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 688.6443 - val_loss: 660.3990\n",
      "Epoch 6/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.3550 - val_loss: 660.0779\n",
      "Epoch 7/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 688.0412 - val_loss: 659.7360\n",
      "Epoch 8/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.6970 - val_loss: 659.3672\n",
      "Epoch 9/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 687.3159 - val_loss: 658.9594\n",
      "Epoch 10/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.8898 - val_loss: 658.5058\n",
      "Epoch 11/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 686.4103 - val_loss: 657.9979\n",
      "Epoch 12/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.8670 - val_loss: 657.4218\n",
      "Epoch 13/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 685.2483 - val_loss: 656.7625\n",
      "Epoch 14/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 684.5403 - val_loss: 656.0179\n",
      "Epoch 15/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 683.7272 - val_loss: 655.1532\n",
      "Epoch 16/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 682.7905 - val_loss: 654.1591\n",
      "Epoch 17/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 681.7081 - val_loss: 653.0132\n",
      "Epoch 18/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 680.4547 - val_loss: 651.6755\n",
      "Epoch 19/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 679.0005 - val_loss: 650.1158\n",
      "Epoch 20/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 677.3106 - val_loss: 648.2975\n",
      "Epoch 21/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 675.3442 - val_loss: 646.1817\n",
      "Epoch 22/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 673.0532 - val_loss: 643.7120\n",
      "Epoch 23/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 670.3815 - val_loss: 640.8157\n",
      "Epoch 24/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 667.2634 - val_loss: 637.4286\n",
      "Epoch 25/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 663.6215 - val_loss: 633.4625\n",
      "Epoch 26/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 659.3655 - val_loss: 628.7866\n",
      "Epoch 27/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 654.3893 - val_loss: 623.3828\n",
      "Epoch 28/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 648.5685 - val_loss: 617.0345\n",
      "Epoch 29/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 641.7573 - val_loss: 609.6215\n",
      "Epoch 30/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 633.7848 - val_loss: 600.9172\n",
      "Epoch 31/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 624.4504 - val_loss: 590.7076\n",
      "Epoch 32/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 613.5192 - val_loss: 578.7388\n",
      "Epoch 33/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.7153 - val_loss: 564.7225\n",
      "Epoch 34/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 585.7158 - val_loss: 548.2446\n",
      "Epoch 35/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 568.1417 - val_loss: 529.3865\n",
      "Epoch 36/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 547.5485 - val_loss: 508.7844\n",
      "Epoch 37/250\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 524.8831 - val_loss: 487.9672\n",
      "Epoch 38/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 499.1611 - val_loss: 463.4258\n",
      "Epoch 39/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 469.1716 - val_loss: 434.9987\n",
      "Epoch 40/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 436.9475 - val_loss: 402.6782\n",
      "Epoch 41/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 399.9496 - val_loss: 366.8345\n",
      "Epoch 42/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 361.4517 - val_loss: 330.4579\n",
      "Epoch 43/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 317.4713 - val_loss: 290.2901\n",
      "Epoch 44/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 281.7429 - val_loss: 258.9863\n",
      "Epoch 45/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 243.9349 - val_loss: 218.6235\n",
      "Epoch 46/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 213.5108 - val_loss: 189.9453\n",
      "Epoch 47/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 183.1410 - val_loss: 160.3835\n",
      "Epoch 48/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 155.1423 - val_loss: 152.6839\n",
      "Epoch 49/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 141.0099 - val_loss: 138.5758\n",
      "Epoch 50/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.0543 - val_loss: 133.9695\n",
      "Epoch 51/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 137.2074 - val_loss: 131.4728\n",
      "Epoch 52/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.1591 - val_loss: 130.8195\n",
      "Epoch 53/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 128.5338 - val_loss: 129.4389\n",
      "Epoch 54/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.2240 - val_loss: 120.0014\n",
      "Epoch 55/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.3773 - val_loss: 112.2940\n",
      "Epoch 56/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.3994 - val_loss: 113.2984\n",
      "Epoch 57/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8391 - val_loss: 107.9052\n",
      "Epoch 58/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 120.7865 - val_loss: 98.5145\n",
      "Epoch 59/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1586 - val_loss: 93.2476\n",
      "Epoch 60/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.1293 - val_loss: 91.9553\n",
      "Epoch 61/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0870 - val_loss: 89.2600\n",
      "Epoch 62/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.6823 - val_loss: 97.5584\n",
      "Epoch 63/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 113.8275 - val_loss: 90.0402\n",
      "Epoch 64/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 101.3696 - val_loss: 93.5878\n",
      "Epoch 65/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5808 - val_loss: 86.8350\n",
      "Epoch 66/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 87.3648 - val_loss: 86.0615\n",
      "Epoch 67/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.3539 - val_loss: 82.1419\n",
      "Epoch 68/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.8976 - val_loss: 87.1654\n",
      "Epoch 69/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 110.5769 - val_loss: 92.0247\n",
      "Epoch 70/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.5131 - val_loss: 90.4586\n",
      "Epoch 71/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 112.1757 - val_loss: 80.8357\n",
      "Epoch 72/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5430 - val_loss: 79.7566\n",
      "Epoch 73/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 86.7613 - val_loss: 76.9341\n",
      "Epoch 74/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.5322 - val_loss: 89.0777\n",
      "Epoch 75/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.1313 - val_loss: 80.3006\n",
      "Epoch 76/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.8365 - val_loss: 75.2855\n",
      "Epoch 77/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 84.7587 - val_loss: 74.4226\n",
      "Epoch 78/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 80.9006 - val_loss: 86.6500\n",
      "Epoch 79/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.7721 - val_loss: 80.9393\n",
      "Epoch 80/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8334 - val_loss: 79.2952\n",
      "Epoch 81/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.4162 - val_loss: 77.0208\n",
      "Epoch 82/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.1288 - val_loss: 71.1889\n",
      "Epoch 83/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.2202 - val_loss: 76.3319\n",
      "Epoch 84/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.6361 - val_loss: 70.5732\n",
      "Epoch 85/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 83.1088 - val_loss: 70.9678\n",
      "Epoch 86/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.7718 - val_loss: 79.4637\n",
      "Epoch 87/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5210 - val_loss: 72.8942\n",
      "Epoch 88/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.5480 - val_loss: 75.2786\n",
      "Epoch 89/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6111 - val_loss: 70.5378\n",
      "Epoch 90/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1368 - val_loss: 68.5025\n",
      "Epoch 91/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.4933 - val_loss: 70.7815\n",
      "Epoch 92/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.5493 - val_loss: 70.1675\n",
      "Epoch 93/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 63.7139 - val_loss: 71.8428\n",
      "Epoch 94/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.4835 - val_loss: 66.2499\n",
      "Epoch 95/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.4952 - val_loss: 65.2627\n",
      "Epoch 96/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.8185 - val_loss: 74.6359\n",
      "Epoch 97/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.3088 - val_loss: 78.6378\n",
      "Epoch 98/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 98.5805 - val_loss: 69.0570\n",
      "Epoch 99/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 93.7391 - val_loss: 83.5162\n",
      "Epoch 100/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 83.3327 - val_loss: 65.4978\n",
      "Epoch 101/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.6583 - val_loss: 65.5371\n",
      "Epoch 102/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.8632 - val_loss: 65.5076\n",
      "Epoch 103/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.9365 - val_loss: 72.1920\n",
      "Epoch 104/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.1391 - val_loss: 74.7428\n",
      "Epoch 105/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.2595 - val_loss: 69.1175\n",
      "Epoch 106/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.5957 - val_loss: 65.7071\n",
      "Epoch 107/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.7545 - val_loss: 67.9071\n",
      "Epoch 108/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6248 - val_loss: 67.4752\n",
      "Epoch 109/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.1220 - val_loss: 67.6829\n",
      "Epoch 110/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 74.1189 - val_loss: 66.7245\n",
      "Epoch 111/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.9051 - val_loss: 68.2472\n",
      "Epoch 112/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.2935 - val_loss: 66.8801\n",
      "Epoch 113/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.1979 - val_loss: 62.5578\n",
      "Epoch 114/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.4546 - val_loss: 62.5272\n",
      "Epoch 115/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.5185 - val_loss: 67.2085\n",
      "Epoch 116/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 109.1777 - val_loss: 62.6155\n",
      "Epoch 117/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 76.1217 - val_loss: 65.3539\n",
      "Epoch 118/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 79.4278 - val_loss: 64.5953\n",
      "Epoch 119/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.6008 - val_loss: 76.6013\n",
      "Epoch 120/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.3281 - val_loss: 63.3525\n",
      "Epoch 121/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.8024 - val_loss: 61.3875\n",
      "Epoch 122/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.2968 - val_loss: 61.9577\n",
      "Epoch 123/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0414 - val_loss: 62.7043\n",
      "Epoch 124/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.1472 - val_loss: 63.6621\n",
      "Epoch 125/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.8292 - val_loss: 69.9558\n",
      "Epoch 126/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.3237 - val_loss: 63.2220\n",
      "Epoch 127/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.9300 - val_loss: 65.5760\n",
      "Epoch 128/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8979 - val_loss: 78.5229\n",
      "Epoch 129/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.9176 - val_loss: 69.3530\n",
      "Epoch 130/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.6012 - val_loss: 68.7145\n",
      "Epoch 131/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.2975 - val_loss: 71.4494\n",
      "Epoch 132/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 69.1449 - val_loss: 62.1375\n",
      "Epoch 133/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.7786 - val_loss: 64.5999\n",
      "Epoch 134/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 60.1229 - val_loss: 61.6232\n",
      "Epoch 135/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.1658 - val_loss: 63.5328\n",
      "Epoch 136/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.8602 - val_loss: 66.0028\n",
      "Epoch 137/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.3331 - val_loss: 64.6018\n",
      "Epoch 138/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 95.3435 - val_loss: 60.9196\n",
      "Epoch 139/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.7023 - val_loss: 64.0614\n",
      "Epoch 140/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.8224 - val_loss: 61.7058\n",
      "Epoch 141/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.3577 - val_loss: 62.8273\n",
      "Epoch 142/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 139.9135 - val_loss: 63.8219\n",
      "Epoch 143/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.8751 - val_loss: 63.3204\n",
      "Epoch 144/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1681 - val_loss: 67.7115\n",
      "Epoch 145/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6275 - val_loss: 63.3725\n",
      "Epoch 146/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.5351 - val_loss: 62.1575\n",
      "Epoch 147/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5246 - val_loss: 61.5558\n",
      "Epoch 148/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.8224 - val_loss: 80.1989\n",
      "Epoch 149/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.9794 - val_loss: 82.0781\n",
      "Epoch 150/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 83.0212 - val_loss: 64.8869\n",
      "Epoch 151/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 65.0327 - val_loss: 63.6336\n",
      "Epoch 152/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.1655 - val_loss: 63.5660\n",
      "Epoch 153/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.5351 - val_loss: 64.1049\n",
      "Epoch 154/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.2406 - val_loss: 66.8909\n",
      "Epoch 155/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 89.5408 - val_loss: 63.1911\n",
      "Epoch 156/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 144.7297 - val_loss: 64.7455\n",
      "Epoch 157/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 116.4995 - val_loss: 65.0055\n",
      "Epoch 158/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.0722 - val_loss: 63.2206\n",
      "Epoch 159/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.9157 - val_loss: 72.2113\n",
      "Epoch 160/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.4316 - val_loss: 66.8750\n",
      "Epoch 161/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4027 - val_loss: 64.6394\n",
      "Epoch 162/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 97.3043 - val_loss: 70.5476\n",
      "Epoch 163/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 79.0600 - val_loss: 61.9016\n",
      "Epoch 164/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 64.1194 - val_loss: 62.8410\n",
      "Epoch 165/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 88.3141 - val_loss: 66.0959\n",
      "Epoch 166/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 103.9038 - val_loss: 64.8139\n",
      "Epoch 167/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 74.3253 - val_loss: 65.0201\n",
      "Epoch 168/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 102.1718 - val_loss: 62.8521\n",
      "Epoch 169/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8218 - val_loss: 68.9577\n",
      "Epoch 170/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.5050 - val_loss: 61.5030\n",
      "Epoch 171/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.0110 - val_loss: 69.6640\n",
      "Epoch 172/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.6164 - val_loss: 62.4929\n",
      "Epoch 173/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.2739 - val_loss: 62.6355\n",
      "Epoch 174/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 67.6154 - val_loss: 65.7392\n",
      "Epoch 175/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 92.3978 - val_loss: 65.9445\n",
      "Epoch 176/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3310 - val_loss: 66.1124\n",
      "Epoch 177/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 62.6502 - val_loss: 69.2438\n",
      "Epoch 178/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.8185 - val_loss: 62.5390\n",
      "Epoch 179/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.0991 - val_loss: 62.7601\n",
      "Epoch 180/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.2010 - val_loss: 74.6806\n",
      "Epoch 181/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 87.1300 - val_loss: 66.4409\n",
      "Epoch 182/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.3046 - val_loss: 67.6248\n",
      "Epoch 183/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 136.2896 - val_loss: 65.6329\n",
      "Epoch 184/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.7991 - val_loss: 61.7027\n",
      "Epoch 185/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.0763 - val_loss: 67.8902\n",
      "Epoch 186/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.5246 - val_loss: 63.4853\n",
      "Epoch 187/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 68.9758 - val_loss: 63.0908\n",
      "Epoch 188/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 73.3141 - val_loss: 62.2983\n",
      "Epoch 189/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 111.0476 - val_loss: 62.4844\n",
      "Epoch 190/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 86.8065 - val_loss: 60.7347\n",
      "Epoch 191/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.4359 - val_loss: 61.0768\n",
      "Epoch 192/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 118.1469 - val_loss: 63.0010\n",
      "Epoch 193/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3389 - val_loss: 63.8313\n",
      "Epoch 194/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.0012 - val_loss: 67.0207\n",
      "Epoch 195/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 67.6700 - val_loss: 62.7135\n",
      "Epoch 196/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 126.6826 - val_loss: 62.3205\n",
      "Epoch 197/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 71.9513 - val_loss: 70.4101\n",
      "Epoch 198/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.4995 - val_loss: 64.6036\n",
      "Epoch 199/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.5932 - val_loss: 73.8352\n",
      "Epoch 200/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 96.6368 - val_loss: 63.5469\n",
      "Epoch 201/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.9496 - val_loss: 61.7140\n",
      "Epoch 202/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 55.4094 - val_loss: 67.4055\n",
      "Epoch 203/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 64.1204 - val_loss: 75.2181\n",
      "Epoch 204/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 77.1511 - val_loss: 62.4050\n",
      "Epoch 205/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.1204 - val_loss: 61.9094\n",
      "Epoch 206/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 102.9779 - val_loss: 62.8526\n",
      "Epoch 207/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.8841 - val_loss: 65.1034\n",
      "Epoch 208/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 75.4570 - val_loss: 70.5540\n",
      "Epoch 209/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.6775 - val_loss: 65.1079\n",
      "Epoch 210/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.3891 - val_loss: 73.8165\n",
      "Epoch 211/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 63.9435 - val_loss: 64.9409\n",
      "Epoch 212/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.8069 - val_loss: 62.5827\n",
      "Epoch 213/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 71.3756 - val_loss: 62.9543\n",
      "Epoch 214/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 70.3891 - val_loss: 74.2653\n",
      "Epoch 215/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.6134 - val_loss: 66.7207\n",
      "Epoch 216/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 97.3172 - val_loss: 64.2482\n",
      "Epoch 217/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5664 - val_loss: 73.5026\n",
      "Epoch 218/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 101.3594 - val_loss: 62.8624\n",
      "Epoch 219/250\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 74.5367 - val_loss: 61.7129\n",
      "Epoch 220/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.4161 - val_loss: 70.3272\n",
      "Epoch 221/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 91.5483 - val_loss: 63.8428\n",
      "Epoch 222/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.1821 - val_loss: 63.8281\n",
      "Epoch 223/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.3191 - val_loss: 63.9240\n",
      "Epoch 224/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 99.5282 - val_loss: 64.8760\n",
      "Epoch 225/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7829 - val_loss: 65.5901\n",
      "Epoch 226/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 79.5803 - val_loss: 65.8715\n",
      "Epoch 227/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 54.5715 - val_loss: 62.0700\n",
      "Epoch 228/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 100.1722 - val_loss: 64.6973\n",
      "Epoch 229/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 81.1009 - val_loss: 67.1300\n",
      "Epoch 230/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 80.7609 - val_loss: 80.6476\n",
      "Epoch 231/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 94.6822 - val_loss: 62.1480\n",
      "Epoch 232/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.7498 - val_loss: 66.5992\n",
      "Epoch 233/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 56.3395 - val_loss: 69.4415\n",
      "Epoch 234/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 68.8284 - val_loss: 63.5631\n",
      "Epoch 235/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 93.1079 - val_loss: 64.5555\n",
      "Epoch 236/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.2099 - val_loss: 64.4705\n",
      "Epoch 237/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.0706 - val_loss: 67.6222\n",
      "Epoch 238/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 76.6952 - val_loss: 61.5559\n",
      "Epoch 239/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 61.5164 - val_loss: 70.0570\n",
      "Epoch 240/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.1660 - val_loss: 64.4347\n",
      "Epoch 241/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 78.5520 - val_loss: 64.3907\n",
      "Epoch 242/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.5056 - val_loss: 63.5469\n",
      "Epoch 243/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 85.7493 - val_loss: 61.6199\n",
      "Epoch 244/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 69.6142 - val_loss: 61.7213\n",
      "Epoch 245/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 82.7027 - val_loss: 61.4024\n",
      "Epoch 246/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 73.1081 - val_loss: 61.7947\n",
      "Epoch 247/250\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 89.1112 - val_loss: 61.4600\n",
      "Epoch 248/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 90.6783 - val_loss: 61.3168\n",
      "Epoch 249/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 95.2981 - val_loss: 63.2398\n",
      "Epoch 250/250\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 75.3943 - val_loss: 63.1968\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 58.5849\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for droput in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for activation in HP_ACTIVATION.domain.values:\n",
    "            for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                hparams = {\n",
    "                    HP_ACTIVATION: activation,\n",
    "                    HP_DROPOUT: droput,\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_OPTIMIZER: optimizer\n",
    "                }\n",
    "\n",
    "                run_name = \"run-%d\" % session_num\n",
    "                print('--- Starting trial: %s' % run_name)\n",
    "                print({h.name: hparams[h] for h in hparams})\n",
    "                run_model(log_dir + run_name, hparams)\n",
    "                session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
