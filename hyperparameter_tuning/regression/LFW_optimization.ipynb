{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 11:48:10.340115: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 11:48:10.387143: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-19 11:48:10.387797: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-19 11:48:11.086989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dataloader.ipynb\n",
      "Tensorflow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import import_ipynb\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from dataloader import get_LFW_X_df, get_y_df, data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filepath = \"../../data/csv/plant_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_LFW_X_df(csv_filepath)\n",
    "y = get_y_df(csv_filepath, 'LFW_g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_NUM_UNITS1 = hp.HParam(\"num_units\", hp.Discrete([16, 32, 64, 128]))\n",
    "HP_NUM_UNITS2 = hp.HParam(\"num_units\", hp.Discrete([16, 32, 64, 128]))\n",
    "\n",
    "\n",
    "HP_DROPOUT1 = hp.HParam(\"dropout\", hp.RealInterval(0.1, 0.2))\n",
    "HP_DROPOUT2 = hp.HParam(\"dropout\", hp.RealInterval(0.1, 0.2))\n",
    "\n",
    "HP_OPTIMIZER = hp.HParam(\"optimizer\", hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "HP_ACTIVATION1 = hp.HParam(\"activation\", hp.Discrete(['linear', 'relu', 'sigmoid']))\n",
    "HP_ACTIVATION2 = hp.HParam(\"activation\", hp.Discrete(['linear', 'relu', 'sigmoid']))\n",
    "\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 11:48:12.284792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-19 11:48:12.303830: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "with tf.summary.create_file_writer('../../logs/hyperparam_tuning/repression/LFW').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS1, HP_NUM_UNITS2, HP_DROPOUT1, HP_DROPOUT2, HP_OPTIMIZER, HP_ACTIVATION1, HP_ACTIVATION2],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name=\"Test Accuracy\")]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data_prep(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFW_model(hparams):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(hparams[HP_NUM_UNITS1], hparams[HP_ACTIVATION1], name='layers_input', input_shape = (11,),),\n",
    "            tf.keras.layers.Dropout(hparams[HP_DROPOUT1]),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(hparams[HP_NUM_UNITS2], hparams[HP_ACTIVATION2], name='layers_dense2'),\n",
    "            tf.keras.layers.Dropout(HP_DROPOUT2),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(1, name='layers_dense3')\n",
    "        ])\n",
    "\n",
    "        model.compile (\n",
    "            optimizer=hparams[HP_OPTIMIZER],\n",
    "            loss='mae',\n",
    "            metrics=['accuracy'],\n",
    "        )\n",
    "\n",
    "        model.fit (\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=100,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "                hp.KerasCallback(log_dir, hparams)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../../logs/hyperparam_tuning/regression/LFW/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy = LFW_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'activation': 'linear', 'dropout': 0.1, 'num_units': 16, 'optimizer': 'adam'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiple values specified for hparam 'dropout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m--- Starting trial: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m run_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m({h\u001b[39m.\u001b[39mname: hparams[h] \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hparams})\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m run_model(log_dir \u001b[39m+\u001b[39;49m run_name, hparams)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m session_num \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_model\u001b[39m(run_dir, hparams):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mcreate_file_writer(run_dir)\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         hp\u001b[39m.\u001b[39;49mhparams(hparams)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         accuracy \u001b[39m=\u001b[39m LFW_model(hparams)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/shilo/Documents/GitHub/PlantFlow/hyperparameter_tuning/regression/LFW_optimization.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         tf\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mscalar(METRIC_ACCURACY, accuracy, step\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/PlantFlow/venv/lib/python3.11/site-packages/tensorboard/plugins/hparams/summary_v2.py:56\u001b[0m, in \u001b[0;36mhparams\u001b[0;34m(hparams, trial_id, start_time_secs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhparams\u001b[39m(hparams, trial_id\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, start_time_secs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     37\u001b[0m     \u001b[39m# NOTE: Keep docs in sync with `hparams_pb` below.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Write hyperparameter values for a single trial.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m      was written because no default summary writer was available.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     pb \u001b[39m=\u001b[39m hparams_pb(\n\u001b[1;32m     57\u001b[0m         hparams\u001b[39m=\u001b[39;49mhparams,\n\u001b[1;32m     58\u001b[0m         trial_id\u001b[39m=\u001b[39;49mtrial_id,\n\u001b[1;32m     59\u001b[0m         start_time_secs\u001b[39m=\u001b[39;49mstart_time_secs,\n\u001b[1;32m     60\u001b[0m     )\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m _write_summary(\u001b[39m\"\u001b[39m\u001b[39mhparams\u001b[39m\u001b[39m\"\u001b[39m, pb)\n",
      "File \u001b[0;32m~/Documents/GitHub/PlantFlow/venv/lib/python3.11/site-packages/tensorboard/plugins/hparams/summary_v2.py:84\u001b[0m, in \u001b[0;36mhparams_pb\u001b[0;34m(hparams, trial_id, start_time_secs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m start_time_secs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     start_time_secs \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> 84\u001b[0m hparams \u001b[39m=\u001b[39m _normalize_hparams(hparams)\n\u001b[1;32m     85\u001b[0m group_name \u001b[39m=\u001b[39m _derive_session_group_name(trial_id, hparams)\n\u001b[1;32m     87\u001b[0m session_start_info \u001b[39m=\u001b[39m plugin_data_pb2\u001b[39m.\u001b[39mSessionStartInfo(\n\u001b[1;32m     88\u001b[0m     group_name\u001b[39m=\u001b[39mgroup_name,\n\u001b[1;32m     89\u001b[0m     start_time_secs\u001b[39m=\u001b[39mstart_time_secs,\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/PlantFlow/venv/lib/python3.11/site-packages/tensorboard/plugins/hparams/summary_v2.py:203\u001b[0m, in \u001b[0;36m_normalize_hparams\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m    201\u001b[0m         k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mname\n\u001b[1;32m    202\u001b[0m     \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m result:\n\u001b[0;32m--> 203\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmultiple values specified for hparam \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (k,))\n\u001b[1;32m    204\u001b[0m     result[k] \u001b[39m=\u001b[39m _normalize_numpy_value(v)\n\u001b[1;32m    205\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mValueError\u001b[0m: multiple values specified for hparam 'dropout'"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units1 in HP_NUM_UNITS1.domain.values:\n",
    "    for num_units2 in HP_NUM_UNITS2.domain.values:\n",
    "        for droput1 in (HP_DROPOUT1.domain.min_value, HP_DROPOUT1.domain.max_value):\n",
    "            for droput2 in (HP_DROPOUT2.domain.min_value, HP_DROPOUT2.domain.max_value):\n",
    "                for activation1 in HP_ACTIVATION1.domain.values:\n",
    "                    for activation2 in HP_ACTIVATION2.domain.values:\n",
    "                        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                            hparams = {\n",
    "                                HP_ACTIVATION1: activation1,\n",
    "                                HP_ACTIVATION2: activation2,\n",
    "                                HP_DROPOUT1: droput1,\n",
    "                                HP_DROPOUT2: droput2,\n",
    "                                HP_NUM_UNITS1: num_units1,\n",
    "                                HP_NUM_UNITS2: num_units2,\n",
    "                                HP_OPTIMIZER: optimizer\n",
    "                            }\n",
    "\n",
    "                            run_name = \"run-%d\" % session_num\n",
    "                            print('--- Starting trial: %s' % run_name)\n",
    "                            print({h.name: hparams[h] for h in hparams})\n",
    "                            run_model(log_dir + run_name, hparams)\n",
    "                            session_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
